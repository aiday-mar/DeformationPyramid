model 002 file1 020 file2 104
0 to 1
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[132, 123]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([255, 2048])
block_i :  1
x.shape :  torch.Size([255, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 255])
coarse_feats.shape :  torch.Size([1, 528, 255])
coarse_feats.shape :  torch.Size([255, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 132])
tgt_mask.shape :  torch.Size([1, 123])
src_ind_coarse_split.shape :  torch.Size([132])
tgt_ind_coarse_split.shape :  torch.Size([123])
src_ind_coarse.shape :  torch.Size([132])
tgt_ind_coarse.shape :  torch.Size([123])
src_feats.shape :  torch.Size([1, 132, 528])
tgt_feats.shape :  torch.Size([1, 123, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([132, 528])
F1.shape : torch.Size([123, 528])
ldmk_t_indices :  tensor([  0,  71,   0,  16,  79,  85,   1,  75,   1, 101,  28,  16,  48,  89,
         28,  48,  70,  33,  46,  28,   0,  99,  88,  63,  70,  28,  43,  99,
        117,  33,  70,  48,  96,  37,  65,  46,  79,  48,  99,  81,  79,  37,
         70,  90,  48, 101,  63, 108,  48,  63,  45,  75,  75,  30,  90,  62,
         33,  85,  62,  89,  35,  89,  28,  62,  95,  33,  62, 101, 108,  46,
         46,  28,  96,   0,  55,  74,  96,   0,  62,  46,  48,  69,  48,  62,
         89,  74,  99,  14,  48,  48,  48,  75,  62,  33,  60,  33,  21,  37,
         79,  33, 108,  41,  16,  21,  33,  95, 120,  33,  48,  33, 120,   1,
         53,  60,  33,  45,  33,  79,   1,   0,  28,  16,  33,  33,  79,   1,
         46,  33, 120,  33, 108,  43], device='cuda:0')
ldmk_s.shape :  torch.Size([132, 3])
ldmk_t.shape :  torch.Size([132, 3])
vec_6d.shape :  torch.Size([132, 6])
ind.shape :  torch.Size([1, 132, 2])
bi :  0
si.shape :  torch.Size([132])
ti.shape :  torch.Size([132])
s_pos.shape :  torch.Size([132, 3])
t_pos.shape :  torch.Size([132, 3])
ind.shape :  torch.Size([1, 132, 2])
bi :  0
si.shape :  torch.Size([132])
ti.shape :  torch.Size([132])
s_pos.shape :  torch.Size([132, 3])
t_pos.shape :  torch.Size([132, 3])
number of true landmarks correspondences returned from KNN matching :  0  out of  132
fraction of true landmark correspondences returned from KNN matching :  0.0
[1;33m[Open3D WARNING] Write PLY failed: line set has 0 points.[0;m
vec6d.shape :  torch.Size([132, 6])
ldmk_s.shape :  torch.Size([132, 3])
ldmk_t.shape :  torch.Size([132, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([132, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 18.230 
full-AccS: 0.000 
full-AccR: 0.000 
full-outlier: 99.086 
vis-epe: 19.901 
vis-AccS: 0.000 
vis-AccR: 0.000 
vis-outlier: 98.236 
occ-epe: 16.780 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 99.823 

Actual rotation :  [[-0.40974485 -0.0177874  -0.91202674]
 [ 0.82672423  0.41532003 -0.37952117]
 [ 0.38553367 -0.90950145 -0.15546996]]
Actual translation :  [ 1.97322969 -0.31353126  0.18591825]
Predicted rotation :  [[ 0.64955713  0.6056678  -0.45961082]
 [-0.62622557  0.76900417  0.12835169]
 [ 0.43118104  0.20444824  0.87879674]]
Predicted translation :  [-0.08372155 -0.00461093  0.00436416]
Relative Rotation Error :  2.2530782221332375
Relative Translation Error :  2.0879276952926125
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.15334722901931883
Strict IR :  0.0
Relaxed IR :  0.0
model 042 file1 020 file2 104
0 to 1
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[117, 114]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([231, 2048])
block_i :  1
x.shape :  torch.Size([231, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 231])
coarse_feats.shape :  torch.Size([1, 528, 231])
coarse_feats.shape :  torch.Size([231, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 117])
tgt_mask.shape :  torch.Size([1, 114])
src_ind_coarse_split.shape :  torch.Size([117])
tgt_ind_coarse_split.shape :  torch.Size([114])
src_ind_coarse.shape :  torch.Size([117])
tgt_ind_coarse.shape :  torch.Size([114])
src_feats.shape :  torch.Size([1, 117, 528])
tgt_feats.shape :  torch.Size([1, 114, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([117, 528])
F1.shape : torch.Size([114, 528])
ldmk_t_indices :  tensor([ 28,  72, 107,   5, 107,   5,  54,  54,  54, 107,  28,  73,  69,  61,
         72,  43,  54,  61,  59,  36,   1,  54,  58, 104,  54,  72,  61,  35,
         77,  69,  59,  49,  44,   1,  19,  54,  28,  54,  37, 109,  35,  28,
         34,  17,  28,  53, 112,  72,  40,  59,  43,  54,  37,  28,  53,   5,
         74,  53,  59,  28,   1,  74,  74,  74,  34,  28,  14,  15,  59,  59,
         61,   5,  74,  54,  26,  34,  74,   5, 104,  11,  69,  34,  28,  61,
         17,  28,  61,  88,  28,  92,  39,  71,  59,  34,  28,  11,  28,  69,
         14,  43,  28,  28, 109,  69,   5,  74,  77,  23,  17,  28,  54,  28,
         28,  25,  28,  69,  28], device='cuda:0')
ldmk_s.shape :  torch.Size([117, 3])
ldmk_t.shape :  torch.Size([117, 3])
vec_6d.shape :  torch.Size([117, 6])
ind.shape :  torch.Size([1, 117, 2])
bi :  0
si.shape :  torch.Size([117])
ti.shape :  torch.Size([117])
s_pos.shape :  torch.Size([117, 3])
t_pos.shape :  torch.Size([117, 3])
ind.shape :  torch.Size([1, 117, 2])
bi :  0
si.shape :  torch.Size([117])
ti.shape :  torch.Size([117])
s_pos.shape :  torch.Size([117, 3])
t_pos.shape :  torch.Size([117, 3])
number of true landmarks correspondences returned from KNN matching :  2  out of  117
fraction of true landmark correspondences returned from KNN matching :  0.017094017094017096
vec6d.shape :  torch.Size([117, 6])
ldmk_s.shape :  torch.Size([117, 3])
ldmk_t.shape :  torch.Size([117, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([117, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 23.453 
full-AccS: 0.000 
full-AccR: 1.221 
full-outlier: 98.111 
vis-epe: 26.920 
vis-AccS: 0.000 
vis-AccR: 0.794 
vis-outlier: 98.739 
occ-epe: 14.261 
occ-AccS: 0.000 
occ-AccR: 2.353 
occ-outlier: 96.449 

Actual rotation :  [[-0.87462848 -0.4705988  -0.11645507]
 [ 0.24256895 -0.63279443  0.73534448]
 [-0.41974435  0.61490485  0.66761269]]
Actual translation :  [ 1.20593496  0.83257865 -0.4390415 ]
Predicted rotation :  [[ 0.95582612  0.19951966 -0.21584318]
 [-0.16955122  0.97410036  0.14960228]
 [ 0.24010153 -0.10639726  0.96489942]]
Predicted translation :  [-0.02145904  0.01494844 -0.0122162 ]
Relative Rotation Error :  2.9811105363235177
Relative Translation Error :  1.5353159354418529
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.13671415506989784
Strict IR :  0.00011308379509216329
Relaxed IR :  0.02510460251046025
model 085 file1 020 file2 104
0 to 1
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[73, 57]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([130, 2048])
block_i :  1
x.shape :  torch.Size([130, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 130])
coarse_feats.shape :  torch.Size([1, 528, 130])
coarse_feats.shape :  torch.Size([130, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 73])
tgt_mask.shape :  torch.Size([1, 57])
src_ind_coarse_split.shape :  torch.Size([73])
tgt_ind_coarse_split.shape :  torch.Size([57])
src_ind_coarse.shape :  torch.Size([73])
tgt_ind_coarse.shape :  torch.Size([57])
src_feats.shape :  torch.Size([1, 73, 528])
tgt_feats.shape :  torch.Size([1, 57, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([73, 528])
F1.shape : torch.Size([57, 528])
ldmk_t_indices :  tensor([ 9,  9, 45, 31, 25, 50, 31, 25, 31, 31, 25, 31, 50, 25, 56, 25, 31, 31,
        25, 25, 50, 25,  9, 31, 31, 24, 31,  4, 31,  2, 44, 31, 39, 44,  9, 56,
        31, 44, 12, 31, 12, 12, 44, 31, 13, 31, 12, 44,  2, 44, 42, 31, 39, 50,
         9, 12, 44, 12, 39, 56, 24, 31, 45, 31,  9, 44,  9, 31, 44, 12, 24, 50,
        31], device='cuda:0')
ldmk_s.shape :  torch.Size([73, 3])
ldmk_t.shape :  torch.Size([73, 3])
vec_6d.shape :  torch.Size([73, 6])
ind.shape :  torch.Size([1, 73, 2])
bi :  0
si.shape :  torch.Size([73])
ti.shape :  torch.Size([73])
s_pos.shape :  torch.Size([73, 3])
t_pos.shape :  torch.Size([73, 3])
ind.shape :  torch.Size([1, 73, 2])
bi :  0
si.shape :  torch.Size([73])
ti.shape :  torch.Size([73])
s_pos.shape :  torch.Size([73, 3])
t_pos.shape :  torch.Size([73, 3])
number of true landmarks correspondences returned from KNN matching :  1  out of  73
fraction of true landmark correspondences returned from KNN matching :  0.0136986301369863
vec6d.shape :  torch.Size([73, 6])
ldmk_s.shape :  torch.Size([73, 3])
ldmk_t.shape :  torch.Size([73, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([73, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 11.652 
full-AccS: 0.058 
full-AccR: 2.039 
full-outlier: 62.820 
vis-epe: 14.570 
vis-AccS: 0.000 
vis-AccR: 0.921 
vis-outlier: 74.616 
occ-epe: 9.371 
occ-AccS: 0.103 
occ-AccR: 2.913 
occ-outlier: 53.598 

Actual rotation :  [[-0.08515318 -0.0477966  -0.99522079]
 [-0.17928303  0.98328076 -0.03188333]
 [ 0.98010537  0.17571123 -0.0922986 ]]
Actual translation :  [ 0.67656808  0.74129062 -0.19986074]
Predicted rotation :  [[ 0.89402181  0.36977673  0.25296273]
 [-0.119568    0.74106591 -0.66070021]
 [-0.43177363  0.56043419  0.70674261]]
Predicted translation :  [-0.02031422 -0.00768469 -0.05377609]
Relative Rotation Error :  2.0739145323838115
Relative Translation Error :  1.0334165087923322
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.09403739570592415
Strict IR :  0.004039238315060588
Relaxed IR :  0.05174071936910944
model 126 file1 020 file2 104
0 to 1
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[128, 132]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([260, 2048])
block_i :  1
x.shape :  torch.Size([260, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 260])
coarse_feats.shape :  torch.Size([1, 528, 260])
coarse_feats.shape :  torch.Size([260, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 128])
tgt_mask.shape :  torch.Size([1, 132])
src_ind_coarse_split.shape :  torch.Size([128])
tgt_ind_coarse_split.shape :  torch.Size([132])
src_ind_coarse.shape :  torch.Size([128])
tgt_ind_coarse.shape :  torch.Size([132])
src_feats.shape :  torch.Size([1, 128, 528])
tgt_feats.shape :  torch.Size([1, 132, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([128, 528])
F1.shape : torch.Size([132, 528])
ldmk_t_indices :  tensor([ 10,  44,  10, 124, 124,  27,  39,  41,  44,  18,  82,  89,  85,  85,
         82,  18,  85,  98,  39,  70, 124,  39,  18,  18,  89,  18,  10,  52,
        103,  39,  92,  52,  82,  41, 124,  96,  59, 111,  20,  89,  34,  80,
         89,  98,  27,  89,  34,  82,  98,  27,  41,  18,  98,  18,  82,  98,
         86,  66,  18,   4,  77, 102,  34, 111,  59,   4,  80,  34,  50,  62,
         72,  86,  98,  98,  86,  64,  85,  44,  18,  98,  86,  34, 125,  82,
         10,  82,  64,  14,  54, 124,  89,  89,  79,  89,  26,  98,  82,  10,
         79,  41, 126,  82,  27, 124,  72,  34, 100,  39,  41,  80,  95,  10,
         27, 102,  62, 100,  85,  89,  39,  10,  64,  39,  86, 124,  39,  89,
         26,  23], device='cuda:0')
ldmk_s.shape :  torch.Size([128, 3])
ldmk_t.shape :  torch.Size([128, 3])
vec_6d.shape :  torch.Size([128, 6])
ind.shape :  torch.Size([1, 128, 2])
bi :  0
si.shape :  torch.Size([128])
ti.shape :  torch.Size([128])
s_pos.shape :  torch.Size([128, 3])
t_pos.shape :  torch.Size([128, 3])
ind.shape :  torch.Size([1, 128, 2])
bi :  0
si.shape :  torch.Size([128])
ti.shape :  torch.Size([128])
s_pos.shape :  torch.Size([128, 3])
t_pos.shape :  torch.Size([128, 3])
number of true landmarks correspondences returned from KNN matching :  3  out of  128
fraction of true landmark correspondences returned from KNN matching :  0.0234375
vec6d.shape :  torch.Size([128, 6])
ldmk_s.shape :  torch.Size([128, 3])
ldmk_t.shape :  torch.Size([128, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([128, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 18.065 
full-AccS: 0.000 
full-AccR: 0.400 
full-outlier: 98.596 
vis-epe: 23.608 
vis-AccS: 0.000 
vis-AccR: 0.254 
vis-outlier: 98.834 
occ-epe: 10.689 
occ-AccS: 0.000 
occ-AccR: 0.593 
occ-outlier: 98.279 

Actual rotation :  [[-0.81564788 -0.06094346 -0.57532984]
 [ 0.57678234 -0.16330348 -0.80040871]
 [-0.04517368 -0.98469176  0.16834925]]
Actual translation :  [0.89703757 1.00050158 0.50390294]
Predicted rotation :  [[ 0.78056452 -0.15540366 -0.6054491 ]
 [ 0.00702879  0.97072308 -0.24009862]
 [ 0.62503571  0.18315687  0.75880441]]
Predicted translation :  [ 0.05133087 -0.01522938 -0.04818387]
Relative Rotation Error :  2.2929452516470077
Relative Translation Error :  1.432385788890521
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.10868478647617166
Strict IR :  0.0
Relaxed IR :  0.051452784503631964
model 167 file1 020 file2 104
0 to 1
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[61, 52]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([113, 2048])
block_i :  1
x.shape :  torch.Size([113, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 113])
coarse_feats.shape :  torch.Size([1, 528, 113])
coarse_feats.shape :  torch.Size([113, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 61])
tgt_mask.shape :  torch.Size([1, 52])
src_ind_coarse_split.shape :  torch.Size([61])
tgt_ind_coarse_split.shape :  torch.Size([52])
src_ind_coarse.shape :  torch.Size([61])
tgt_ind_coarse.shape :  torch.Size([52])
src_feats.shape :  torch.Size([1, 61, 528])
tgt_feats.shape :  torch.Size([1, 52, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([61, 528])
F1.shape : torch.Size([52, 528])
ldmk_t_indices :  tensor([33,  8, 36, 36, 18, 14, 33, 36, 23, 10, 34, 45, 26, 16, 47, 17, 33, 31,
        34, 45, 31, 16, 48,  7, 24, 42, 46, 32, 30, 29, 33, 36, 17, 14, 19, 36,
        36, 46,  9, 24, 45, 32, 15, 14, 34, 39,  8, 17, 14, 14, 17, 34, 34, 29,
         8, 36, 42,  8, 32,  8, 36], device='cuda:0')
ldmk_s.shape :  torch.Size([61, 3])
ldmk_t.shape :  torch.Size([61, 3])
vec_6d.shape :  torch.Size([61, 6])
ind.shape :  torch.Size([1, 61, 2])
bi :  0
si.shape :  torch.Size([61])
ti.shape :  torch.Size([61])
s_pos.shape :  torch.Size([61, 3])
t_pos.shape :  torch.Size([61, 3])
ind.shape :  torch.Size([1, 61, 2])
bi :  0
si.shape :  torch.Size([61])
ti.shape :  torch.Size([61])
s_pos.shape :  torch.Size([61, 3])
t_pos.shape :  torch.Size([61, 3])
number of true landmarks correspondences returned from KNN matching :  2  out of  61
fraction of true landmark correspondences returned from KNN matching :  0.03278688524590164
vec6d.shape :  torch.Size([61, 6])
ldmk_s.shape :  torch.Size([61, 3])
ldmk_t.shape :  torch.Size([61, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([61, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 12.193 
full-AccS: 0.000 
full-AccR: 0.230 
full-outlier: 99.388 
vis-epe: 14.818 
vis-AccS: 0.000 
vis-AccR: 0.316 
vis-outlier: 99.007 
occ-epe: 8.778 
occ-AccS: 0.000 
occ-AccR: 0.117 
occ-outlier: 99.883 

Actual rotation :  [[-0.81029619  0.58572329  0.0186628 ]
 [ 0.42981428  0.61565456 -0.66047646]
 [-0.39834628 -0.52716002 -0.75061478]]
Actual translation :  [0.2961076  0.17846237 1.41276713]
Predicted rotation :  [[ 0.91403269 -0.37490585  0.15488608]
 [ 0.40319817  0.79785619 -0.44817031]
 [ 0.04444484  0.47209214  0.88042811]]
Predicted translation :  [-0.00441018  0.01554792  0.01609313]
Relative Rotation Error :  2.8655122577826555
Relative Translation Error :  1.4378978793129003
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.07951749066045027
Strict IR :  0.0
Relaxed IR :  0.042102577188058175
model 207 file1 020 file2 104
0 to 1
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[51, 52]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([103, 2048])
block_i :  1
x.shape :  torch.Size([103, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 103])
coarse_feats.shape :  torch.Size([1, 528, 103])
coarse_feats.shape :  torch.Size([103, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 51])
tgt_mask.shape :  torch.Size([1, 52])
src_ind_coarse_split.shape :  torch.Size([51])
tgt_ind_coarse_split.shape :  torch.Size([52])
src_ind_coarse.shape :  torch.Size([51])
tgt_ind_coarse.shape :  torch.Size([52])
src_feats.shape :  torch.Size([1, 51, 528])
tgt_feats.shape :  torch.Size([1, 52, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([51, 528])
F1.shape : torch.Size([52, 528])
ldmk_t_indices :  tensor([36, 11,  4,  4, 11, 46, 36, 42, 36, 22, 36, 38,  6, 43, 43, 11,  6, 51,
        38, 20, 36, 42, 42,  6,  6, 38, 42, 34,  2, 11, 38, 39, 38, 35, 11,  3,
        43,  2, 38, 51,  9, 11,  6, 16, 34, 51,  2,  2, 38, 30, 38],
       device='cuda:0')
ldmk_s.shape :  torch.Size([51, 3])
ldmk_t.shape :  torch.Size([51, 3])
vec_6d.shape :  torch.Size([51, 6])
ind.shape :  torch.Size([1, 51, 2])
bi :  0
si.shape :  torch.Size([51])
ti.shape :  torch.Size([51])
s_pos.shape :  torch.Size([51, 3])
t_pos.shape :  torch.Size([51, 3])
ind.shape :  torch.Size([1, 51, 2])
bi :  0
si.shape :  torch.Size([51])
ti.shape :  torch.Size([51])
s_pos.shape :  torch.Size([51, 3])
t_pos.shape :  torch.Size([51, 3])
number of true landmarks correspondences returned from KNN matching :  2  out of  51
fraction of true landmark correspondences returned from KNN matching :  0.0392156862745098
vec6d.shape :  torch.Size([51, 6])
ldmk_s.shape :  torch.Size([51, 3])
ldmk_t.shape :  torch.Size([51, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([51, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 10.174 
full-AccS: 0.000 
full-AccR: 6.297 
full-outlier: 35.384 
vis-epe: 13.500 
vis-AccS: 0.000 
vis-AccR: 0.523 
vis-outlier: 58.667 
occ-epe: 6.007 
occ-AccS: 0.000 
occ-AccR: 13.530 
occ-outlier: 6.219 

Actual rotation :  [[-0.32787446  0.25529739 -0.9095722 ]
 [ 0.93634976  0.21570775 -0.27698246]
 [ 0.12548888 -0.94249319 -0.30977271]]
Actual translation :  [0.74584319 0.0201462  0.21741575]
Predicted rotation :  [[ 0.69133062 -0.54562346 -0.47366341]
 [ 0.67043356  0.7288416   0.1389556 ]
 [ 0.26940828 -0.41362417  0.86967494]]
Predicted translation :  [-0.05467463  0.10605914  0.0300646 ]
Relative Rotation Error :  1.5879981094217768
Relative Translation Error :  0.8266258284196307
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.0636493923385957
Strict IR :  0.0
Relaxed IR :  0.17122790021797046
