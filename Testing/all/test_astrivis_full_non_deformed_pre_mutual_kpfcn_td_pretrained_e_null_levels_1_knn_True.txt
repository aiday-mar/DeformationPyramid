model 002
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[156, 163]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([319, 2048])
block_i :  1
x.shape :  torch.Size([319, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 319])
coarse_feats.shape :  torch.Size([1, 528, 319])
coarse_feats.shape :  torch.Size([319, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 156])
tgt_mask.shape :  torch.Size([1, 163])
src_ind_coarse_split.shape :  torch.Size([156])
tgt_ind_coarse_split.shape :  torch.Size([163])
src_ind_coarse.shape :  torch.Size([156])
tgt_ind_coarse.shape :  torch.Size([163])
src_feats.shape :  torch.Size([1, 156, 528])
tgt_feats.shape :  torch.Size([1, 163, 528])
confidence threshold used in the matching :  0.1
preprocessing :  mutual
confidence threshold used in the matching :  0.1
preprocessing :  mutual
F0.shape : torch.Size([156, 528])
F1.shape : torch.Size([163, 528])
ldmk_t_indices :  tensor([ 66,  66,  66,  14,  25,  19,  51,  53,  63, 152,  15,  27,  20, 162,
        124,  33,  52,  27,  51, 149,   4,  61,  58,  51,  33,  19,  11, 134,
         24,  51,  33,  25,  52, 159,  70,  33,  54,  29,  15,  59,  29,  59,
         33,  24,  19,  57, 159,  70,  53,  19, 140,  52,  20, 134,  40,  50,
        146,  71, 146, 140,  44,  52,  12,  19,  44,   2,  51,  11,  94,  68,
        130, 112,  44, 118, 140, 131, 118, 114,  90,  31, 130, 140, 152,  54,
        118,  54,  12,   9, 124,  91,  19,  56, 162, 154,  32, 102,  27, 118,
          3, 114,  27, 104,  93,  91,  19, 102,  12,  31,  21,  84,  94,  53,
        142,  56,  96,  93, 104, 103,  19, 109, 161,  37, 131, 122, 142,  68,
         65,   6,  94, 140, 122, 140, 122, 142, 117,  94, 100, 145,  53, 146,
         92,  31, 146, 130,  94,   6, 152,  90,   6, 140, 146,  70, 146,   7,
          1,  30], device='cuda:0')
ldmk_s.shape :  torch.Size([156, 3])
ldmk_t.shape :  torch.Size([156, 3])
vec_6d.shape :  torch.Size([156, 6])
ind.shape :  torch.Size([1, 156, 2])
bi :  0
si.shape :  torch.Size([156])
ti.shape :  torch.Size([156])
s_pos.shape :  torch.Size([156, 3])
t_pos.shape :  torch.Size([156, 3])
ind.shape :  torch.Size([1, 156, 2])
bi :  0
si.shape :  torch.Size([156])
ti.shape :  torch.Size([156])
s_pos.shape :  torch.Size([156, 3])
t_pos.shape :  torch.Size([156, 3])
number of true landmarks correspondences returned from KNN matching :  38  out of  156
fraction of true landmark correspondences returned from KNN matching :  0.24358974358974358
vec6d.shape :  torch.Size([156, 6])
ldmk_s.shape :  torch.Size([156, 3])
ldmk_t.shape :  torch.Size([156, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([156, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 18.061 
full-AccS: 0.136 
full-AccR: 1.068 
full-outlier: 93.099 
vis-epe: 18.061 
vis-AccS: 0.136 
vis-AccR: 1.068 
vis-outlier: 93.099 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[-0.53486491 -0.60002104  0.59489014]
 [-0.74890142  0.66266287 -0.00495792]
 [-0.39123675 -0.44816589 -0.80379173]]
Actual translation :  [0.89692495 0.43777249 1.20478005]
Predicted rotation :  [[-0.55696869 -0.60525906  0.56872445]
 [-0.66942286  0.73247004  0.12393811]
 [-0.49158829 -0.3116875  -0.81313717]]
Predicted translation :  [-0.00615139 -0.01095963 -0.01824151]
Relative Rotation Error :  0.17018839961531906
Relative Translation Error :  1.5851464001674138
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.028302471137637203
Strict IR :  0.008138351983723296
Relaxed IR :  0.5652763648694473
model 042
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[123, 130]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([253, 2048])
block_i :  1
x.shape :  torch.Size([253, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 253])
coarse_feats.shape :  torch.Size([1, 528, 253])
coarse_feats.shape :  torch.Size([253, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 123])
tgt_mask.shape :  torch.Size([1, 130])
src_ind_coarse_split.shape :  torch.Size([123])
tgt_ind_coarse_split.shape :  torch.Size([130])
src_ind_coarse.shape :  torch.Size([123])
tgt_ind_coarse.shape :  torch.Size([130])
src_feats.shape :  torch.Size([1, 123, 528])
tgt_feats.shape :  torch.Size([1, 130, 528])
confidence threshold used in the matching :  0.1
preprocessing :  mutual
confidence threshold used in the matching :  0.1
preprocessing :  mutual
F0.shape : torch.Size([123, 528])
F1.shape : torch.Size([130, 528])
ldmk_t_indices :  tensor([ 12,  14,  79,  47, 119,  87,  87,  36,  74, 119, 122, 109,  84,  87,
        119, 113, 106,  29,  84, 102,  94,  30,  46,  54,  35,  54,  24,  64,
         46,  23,  40,  43,  94,  40,  53,  64,  66,  67, 115,  45,  10, 122,
         26,  61,   7,  38,  53,  57,  57,  32,  54,  54, 102,  57, 125,  50,
        125,  77,  30,  94,  72,  12,  58,  28,  53,  72,  67, 121,  31, 122,
        115,  64,  14,  40,  61,  86,  86,   7,  44, 126,   7,  14,   1,  46,
         14,  14,  77,  79,  28,  64, 100,  92,   9,   8,  77, 113, 117,  35,
         23,  35,  67,  95,  57, 120,  45, 106,  87, 117,  10,  32,  71,  24,
         62,  28,  79, 120,  87,  57, 122,  45,  12,   5,  35],
       device='cuda:0')
ldmk_s.shape :  torch.Size([123, 3])
ldmk_t.shape :  torch.Size([123, 3])
vec_6d.shape :  torch.Size([123, 6])
ind.shape :  torch.Size([1, 123, 2])
bi :  0
si.shape :  torch.Size([123])
ti.shape :  torch.Size([123])
s_pos.shape :  torch.Size([123, 3])
t_pos.shape :  torch.Size([123, 3])
ind.shape :  torch.Size([1, 123, 2])
bi :  0
si.shape :  torch.Size([123])
ti.shape :  torch.Size([123])
s_pos.shape :  torch.Size([123, 3])
t_pos.shape :  torch.Size([123, 3])
number of true landmarks correspondences returned from KNN matching :  38  out of  123
fraction of true landmark correspondences returned from KNN matching :  0.3089430894308943
vec6d.shape :  torch.Size([123, 6])
ldmk_s.shape :  torch.Size([123, 3])
ldmk_t.shape :  torch.Size([123, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([123, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 13.405 
full-AccS: 0.292 
full-AccR: 3.340 
full-outlier: 90.647 
vis-epe: 13.405 
vis-AccS: 0.292 
vis-AccR: 3.340 
vis-outlier: 90.647 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[-0.40066553 -0.11995433 -0.90833809]
 [ 0.24675989  0.94063308 -0.23306431]
 [ 0.88236993 -0.31752224 -0.34727933]]
Actual translation :  [1.20244689 0.33445861 0.35577331]
Predicted rotation :  [[-0.28154278 -0.14313029 -0.94881374]
 [ 0.27501124  0.93529439 -0.22269529]
 [ 0.91929466 -0.32363266 -0.22396302]]
Predicted translation :  [-0.02253422  0.00086614 -0.01380236]
Relative Rotation Error :  0.13029811706087016
Relative Translation Error :  1.3222892331943414
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.028514556975161216
Strict IR :  0.0
Relaxed IR :  0.6088910482205757
model 085
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[88, 89]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([177, 2048])
block_i :  1
x.shape :  torch.Size([177, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 177])
coarse_feats.shape :  torch.Size([1, 528, 177])
coarse_feats.shape :  torch.Size([177, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 88])
tgt_mask.shape :  torch.Size([1, 89])
src_ind_coarse_split.shape :  torch.Size([88])
tgt_ind_coarse_split.shape :  torch.Size([89])
src_ind_coarse.shape :  torch.Size([88])
tgt_ind_coarse.shape :  torch.Size([89])
src_feats.shape :  torch.Size([1, 88, 528])
tgt_feats.shape :  torch.Size([1, 89, 528])
confidence threshold used in the matching :  0.1
preprocessing :  mutual
confidence threshold used in the matching :  0.1
preprocessing :  mutual
F0.shape : torch.Size([88, 528])
F1.shape : torch.Size([89, 528])
ldmk_t_indices :  tensor([84,  9, 42,  9, 57, 69,  9,  0,  7,  7, 69, 66, 82, 77, 25,  9,  9, 21,
        30,  5, 62,  9,  2, 86, 77,  9, 77, 48, 14, 67, 21, 74,  5, 53, 19,  5,
         9, 39,  1, 17, 12, 39, 30, 25, 49, 25, 49, 53, 77, 50, 33, 30, 77, 14,
        50,  3, 65, 33, 30, 77, 75, 20, 21, 70, 21, 70, 39,  9, 48, 82,  0, 19,
        27, 19, 75, 37, 81, 48,  0,  9,  4, 37, 86, 19, 34,  0,  1,  0],
       device='cuda:0')
ldmk_s.shape :  torch.Size([88, 3])
ldmk_t.shape :  torch.Size([88, 3])
vec_6d.shape :  torch.Size([88, 6])
ind.shape :  torch.Size([1, 88, 2])
bi :  0
si.shape :  torch.Size([88])
ti.shape :  torch.Size([88])
s_pos.shape :  torch.Size([88, 3])
t_pos.shape :  torch.Size([88, 3])
ind.shape :  torch.Size([1, 88, 2])
bi :  0
si.shape :  torch.Size([88])
ti.shape :  torch.Size([88])
s_pos.shape :  torch.Size([88, 3])
t_pos.shape :  torch.Size([88, 3])
number of true landmarks correspondences returned from KNN matching :  30  out of  88
fraction of true landmark correspondences returned from KNN matching :  0.3409090909090909
vec6d.shape :  torch.Size([88, 6])
ldmk_s.shape :  torch.Size([88, 3])
ldmk_t.shape :  torch.Size([88, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([88, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 17.717 
full-AccS: 0.000 
full-AccR: 0.490 
full-outlier: 98.886 
vis-epe: 17.717 
vis-AccS: 0.000 
vis-AccR: 0.490 
vis-outlier: 98.886 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[ 0.76902396  0.10084417  0.63121518]
 [-0.46095699 -0.59664159  0.65691511]
 [ 0.44285529 -0.79614651 -0.41234685]]
Actual translation :  [-0.53063257  0.48585253  1.09298804]
Predicted rotation :  [[ 0.34057015  0.80171037  0.4911949 ]
 [-0.83013296  0.01110065  0.55745488]
 [ 0.44146478 -0.59760958  0.66930681]]
Predicted translation :  [ 0.03578959  0.01226506 -0.05312765]
Relative Rotation Error :  1.164543226429269
Relative Translation Error :  1.3633416050856453
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.10708946264274319
Strict IR :  0.0
Relaxed IR :  0.03208556149732621
model 126
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[142, 137]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([279, 2048])
block_i :  1
x.shape :  torch.Size([279, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 279])
coarse_feats.shape :  torch.Size([1, 528, 279])
coarse_feats.shape :  torch.Size([279, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 142])
tgt_mask.shape :  torch.Size([1, 137])
src_ind_coarse_split.shape :  torch.Size([142])
tgt_ind_coarse_split.shape :  torch.Size([137])
src_ind_coarse.shape :  torch.Size([142])
tgt_ind_coarse.shape :  torch.Size([137])
src_feats.shape :  torch.Size([1, 142, 528])
tgt_feats.shape :  torch.Size([1, 137, 528])
confidence threshold used in the matching :  0.1
preprocessing :  mutual
confidence threshold used in the matching :  0.1
preprocessing :  mutual
F0.shape : torch.Size([142, 528])
F1.shape : torch.Size([137, 528])
ldmk_t_indices :  tensor([113, 113,  91, 113, 113,  23,  59,  18, 131, 131, 109, 129,  37,  64,
         81,  28,  31, 129, 110,  28, 125,  91,  23,  30,  40,  59, 101, 110,
         40,  79,  64, 128,  30, 123, 117, 119, 128,   6, 113,  73, 115,  17,
         43, 128,  85,  51,  49, 126, 133, 122,  51, 123,  30, 113,  54,  68,
         49,  59,  91,  60,  63, 103,  18,  63,  60,  53,  61,  69,  84,  85,
        110,  79,  96,  60,  73,  61,  95,  96,  99,  99,  81,   3,  47, 108,
         39,  75,  95,  79,  72,  95,  72,  49,  32,  95,  88,  73,  79, 131,
         63, 103,  53,  26, 125,  81,  50,  34,  81,  47, 104,  52,  47,  75,
         26,  47,  79, 101, 106,  49, 102, 107,  97,  47,   1, 127,  82, 126,
        128,  67,  75,  51, 103,  54,  51,  51, 126, 118, 128, 113,  62,  49,
        113,  33], device='cuda:0')
ldmk_s.shape :  torch.Size([142, 3])
ldmk_t.shape :  torch.Size([142, 3])
vec_6d.shape :  torch.Size([142, 6])
ind.shape :  torch.Size([1, 142, 2])
bi :  0
si.shape :  torch.Size([142])
ti.shape :  torch.Size([142])
s_pos.shape :  torch.Size([142, 3])
t_pos.shape :  torch.Size([142, 3])
ind.shape :  torch.Size([1, 142, 2])
bi :  0
si.shape :  torch.Size([142])
ti.shape :  torch.Size([142])
s_pos.shape :  torch.Size([142, 3])
t_pos.shape :  torch.Size([142, 3])
number of true landmarks correspondences returned from KNN matching :  44  out of  142
fraction of true landmark correspondences returned from KNN matching :  0.30985915492957744
vec6d.shape :  torch.Size([142, 6])
ldmk_s.shape :  torch.Size([142, 3])
ldmk_t.shape :  torch.Size([142, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([142, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 19.693 
full-AccS: 0.084 
full-AccR: 0.868 
full-outlier: 93.323 
vis-epe: 19.693 
vis-AccS: 0.084 
vis-AccR: 0.868 
vis-outlier: 93.323 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[ 0.63814927 -0.15503533 -0.7541416 ]
 [-0.61475232 -0.69230752 -0.37787548]
 [-0.46351385  0.70475126 -0.53710387]]
Actual translation :  [0.96696898 0.79531393 0.98999611]
Predicted rotation :  [[ 0.59196693 -0.14625119 -0.79258168]
 [-0.5976218  -0.73946416 -0.30990475]
 [-0.54076183  0.65711749 -0.52514124]]
Predicted translation :  [-0.00517652 -0.01308147 -0.01385647]
Relative Rotation Error :  0.0980293217935339
Relative Translation Error :  1.6144008182604233
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.021783768453019433
Strict IR :  0.020716685330347144
Relaxed IR :  0.9617861142217246
model 167
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[64, 60]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([124, 2048])
block_i :  1
x.shape :  torch.Size([124, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 124])
coarse_feats.shape :  torch.Size([1, 528, 124])
coarse_feats.shape :  torch.Size([124, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 64])
tgt_mask.shape :  torch.Size([1, 60])
src_ind_coarse_split.shape :  torch.Size([64])
tgt_ind_coarse_split.shape :  torch.Size([60])
src_ind_coarse.shape :  torch.Size([64])
tgt_ind_coarse.shape :  torch.Size([60])
src_feats.shape :  torch.Size([1, 64, 528])
tgt_feats.shape :  torch.Size([1, 60, 528])
confidence threshold used in the matching :  0.1
preprocessing :  mutual
confidence threshold used in the matching :  0.1
preprocessing :  mutual
F0.shape : torch.Size([64, 528])
F1.shape : torch.Size([60, 528])
ldmk_t_indices :  tensor([27,  8, 59, 12, 14, 44,  6, 10, 27,  2, 12, 59, 18, 27, 54, 56, 48, 14,
        12, 12, 10, 27, 48, 10,  8, 46, 12, 53, 49, 40, 27, 12, 12, 40,  8, 46,
        12, 33,  8, 12, 40, 12, 30, 46, 12, 53, 54, 45, 51, 18, 21, 21, 48, 12,
        14, 16, 21,  8, 14, 54, 56, 27, 53, 21], device='cuda:0')
ldmk_s.shape :  torch.Size([64, 3])
ldmk_t.shape :  torch.Size([64, 3])
vec_6d.shape :  torch.Size([64, 6])
ind.shape :  torch.Size([1, 64, 2])
bi :  0
si.shape :  torch.Size([64])
ti.shape :  torch.Size([64])
s_pos.shape :  torch.Size([64, 3])
t_pos.shape :  torch.Size([64, 3])
ind.shape :  torch.Size([1, 64, 2])
bi :  0
si.shape :  torch.Size([64])
ti.shape :  torch.Size([64])
s_pos.shape :  torch.Size([64, 3])
t_pos.shape :  torch.Size([64, 3])
number of true landmarks correspondences returned from KNN matching :  18  out of  64
fraction of true landmark correspondences returned from KNN matching :  0.28125
vec6d.shape :  torch.Size([64, 6])
ldmk_s.shape :  torch.Size([64, 3])
ldmk_t.shape :  torch.Size([64, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([64, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 7.079 
full-AccS: 0.498 
full-AccR: 18.649 
full-outlier: 27.460 
vis-epe: 7.079 
vis-AccS: 0.498 
vis-AccR: 18.649 
vis-outlier: 27.460 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[ 0.39671545  0.36679516 -0.8414738 ]
 [-0.57527497  0.81369012  0.08346918]
 [ 0.71531501  0.4509653   0.53381151]]
Actual translation :  [ 0.05762421 -0.46980197  0.32040084]
Predicted rotation :  [[ 0.80950832  0.2229261  -0.54313934]
 [-0.40638915  0.88042635 -0.24433035]
 [ 0.42372662  0.41851336  0.80330718]]
Predicted translation :  [-0.02325677 -0.02464079  0.03700268]
Relative Rotation Error :  0.5448756524703898
Relative Translation Error :  0.5338770695635338
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.06177870748017361
Strict IR :  0.0
Relaxed IR :  0.09090909090909091
model 207
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[70, 65]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([135, 2048])
block_i :  1
x.shape :  torch.Size([135, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 135])
coarse_feats.shape :  torch.Size([1, 528, 135])
coarse_feats.shape :  torch.Size([135, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 70])
tgt_mask.shape :  torch.Size([1, 65])
src_ind_coarse_split.shape :  torch.Size([70])
tgt_ind_coarse_split.shape :  torch.Size([65])
src_ind_coarse.shape :  torch.Size([70])
tgt_ind_coarse.shape :  torch.Size([65])
src_feats.shape :  torch.Size([1, 70, 528])
tgt_feats.shape :  torch.Size([1, 65, 528])
confidence threshold used in the matching :  0.1
preprocessing :  mutual
confidence threshold used in the matching :  0.1
preprocessing :  mutual
F0.shape : torch.Size([70, 528])
F1.shape : torch.Size([65, 528])
ldmk_t_indices :  tensor([53, 44, 44, 44, 16, 22, 12, 29,  4,  4, 59, 29,  4, 16, 21, 16, 35, 18,
        53, 43, 22, 19,  4, 47, 43, 50, 51, 45, 32, 16, 19, 19, 29, 43, 34, 50,
        29, 44, 34, 32, 48, 22, 29, 22,  4, 32, 40, 22, 29, 46, 29,  4, 22, 40,
        43, 47, 16, 29, 53, 46, 16, 51,  4, 52, 48, 40, 53, 51, 53, 43],
       device='cuda:0')
ldmk_s.shape :  torch.Size([70, 3])
ldmk_t.shape :  torch.Size([70, 3])
vec_6d.shape :  torch.Size([70, 6])
ind.shape :  torch.Size([1, 70, 2])
bi :  0
si.shape :  torch.Size([70])
ti.shape :  torch.Size([70])
s_pos.shape :  torch.Size([70, 3])
t_pos.shape :  torch.Size([70, 3])
ind.shape :  torch.Size([1, 70, 2])
bi :  0
si.shape :  torch.Size([70])
ti.shape :  torch.Size([70])
s_pos.shape :  torch.Size([70, 3])
t_pos.shape :  torch.Size([70, 3])
number of true landmarks correspondences returned from KNN matching :  15  out of  70
fraction of true landmark correspondences returned from KNN matching :  0.21428571428571427
vec6d.shape :  torch.Size([70, 6])
ldmk_s.shape :  torch.Size([70, 3])
ldmk_t.shape :  torch.Size([70, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([70, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 14.622 
full-AccS: 0.140 
full-AccR: 2.966 
full-outlier: 96.232 
vis-epe: 14.622 
vis-AccS: 0.140 
vis-AccR: 2.966 
vis-outlier: 96.232 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[-0.69578084  0.62399956  0.35568745]
 [ 0.66485052  0.37215059  0.64767101]
 [ 0.27177713  0.68711606 -0.67380168]]
Actual translation :  [ 0.44784053 -0.19352481 -0.1776428 ]
Predicted rotation :  [[-0.66214907  0.66170728 -0.35171339]
 [ 0.43793064  0.72254723  0.53492266]
 [ 0.60809171  0.20017235 -0.76821589]]
Predicted translation :  [ 0.03363461  0.0014251  -0.02092576]
Relative Rotation Error :  0.741097205961548
Relative Translation Error :  0.4838721339506523
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.060255892378402
Strict IR :  0.0
Relaxed IR :  0.16608513607815772
