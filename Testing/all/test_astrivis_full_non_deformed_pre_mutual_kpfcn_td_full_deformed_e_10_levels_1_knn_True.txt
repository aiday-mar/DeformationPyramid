model 002
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[156, 163]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([319, 2048])
block_i :  1
x.shape :  torch.Size([319, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 319])
coarse_feats.shape :  torch.Size([1, 528, 319])
coarse_feats.shape :  torch.Size([319, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 156])
tgt_mask.shape :  torch.Size([1, 163])
src_ind_coarse_split.shape :  torch.Size([156])
tgt_ind_coarse_split.shape :  torch.Size([163])
src_ind_coarse.shape :  torch.Size([156])
tgt_ind_coarse.shape :  torch.Size([163])
src_feats.shape :  torch.Size([1, 156, 528])
tgt_feats.shape :  torch.Size([1, 163, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([156, 528])
F1.shape : torch.Size([163, 528])
ldmk_t_indices :  tensor([ 52, 156,  52,  52,  44, 103, 156, 156,  63, 156,  24,  63, 139,  52,
        124,  26,  52,  39,  24,  30,  68,  24, 148,  39,  26,  52,  65,  66,
         24,  65,  26,  44,  43,  87, 137,  26, 107,  15,  15,  63,  15,  24,
         26,  24, 154, 100, 154,  65,  91, 100, 136,  65, 100,  30,  61, 160,
        148, 156, 121, 160,  62,  41, 124,  60,  52, 100,  24, 100,  58, 156,
         30, 124,  54, 137, 136,   6, 137,  12, 137,   6,  30, 121,   4, 107,
        137, 107, 137, 143, 127,  12,  12,  56,  12, 154, 107,  72, 107, 121,
         65,  12, 107, 161,  12,  56, 127, 124, 127,  37,  24, 124,  58, 103,
          5,  44,  30,  12, 137,  56,  99,  11, 127,  63, 120,  30, 121,  39,
         12,   6, 137, 144,  30, 121,  30, 100,   4,  58, 121, 152,  99,   6,
         43, 156, 121,  30, 143, 120, 156,  58, 136,   5, 143,  65, 121, 156,
          1,  52], device='cuda:0')
ldmk_s.shape :  torch.Size([156, 3])
ldmk_t.shape :  torch.Size([156, 3])
vec_6d.shape :  torch.Size([156, 6])
ind.shape :  torch.Size([1, 156, 2])
bi :  0
si.shape :  torch.Size([156])
ti.shape :  torch.Size([156])
s_pos.shape :  torch.Size([156, 3])
t_pos.shape :  torch.Size([156, 3])
ind.shape :  torch.Size([1, 156, 2])
bi :  0
si.shape :  torch.Size([156])
ti.shape :  torch.Size([156])
s_pos.shape :  torch.Size([156, 3])
t_pos.shape :  torch.Size([156, 3])
number of true landmarks correspondences returned from KNN matching :  15  out of  156
fraction of true landmark correspondences returned from KNN matching :  0.09615384615384616
vec6d.shape :  torch.Size([156, 6])
ldmk_s.shape :  torch.Size([156, 3])
ldmk_t.shape :  torch.Size([156, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([156, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 18.786 
full-AccS: 0.102 
full-AccR: 1.102 
full-outlier: 94.252 
vis-epe: 18.786 
vis-AccS: 0.102 
vis-AccR: 1.102 
vis-outlier: 94.252 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[-0.53486491 -0.60002104  0.59489014]
 [-0.74890142  0.66266287 -0.00495792]
 [-0.39123675 -0.44816589 -0.80379173]]
Actual translation :  [0.89692495 0.43777249 1.20478005]
Predicted rotation :  [[-0.37856364 -0.55104852  0.74366319]
 [-0.85856104  0.50922096 -0.05972394]
 [-0.34577808 -0.66108966 -0.66588128]]
Predicted translation :  [-0.01634349 -0.00485905  0.00929201]
Relative Rotation Error :  0.2783444017508888
Relative Translation Error :  1.5681752347988078
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.035007216000930895
Strict IR :  0.0
Relaxed IR :  0.40098338419803325
model 042
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[123, 130]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([253, 2048])
block_i :  1
x.shape :  torch.Size([253, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 253])
coarse_feats.shape :  torch.Size([1, 528, 253])
coarse_feats.shape :  torch.Size([253, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 123])
tgt_mask.shape :  torch.Size([1, 130])
src_ind_coarse_split.shape :  torch.Size([123])
tgt_ind_coarse_split.shape :  torch.Size([130])
src_ind_coarse.shape :  torch.Size([123])
tgt_ind_coarse.shape :  torch.Size([130])
src_feats.shape :  torch.Size([1, 123, 528])
tgt_feats.shape :  torch.Size([1, 130, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([123, 528])
F1.shape : torch.Size([130, 528])
ldmk_t_indices :  tensor([ 78, 112,  79, 123, 119, 111, 111, 102,  98, 119,  50, 111, 119, 111,
        119, 119, 108,  29, 108,  29,  10, 102,  56, 111,  48,  54, 102,  34,
         56, 113,  22,  63,  80,  22,  70,  60,  27, 111,  10, 113,  10,  10,
         18,  70,  22,  80,  70, 126,  57, 108,  83,  83, 108,  57,  21,  58,
         26,  56, 123,  89,  72,  78,  44,  48,  67,  58,  70, 123, 123,  72,
        101,  34,  39,  27, 111,  63,  63,  27,  72, 126,  27,  25, 112,  56,
         78, 112,  67,  25,  27,  60,  32,  32,  27,  58,  83, 113, 117,  22,
         80,  22,  78,  47, 126, 102,  47, 102,  87,  58,  10, 108, 111,  48,
        111,  48,  54, 102,  91, 128,  10, 112,  78,   1,  27],
       device='cuda:0')
ldmk_s.shape :  torch.Size([123, 3])
ldmk_t.shape :  torch.Size([123, 3])
vec_6d.shape :  torch.Size([123, 6])
ind.shape :  torch.Size([1, 123, 2])
bi :  0
si.shape :  torch.Size([123])
ti.shape :  torch.Size([123])
s_pos.shape :  torch.Size([123, 3])
t_pos.shape :  torch.Size([123, 3])
ind.shape :  torch.Size([1, 123, 2])
bi :  0
si.shape :  torch.Size([123])
ti.shape :  torch.Size([123])
s_pos.shape :  torch.Size([123, 3])
t_pos.shape :  torch.Size([123, 3])
number of true landmarks correspondences returned from KNN matching :  13  out of  123
fraction of true landmark correspondences returned from KNN matching :  0.10569105691056911
vec6d.shape :  torch.Size([123, 6])
ldmk_s.shape :  torch.Size([123, 3])
ldmk_t.shape :  torch.Size([123, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([123, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 14.177 
full-AccS: 0.194 
full-AccR: 2.089 
full-outlier: 94.316 
vis-epe: 14.177 
vis-AccS: 0.194 
vis-AccR: 2.089 
vis-outlier: 94.316 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[-0.40066553 -0.11995433 -0.90833809]
 [ 0.24675989  0.94063308 -0.23306431]
 [ 0.88236993 -0.31752224 -0.34727933]]
Actual translation :  [1.20244689 0.33445861 0.35577331]
Predicted rotation :  [[ 0.26619363 -0.4827843  -0.83430225]
 [ 0.4861773   0.81461823 -0.31627336]
 [ 0.83232957 -0.32142887  0.45156497]]
Predicted translation :  [0.00610825 0.00730367 0.00498729]
Relative Rotation Error :  0.8307202852610656
Relative Translation Error :  1.2889171076491093
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.056250217389982045
Strict IR :  0.006437507591400462
Relaxed IR :  0.1572938175634641
model 085
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[88, 89]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([177, 2048])
block_i :  1
x.shape :  torch.Size([177, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 177])
coarse_feats.shape :  torch.Size([1, 528, 177])
coarse_feats.shape :  torch.Size([177, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 88])
tgt_mask.shape :  torch.Size([1, 89])
src_ind_coarse_split.shape :  torch.Size([88])
tgt_ind_coarse_split.shape :  torch.Size([89])
src_ind_coarse.shape :  torch.Size([88])
tgt_ind_coarse.shape :  torch.Size([89])
src_feats.shape :  torch.Size([1, 88, 528])
tgt_feats.shape :  torch.Size([1, 89, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([88, 528])
F1.shape : torch.Size([89, 528])
ldmk_t_indices :  tensor([73, 45,  3, 45, 87, 57, 85, 28, 87, 87, 38, 28, 75, 45, 19, 45, 45, 67,
        45, 31, 62, 85,  2, 86, 79, 45, 45, 48, 67, 67, 51, 45, 67, 65, 57, 69,
        45, 77, 65, 10, 67, 77, 84, 69, 87, 84, 87, 67, 85, 87, 84, 77, 45, 87,
        87,  3, 65, 84, 77, 45, 75, 52,  3, 75, 17, 75, 74, 45, 31, 17,  6, 62,
        41, 75, 75,  3, 17, 31,  6, 85,  4, 58, 86, 86,  3, 28,  3, 28],
       device='cuda:0')
ldmk_s.shape :  torch.Size([88, 3])
ldmk_t.shape :  torch.Size([88, 3])
vec_6d.shape :  torch.Size([88, 6])
ind.shape :  torch.Size([1, 88, 2])
bi :  0
si.shape :  torch.Size([88])
ti.shape :  torch.Size([88])
s_pos.shape :  torch.Size([88, 3])
t_pos.shape :  torch.Size([88, 3])
ind.shape :  torch.Size([1, 88, 2])
bi :  0
si.shape :  torch.Size([88])
ti.shape :  torch.Size([88])
s_pos.shape :  torch.Size([88, 3])
t_pos.shape :  torch.Size([88, 3])
number of true landmarks correspondences returned from KNN matching :  8  out of  88
fraction of true landmark correspondences returned from KNN matching :  0.09090909090909091
vec6d.shape :  torch.Size([88, 6])
ldmk_s.shape :  torch.Size([88, 3])
ldmk_t.shape :  torch.Size([88, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([88, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 14.291 
full-AccS: 0.000 
full-AccR: 1.649 
full-outlier: 96.034 
vis-epe: 14.291 
vis-AccS: 0.000 
vis-AccR: 1.649 
vis-outlier: 96.034 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[ 0.76902396  0.10084417  0.63121518]
 [-0.46095699 -0.59664159  0.65691511]
 [ 0.44285529 -0.79614651 -0.41234685]]
Actual translation :  [-0.53063257  0.48585253  1.09298804]
Predicted rotation :  [[ 0.85050535  0.05516672  0.52306527]
 [-0.51972497  0.24089867  0.81966686]
 [-0.08078742 -0.96898115  0.23355711]]
Predicted translation :  [-0.01404203  0.01664381 -0.00680628]
Relative Rotation Error :  0.8870208451951016
Relative Translation Error :  1.3025245304726973
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.069232855075927
Strict IR :  0.0
Relaxed IR :  0.11051693404634581
model 126
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[142, 137]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([279, 2048])
block_i :  1
x.shape :  torch.Size([279, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 279])
coarse_feats.shape :  torch.Size([1, 528, 279])
coarse_feats.shape :  torch.Size([279, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 142])
tgt_mask.shape :  torch.Size([1, 137])
src_ind_coarse_split.shape :  torch.Size([142])
tgt_ind_coarse_split.shape :  torch.Size([137])
src_ind_coarse.shape :  torch.Size([142])
tgt_ind_coarse.shape :  torch.Size([137])
src_feats.shape :  torch.Size([1, 142, 528])
tgt_feats.shape :  torch.Size([1, 137, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([142, 528])
F1.shape : torch.Size([137, 528])
ldmk_t_indices :  tensor([  3,   3, 131, 114, 114, 120,  15,  18,  94,  94, 109,  46,  22,  19,
        124, 112,  22,  46, 110,  28,  36,  52,   7, 122, 112,  78,  94, 110,
         40, 136,  62, 115,  15, 113, 122, 131,  15,  19,   3, 129,  46,  28,
        129, 120, 129, 117,  78,  15, 115,  18,  39, 117,  62,   8,  69,  26,
         71,  15,  52,  75,  83,  99,  18,  88,  26, 124, 124,  90, 124,  22,
         46,  99,  99,  21,  90, 124,  99,  99,  99,  99, 124,   3, 106, 124,
         42,  70,  99, 124,  90,  88, 124,  71,  32,  99,  95, 124,  19,  94,
         83,  45,  90,  32,  36, 124,  62, 117,  90,   0,  39,  27,  65,  42,
          1,   0,  39,  94,   7,  27,  62, 131,  19,   0,  39,   1,  94,  15,
        122,  69,  32,  39,  32,  69,  62,  39,  78, 122,  24, 136, 109,  27,
        136,  15], device='cuda:0')
ldmk_s.shape :  torch.Size([142, 3])
ldmk_t.shape :  torch.Size([142, 3])
vec_6d.shape :  torch.Size([142, 6])
ind.shape :  torch.Size([1, 142, 2])
bi :  0
si.shape :  torch.Size([142])
ti.shape :  torch.Size([142])
s_pos.shape :  torch.Size([142, 3])
t_pos.shape :  torch.Size([142, 3])
ind.shape :  torch.Size([1, 142, 2])
bi :  0
si.shape :  torch.Size([142])
ti.shape :  torch.Size([142])
s_pos.shape :  torch.Size([142, 3])
t_pos.shape :  torch.Size([142, 3])
number of true landmarks correspondences returned from KNN matching :  13  out of  142
fraction of true landmark correspondences returned from KNN matching :  0.09154929577464789
vec6d.shape :  torch.Size([142, 6])
ldmk_s.shape :  torch.Size([142, 3])
ldmk_t.shape :  torch.Size([142, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([142, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 20.602 
full-AccS: 0.000 
full-AccR: 0.546 
full-outlier: 94.779 
vis-epe: 20.602 
vis-AccS: 0.000 
vis-AccR: 0.546 
vis-outlier: 94.779 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[ 0.63814927 -0.15503533 -0.7541416 ]
 [-0.61475232 -0.69230752 -0.37787548]
 [-0.46351385  0.70475126 -0.53710387]]
Actual translation :  [0.96696898 0.79531393 0.98999611]
Predicted rotation :  [[ 0.3259027   0.4980869  -0.80355269]
 [-0.6792776  -0.46779442 -0.56546474]
 [-0.65754795  0.73012185  0.18588376]]
Predicted translation :  [-0.00709752 -0.00948851 -0.01809845]
Relative Rotation Error :  0.7874108433275191
Relative Translation Error :  1.6164056339724497
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.06949031308578127
Strict IR :  0.0
Relaxed IR :  0.0998040313549832
model 167
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[64, 60]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([124, 2048])
block_i :  1
x.shape :  torch.Size([124, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 124])
coarse_feats.shape :  torch.Size([1, 528, 124])
coarse_feats.shape :  torch.Size([124, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 64])
tgt_mask.shape :  torch.Size([1, 60])
src_ind_coarse_split.shape :  torch.Size([64])
tgt_ind_coarse_split.shape :  torch.Size([60])
src_ind_coarse.shape :  torch.Size([64])
tgt_ind_coarse.shape :  torch.Size([60])
src_feats.shape :  torch.Size([1, 64, 528])
tgt_feats.shape :  torch.Size([1, 60, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([64, 528])
F1.shape : torch.Size([60, 528])
ldmk_t_indices :  tensor([20, 23, 59, 13, 56,  6,  5, 44, 37,  7,  5, 59, 59, 37, 59, 55, 52, 55,
        51, 46,  6, 37,  5, 10,  5, 37, 36, 44, 54, 13, 13, 13, 36, 13, 13, 37,
        13, 28, 13, 36, 13, 13, 16, 17, 23, 51, 54, 47, 44, 59, 55, 55, 51, 52,
        50, 18, 51, 54, 15, 59, 51, 52,  3, 55], device='cuda:0')
ldmk_s.shape :  torch.Size([64, 3])
ldmk_t.shape :  torch.Size([64, 3])
vec_6d.shape :  torch.Size([64, 6])
ind.shape :  torch.Size([1, 64, 2])
bi :  0
si.shape :  torch.Size([64])
ti.shape :  torch.Size([64])
s_pos.shape :  torch.Size([64, 3])
t_pos.shape :  torch.Size([64, 3])
ind.shape :  torch.Size([1, 64, 2])
bi :  0
si.shape :  torch.Size([64])
ti.shape :  torch.Size([64])
s_pos.shape :  torch.Size([64, 3])
t_pos.shape :  torch.Size([64, 3])
number of true landmarks correspondences returned from KNN matching :  10  out of  64
fraction of true landmark correspondences returned from KNN matching :  0.15625
vec6d.shape :  torch.Size([64, 6])
ldmk_s.shape :  torch.Size([64, 3])
ldmk_t.shape :  torch.Size([64, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([64, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 5.889 
full-AccS: 1.027 
full-AccR: 13.294 
full-outlier: 8.344 
vis-epe: 5.889 
vis-AccS: 1.027 
vis-AccR: 13.294 
vis-outlier: 8.344 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[ 0.39671545  0.36679516 -0.8414738 ]
 [-0.57527497  0.81369012  0.08346918]
 [ 0.71531501  0.4509653   0.53381151]]
Actual translation :  [ 0.05762421 -0.46980197  0.32040084]
Predicted rotation :  [[ 0.76830864  0.2759566  -0.57753772]
 [-0.45880166  0.86658764 -0.19628277]
 [ 0.44632155  0.41578099  0.7924161 ]]
Predicted translation :  [ 0.00680185 -0.00411869  0.0045892 ]
Relative Rotation Error :  0.4794974098910551
Relative Translation Error :  0.5649609009617335
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.03285477757735972
Strict IR :  0.06382316313823164
Relaxed IR :  0.5152552926525529
model 207
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[70, 65]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([135, 2048])
block_i :  1
x.shape :  torch.Size([135, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 135])
coarse_feats.shape :  torch.Size([1, 528, 135])
coarse_feats.shape :  torch.Size([135, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 70])
tgt_mask.shape :  torch.Size([1, 65])
src_ind_coarse_split.shape :  torch.Size([70])
tgt_ind_coarse_split.shape :  torch.Size([65])
src_ind_coarse.shape :  torch.Size([70])
tgt_ind_coarse.shape :  torch.Size([65])
src_feats.shape :  torch.Size([1, 70, 528])
tgt_feats.shape :  torch.Size([1, 65, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([70, 528])
F1.shape : torch.Size([65, 528])
ldmk_t_indices :  tensor([40, 57, 57, 57,  3, 20, 18, 18, 18,  8,  1, 41, 30, 18, 35, 29, 47, 18,
        29, 47, 47, 61,  4, 47, 45,  3, 30,  6, 49, 18, 51, 56, 14,  6, 49, 54,
        36, 57, 45, 32, 54, 20, 42, 20, 34, 45, 32, 47, 57, 30,  0, 49, 57, 47,
        47, 35, 23, 41, 41, 30, 55, 51, 61, 35, 61, 34, 55, 34, 34, 47],
       device='cuda:0')
ldmk_s.shape :  torch.Size([70, 3])
ldmk_t.shape :  torch.Size([70, 3])
vec_6d.shape :  torch.Size([70, 6])
ind.shape :  torch.Size([1, 70, 2])
bi :  0
si.shape :  torch.Size([70])
ti.shape :  torch.Size([70])
s_pos.shape :  torch.Size([70, 3])
t_pos.shape :  torch.Size([70, 3])
ind.shape :  torch.Size([1, 70, 2])
bi :  0
si.shape :  torch.Size([70])
ti.shape :  torch.Size([70])
s_pos.shape :  torch.Size([70, 3])
t_pos.shape :  torch.Size([70, 3])
number of true landmarks correspondences returned from KNN matching :  7  out of  70
fraction of true landmark correspondences returned from KNN matching :  0.1
vec6d.shape :  torch.Size([70, 6])
ldmk_s.shape :  torch.Size([70, 3])
ldmk_t.shape :  torch.Size([70, 3])
k0 :  -8
levels :  1
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([70, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 20.926 
full-AccS: 0.000 
full-AccR: 0.628 
full-outlier: 99.023 
vis-epe: 20.926 
vis-AccS: 0.000 
vis-AccR: 0.628 
vis-outlier: 99.023 
occ-epe: nan 
occ-AccS: nan 
occ-AccR: nan 
occ-outlier: nan 

Actual rotation :  [[-0.69578084  0.62399956  0.35568745]
 [ 0.66485052  0.37215059  0.64767101]
 [ 0.27177713  0.68711606 -0.67380168]]
Actual translation :  [ 0.44784053 -0.19352481 -0.1776428 ]
Predicted rotation :  [[-0.07281947 -0.98437357  0.16033086]
 [ 0.9734832  -0.10510731 -0.20318165]
 [ 0.21685861  0.14128384  0.96592504]]
Predicted translation :  [0.01315715 0.00770063 0.0089633 ]
Relative Rotation Error :  2.437864845383224
Relative Translation Error :  0.5140653196124846
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.11009301921949201
Strict IR :  0.004884856943475227
Relaxed IR :  0.05931612002791347
