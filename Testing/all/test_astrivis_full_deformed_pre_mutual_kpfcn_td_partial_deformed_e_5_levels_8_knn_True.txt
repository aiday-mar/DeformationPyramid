model 002 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[150, 164]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([314, 2048])
block_i :  1
x.shape :  torch.Size([314, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 314])
coarse_feats.shape :  torch.Size([1, 528, 314])
coarse_feats.shape :  torch.Size([314, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 150])
tgt_mask.shape :  torch.Size([1, 164])
src_ind_coarse_split.shape :  torch.Size([150])
tgt_ind_coarse_split.shape :  torch.Size([164])
src_ind_coarse.shape :  torch.Size([150])
tgt_ind_coarse.shape :  torch.Size([164])
src_feats.shape :  torch.Size([1, 150, 528])
tgt_feats.shape :  torch.Size([1, 164, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([150, 528])
F1.shape : torch.Size([164, 528])
ldmk_t_indices :  tensor([ 13, 144,  25, 101,   9, 101,  44, 101, 101, 101, 101,  49,  62,  72,
         27, 138,   5,  97,  64,  32,  72, 152,  72,   0,  57,  38, 124,  60,
        101,  60,  81,  64,  62, 113, 119,  62,  38, 124, 113,  32,   0, 124,
        104,  22, 119,  78,  45, 119,  62, 101,  38, 160,   3,  98, 160, 151,
         61,  61,  92,   1,  93, 118,  93,  60,  92, 106,  67,  58,  92,  93,
        104,   5,  89,  72, 121,   5,  44, 121, 151,  61,  72,  84,  58, 101,
        111, 147, 119, 147,  39, 119, 134,  91,  22,  78,  73, 119, 124,  39,
        142,  84, 151,  61, 113,  57,   1,  61,  85,  61, 119,  91,  32,  84,
         69, 111,  61,  64,   1, 120,  91,  55,   0, 123,  92,  55,  76, 120,
         55,  61,  40,  55, 120,  58,  55,  14,  58,  27,  22,   5, 124, 120,
        151,  73, 151,  93,   4, 151,  39, 151,  93, 106], device='cuda:0')
ldmk_s.shape :  torch.Size([150, 3])
ldmk_t.shape :  torch.Size([150, 3])
vec_6d.shape :  torch.Size([150, 6])
ind.shape :  torch.Size([1, 150, 2])
bi :  0
si.shape :  torch.Size([150])
ti.shape :  torch.Size([150])
s_pos.shape :  torch.Size([150, 3])
t_pos.shape :  torch.Size([150, 3])
ind.shape :  torch.Size([1, 150, 2])
bi :  0
si.shape :  torch.Size([150])
ti.shape :  torch.Size([150])
s_pos.shape :  torch.Size([150, 3])
t_pos.shape :  torch.Size([150, 3])
number of true landmarks correspondences returned from KNN matching :  15  out of  150
fraction of true landmark correspondences returned from KNN matching :  0.1
vec6d.shape :  torch.Size([150, 6])
ldmk_s.shape :  torch.Size([150, 3])
ldmk_t.shape :  torch.Size([150, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([150, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 20.325 
full-AccS: 0.068 
full-AccR: 0.914 
full-outlier: 89.924 
vis-epe: 20.635 
vis-AccS: 0.018 
vis-AccR: 0.444 
vis-outlier: 91.202 
occ-epe: 14.076 
occ-AccS: 1.075 
occ-AccR: 10.394 
occ-outlier: 64.158 

Actual rotation :  [[-0.72100132  0.19757917 -0.66416833]
 [ 0.253515   -0.81682267 -0.51819964]
 [-0.6448932  -0.54199926  0.53884094]]
Actual translation :  [1.49731921 0.86758808 0.78433351]
Predicted rotation :  [[-0.47340245  0.2162815  -0.85388091]
 [ 0.43748615 -0.78364004 -0.44103793]
 [-0.76452357 -0.58234941  0.27635675]]
Predicted translation :  [0.0159514 0.0139855 0.0051906]
Relative Rotation Error :  0.33577806238220914
Relative Translation Error :  1.8788697746745056
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.07212216211721771
Strict IR :  0.024539877300613498
Relaxed IR :  0.2552147239263804
model 042 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[124, 112]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([236, 2048])
block_i :  1
x.shape :  torch.Size([236, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 236])
coarse_feats.shape :  torch.Size([1, 528, 236])
coarse_feats.shape :  torch.Size([236, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 124])
tgt_mask.shape :  torch.Size([1, 112])
src_ind_coarse_split.shape :  torch.Size([124])
tgt_ind_coarse_split.shape :  torch.Size([112])
src_ind_coarse.shape :  torch.Size([124])
tgt_ind_coarse.shape :  torch.Size([112])
src_feats.shape :  torch.Size([1, 124, 528])
tgt_feats.shape :  torch.Size([1, 112, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([124, 528])
F1.shape : torch.Size([112, 528])
ldmk_t_indices :  tensor([105,  68,  16,  77,   4,  77,  16,  52,  68,  42,  63,  47,   4,  63,
         81,  16,  12,  68,  52,  81, 102,  77,  75,  81,  64,  45,  45,  81,
         75,  68,  52,  16,  52,  75,  81,  68,  68, 105,   0,  52,  98,  53,
         91,  52,  68, 102, 102,  63,  16,  52,  52, 102,  47,  52,  42,   0,
         52,  75,  77,  53,  20, 105,  91,  63,  31,  86, 101,  53, 101,  75,
         68,  31,  27,  75,  63,  47,  64,  68,  77, 105,  52,  68,  53, 102,
        102,  11,  75,  16,  63,  63,  52, 102,  81,  63,  52,  52,  29,  47,
         75,  45,  77,  63,  63,  75,  68,  81,  53,  52,  68,  15,  53,  52,
         81,  68,  63,  68, 102,  75,  81,  77,  63,  75, 105,  63],
       device='cuda:0')
ldmk_s.shape :  torch.Size([124, 3])
ldmk_t.shape :  torch.Size([124, 3])
vec_6d.shape :  torch.Size([124, 6])
ind.shape :  torch.Size([1, 124, 2])
bi :  0
si.shape :  torch.Size([124])
ti.shape :  torch.Size([124])
s_pos.shape :  torch.Size([124, 3])
t_pos.shape :  torch.Size([124, 3])
ind.shape :  torch.Size([1, 124, 2])
bi :  0
si.shape :  torch.Size([124])
ti.shape :  torch.Size([124])
s_pos.shape :  torch.Size([124, 3])
t_pos.shape :  torch.Size([124, 3])
number of true landmarks correspondences returned from KNN matching :  2  out of  124
fraction of true landmark correspondences returned from KNN matching :  0.016129032258064516
vec6d.shape :  torch.Size([124, 6])
ldmk_s.shape :  torch.Size([124, 3])
ldmk_t.shape :  torch.Size([124, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([124, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 15.056 
full-AccS: 0.000 
full-AccR: 1.892 
full-outlier: 85.878 
vis-epe: 16.593 
vis-AccS: 0.000 
vis-AccR: 0.533 
vis-outlier: 91.949 
occ-epe: 12.309 
occ-AccS: 0.000 
occ-AccR: 4.321 
occ-outlier: 75.026 

Actual rotation :  [[ 0.77604838  0.62888338 -0.04748266]
 [ 0.31818631 -0.32541498  0.8904283 ]
 [ 0.54452399 -0.70612378 -0.45263985]]
Actual translation :  [-0.19578607  0.27815696  0.64648693]
Predicted rotation :  [[ 0.79067794 -0.12417754  0.59950666]
 [-0.51878828  0.38406908  0.76377335]
 [-0.32509529 -0.91491567  0.2392531 ]]
Predicted translation :  [-0.07175414 -0.06795145  0.08411289]
Relative Rotation Error :  1.4415350383420462
Relative Translation Error :  0.6718924813124643
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.10651787563322329
Strict IR :  0.001693480101608806
Relaxed IR :  0.02476714648602879
model 085 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[72, 76]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([148, 2048])
block_i :  1
x.shape :  torch.Size([148, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 148])
coarse_feats.shape :  torch.Size([1, 528, 148])
coarse_feats.shape :  torch.Size([148, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 72])
tgt_mask.shape :  torch.Size([1, 76])
src_ind_coarse_split.shape :  torch.Size([72])
tgt_ind_coarse_split.shape :  torch.Size([76])
src_ind_coarse.shape :  torch.Size([72])
tgt_ind_coarse.shape :  torch.Size([76])
src_feats.shape :  torch.Size([1, 72, 528])
tgt_feats.shape :  torch.Size([1, 76, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([72, 528])
F1.shape : torch.Size([76, 528])
ldmk_t_indices :  tensor([ 7, 21, 21,  6, 19, 25,  7, 48,  7, 41, 21, 64, 15, 41, 19, 21, 18, 21,
        48, 48, 32, 48, 48, 21, 15, 21, 32, 21,  7, 48,  7, 18, 21, 18, 73, 41,
        32, 48, 21, 21, 19, 21, 21, 25, 48,  6, 73, 41, 48, 43, 41,  6, 15, 41,
        32, 64, 16, 18, 21, 15, 41,  6, 21, 21, 11, 18, 15, 25, 15, 15, 41, 15],
       device='cuda:0')
ldmk_s.shape :  torch.Size([72, 3])
ldmk_t.shape :  torch.Size([72, 3])
vec_6d.shape :  torch.Size([72, 6])
ind.shape :  torch.Size([1, 72, 2])
bi :  0
si.shape :  torch.Size([72])
ti.shape :  torch.Size([72])
s_pos.shape :  torch.Size([72, 3])
t_pos.shape :  torch.Size([72, 3])
ind.shape :  torch.Size([1, 72, 2])
bi :  0
si.shape :  torch.Size([72])
ti.shape :  torch.Size([72])
s_pos.shape :  torch.Size([72, 3])
t_pos.shape :  torch.Size([72, 3])
number of true landmarks correspondences returned from KNN matching :  2  out of  72
fraction of true landmark correspondences returned from KNN matching :  0.027777777777777776
vec6d.shape :  torch.Size([72, 6])
ldmk_s.shape :  torch.Size([72, 3])
ldmk_t.shape :  torch.Size([72, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([72, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 18.131 
full-AccS: 0.000 
full-AccR: 0.000 
full-outlier: 94.920 
vis-epe: 21.234 
vis-AccS: 0.000 
vis-AccR: 0.000 
vis-outlier: 95.333 
occ-epe: 10.304 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 93.878 

Actual rotation :  [[ 0.62309055  0.76764504 -0.14993086]
 [ 0.39456846 -0.14298754  0.90767301]
 [ 0.67533244 -0.62472046 -0.39198271]]
Actual translation :  [-0.1258871  -0.82602395  0.43519561]
Predicted rotation :  [[ 0.29207643  0.92413313 -0.2463117 ]
 [-0.39204053 -0.11922232 -0.91218972]
 [-0.87235054  0.36299321  0.32747568]]
Predicted translation :  [ 0.06267858 -0.00575023 -0.01117621]
Relative Rotation Error :  3.005635953832675
Relative Translation Error :  0.9527086659458875
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.1258793978153923
Strict IR :  0.0
Relaxed IR :  0.013530927835051547
model 126 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[139, 135]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([274, 2048])
block_i :  1
x.shape :  torch.Size([274, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 274])
coarse_feats.shape :  torch.Size([1, 528, 274])
coarse_feats.shape :  torch.Size([274, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 139])
tgt_mask.shape :  torch.Size([1, 135])
src_ind_coarse_split.shape :  torch.Size([139])
tgt_ind_coarse_split.shape :  torch.Size([135])
src_ind_coarse.shape :  torch.Size([139])
tgt_ind_coarse.shape :  torch.Size([135])
src_feats.shape :  torch.Size([1, 139, 528])
tgt_feats.shape :  torch.Size([1, 135, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([139, 528])
F1.shape : torch.Size([135, 528])
ldmk_t_indices :  tensor([ 41, 108,  41, 119,  63, 127,  58,  58, 125,  48,  31,  41, 133,  11,
        118,   1,  25,   9,   7,  41, 113,  11,  45,  71, 113,  31,  11,  40,
         85, 133,  40,  17,  17,  16,  16, 114,  40,  63,  63,  63,  20, 133,
        125,  17, 119,  83,  83,  36,  40, 125,  55,  40,  40,  36,  50, 123,
        125,   1,  63,  34,  63, 132, 125,   7,  33,   7, 108, 125, 113, 133,
         78, 123, 112,  29,  78, 123, 125, 110,  63,  20,  33, 112,  63,  26,
         26,   1, 108, 132,  26,  34,  41,  85,  16,  63,  26,   1, 102,  63,
         78,  81, 132, 102,   1, 125, 127,  31, 125,  63,   0,  63,  40,  58,
         42,  31,  48,  26,  17,  36,  31,  42,  36,  48,  63, 113,  31,  31,
         31, 122,  48,  83, 113, 122, 114,  17,  42,  26,  20,  36,  28],
       device='cuda:0')
ldmk_s.shape :  torch.Size([139, 3])
ldmk_t.shape :  torch.Size([139, 3])
vec_6d.shape :  torch.Size([139, 6])
ind.shape :  torch.Size([1, 139, 2])
bi :  0
si.shape :  torch.Size([139])
ti.shape :  torch.Size([139])
s_pos.shape :  torch.Size([139, 3])
t_pos.shape :  torch.Size([139, 3])
ind.shape :  torch.Size([1, 139, 2])
bi :  0
si.shape :  torch.Size([139])
ti.shape :  torch.Size([139])
s_pos.shape :  torch.Size([139, 3])
t_pos.shape :  torch.Size([139, 3])
number of true landmarks correspondences returned from KNN matching :  12  out of  139
fraction of true landmark correspondences returned from KNN matching :  0.08633093525179857
vec6d.shape :  torch.Size([139, 6])
ldmk_s.shape :  torch.Size([139, 3])
ldmk_t.shape :  torch.Size([139, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([139, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 21.134 
full-AccS: 0.028 
full-AccR: 0.294 
full-outlier: 88.774 
vis-epe: 21.145 
vis-AccS: 0.030 
vis-AccR: 0.316 
vis-outlier: 89.483 
occ-epe: 20.996 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 79.487 

Actual rotation :  [[-0.22957138  0.09752936  0.968393  ]
 [ 0.82843609  0.54182999  0.1418235 ]
 [-0.51087242  0.83481033 -0.2051855 ]]
Actual translation :  [-0.25784987 -0.18299676  1.01717296]
Predicted rotation :  [[ 0.88003684  0.06139286  0.47092054]
 [ 0.25736955  0.77171215 -0.58156814]
 [-0.39911916  0.633002    0.66333448]]
Predicted translation :  [ 0.14889226 -0.12173839  0.06104201]
Relative Rotation Error :  1.366838990280093
Relative Translation Error :  1.0408545264628686
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.11301792901994218
Strict IR :  0.004680708793045804
Relaxed IR :  0.08726178535606821
model 167 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[64, 56]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([120, 2048])
block_i :  1
x.shape :  torch.Size([120, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 120])
coarse_feats.shape :  torch.Size([1, 528, 120])
coarse_feats.shape :  torch.Size([120, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 64])
tgt_mask.shape :  torch.Size([1, 56])
src_ind_coarse_split.shape :  torch.Size([64])
tgt_ind_coarse_split.shape :  torch.Size([56])
src_ind_coarse.shape :  torch.Size([64])
tgt_ind_coarse.shape :  torch.Size([56])
src_feats.shape :  torch.Size([1, 64, 528])
tgt_feats.shape :  torch.Size([1, 56, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([64, 528])
F1.shape : torch.Size([56, 528])
ldmk_t_indices :  tensor([42, 15, 15,  0, 16, 15,  0,  6, 44, 53,  0, 55, 16, 42,  1,  1, 42, 16,
        42, 49,  0, 16, 42, 16, 15, 15,  0, 42,  3,  0,  0,  0,  6,  0, 16, 42,
         0, 15,  3,  0, 55, 16, 43,  0, 15, 16, 16,  3, 43, 16,  0, 42, 43, 53,
         3, 43, 42,  0, 43,  1,  0, 16,  0,  6], device='cuda:0')
ldmk_s.shape :  torch.Size([64, 3])
ldmk_t.shape :  torch.Size([64, 3])
vec_6d.shape :  torch.Size([64, 6])
ind.shape :  torch.Size([1, 64, 2])
bi :  0
si.shape :  torch.Size([64])
ti.shape :  torch.Size([64])
s_pos.shape :  torch.Size([64, 3])
t_pos.shape :  torch.Size([64, 3])
ind.shape :  torch.Size([1, 64, 2])
bi :  0
si.shape :  torch.Size([64])
ti.shape :  torch.Size([64])
s_pos.shape :  torch.Size([64, 3])
t_pos.shape :  torch.Size([64, 3])
number of true landmarks correspondences returned from KNN matching :  5  out of  64
fraction of true landmark correspondences returned from KNN matching :  0.078125
vec6d.shape :  torch.Size([64, 6])
ldmk_s.shape :  torch.Size([64, 3])
ldmk_t.shape :  torch.Size([64, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([64, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 17.537 
full-AccS: 0.000 
full-AccR: 0.716 
full-outlier: 76.059 
vis-epe: 18.128 
vis-AccS: 0.000 
vis-AccR: 0.822 
vis-outlier: 76.233 
occ-epe: 13.545 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 74.879 

Actual rotation :  [[-0.93663582  0.31762455 -0.14774298]
 [-0.33643314 -0.69811809  0.63201573]
 [ 0.09760167  0.6416742   0.76074183]]
Actual translation :  [ 1.39406826  0.65549133 -0.56094614]
Predicted rotation :  [[ 0.79188531  0.60548061  0.07944203]
 [-0.09996805  0.25686682 -0.96126266]
 [-0.60243187  0.75326811  0.26393782]]
Predicted translation :  [-0.01990761  0.03503826  0.02952741]
Relative Rotation Error :  2.5764371656687337
Relative Translation Error :  1.6531632670953493
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.08597769126472724
Strict IR :  0.00635039223010833
Relaxed IR :  0.13933507657825925
model 207 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[67, 66]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([133, 2048])
block_i :  1
x.shape :  torch.Size([133, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 133])
coarse_feats.shape :  torch.Size([1, 528, 133])
coarse_feats.shape :  torch.Size([133, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 67])
tgt_mask.shape :  torch.Size([1, 66])
src_ind_coarse_split.shape :  torch.Size([67])
tgt_ind_coarse_split.shape :  torch.Size([66])
src_ind_coarse.shape :  torch.Size([67])
tgt_ind_coarse.shape :  torch.Size([66])
src_feats.shape :  torch.Size([1, 67, 528])
tgt_feats.shape :  torch.Size([1, 66, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([67, 528])
F1.shape : torch.Size([66, 528])
ldmk_t_indices :  tensor([43, 17, 10, 20, 17, 20, 15, 15, 17, 20, 26, 15, 63, 41, 55, 26, 35, 26,
        64, 49, 15, 63, 20, 36, 63, 36, 56, 43, 30, 46, 10, 30, 41, 41, 44, 30,
        53,  1, 26,  5, 30, 24, 26,  3,  6, 20,  3, 41, 15,  6,  6,  9, 20, 58,
        32, 63, 11, 49, 49, 36, 20, 15, 20, 13, 11, 64, 64], device='cuda:0')
ldmk_s.shape :  torch.Size([67, 3])
ldmk_t.shape :  torch.Size([67, 3])
vec_6d.shape :  torch.Size([67, 6])
ind.shape :  torch.Size([1, 67, 2])
bi :  0
si.shape :  torch.Size([67])
ti.shape :  torch.Size([67])
s_pos.shape :  torch.Size([67, 3])
t_pos.shape :  torch.Size([67, 3])
ind.shape :  torch.Size([1, 67, 2])
bi :  0
si.shape :  torch.Size([67])
ti.shape :  torch.Size([67])
s_pos.shape :  torch.Size([67, 3])
t_pos.shape :  torch.Size([67, 3])
number of true landmarks correspondences returned from KNN matching :  4  out of  67
fraction of true landmark correspondences returned from KNN matching :  0.05970149253731343
vec6d.shape :  torch.Size([67, 6])
ldmk_s.shape :  torch.Size([67, 3])
ldmk_t.shape :  torch.Size([67, 3])
k0 :  -8
levels :  8
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([67, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 18.217 
full-AccS: 0.070 
full-AccR: 0.939 
full-outlier: 87.726 
vis-epe: 18.428 
vis-AccS: 0.072 
vis-AccR: 0.969 
vis-outlier: 88.231 
occ-epe: 11.610 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 71.910 

Actual rotation :  [[ 0.73275637  0.1374364   0.66646781]
 [ 0.60033779 -0.59170884 -0.53802899]
 [ 0.32041012  0.79434998 -0.51608669]]
Actual translation :  [0.26170502 1.10936721 0.50044207]
Predicted rotation :  [[ 0.39827901  0.9170645   0.0191425 ]
 [ 0.74762025 -0.33663944  0.57248377]
 [ 0.53144874 -0.21369687 -0.81969246]]
Predicted translation :  [-0.00254094  0.01058065 -0.00372601]
Relative Rotation Error :  1.4735402979712724
Relative Translation Error :  1.2374745545154555
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.08300796499917157
Strict IR :  0.007741935483870968
Relaxed IR :  0.11268817204301075
