model 002 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[150, 164]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([314, 2048])
block_i :  1
x.shape :  torch.Size([314, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 314])
coarse_feats.shape :  torch.Size([1, 528, 314])
coarse_feats.shape :  torch.Size([314, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 150])
tgt_mask.shape :  torch.Size([1, 164])
src_ind_coarse_split.shape :  torch.Size([150])
tgt_ind_coarse_split.shape :  torch.Size([164])
src_ind_coarse.shape :  torch.Size([150])
tgt_ind_coarse.shape :  torch.Size([164])
src_feats.shape :  torch.Size([1, 150, 528])
tgt_feats.shape :  torch.Size([1, 164, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([150, 528])
F1.shape : torch.Size([164, 528])
ldmk_t_indices :  tensor([ 13, 144,  25, 101,   9, 101,  44, 101, 101, 101, 101,  49,  62,  72,
         27, 138,   5,  97,  64,  32,  72, 152,  72,   0,  57,  38, 124,  60,
        101,  60,  81,  64,  62, 113, 119,  62,  38, 124, 113,  32,   0, 124,
        104,  22, 119,  78,  45, 119,  62, 101,  38, 160,   3,  98, 160, 151,
         61,  61,  92,   1,  93, 118,  93,  60,  92, 106,  67,  58,  92,  93,
        104,   5,  89,  72, 121,   5,  44, 121, 151,  61,  72,  84,  58, 101,
        111, 147, 119, 147,  39, 119, 134,  91,  22,  78,  73, 119, 124,  39,
        142,  84, 151,  61, 113,  57,   1,  61,  85,  61, 119,  91,  32,  84,
         69, 111,  61,  64,   1, 120,  91,  55,   0, 123,  92,  55,  76, 120,
         55,  61,  40,  55, 120,  58,  55,  14,  58,  27,  22,   5, 124, 120,
        151,  73, 151,  93,   4, 151,  39, 151,  93, 106], device='cuda:0')
ldmk_s.shape :  torch.Size([150, 3])
ldmk_t.shape :  torch.Size([150, 3])
vec_6d.shape :  torch.Size([150, 6])
ind.shape :  torch.Size([1, 150, 2])
bi :  0
si.shape :  torch.Size([150])
ti.shape :  torch.Size([150])
s_pos.shape :  torch.Size([150, 3])
t_pos.shape :  torch.Size([150, 3])
ind.shape :  torch.Size([1, 150, 2])
bi :  0
si.shape :  torch.Size([150])
ti.shape :  torch.Size([150])
s_pos.shape :  torch.Size([150, 3])
t_pos.shape :  torch.Size([150, 3])
number of true landmarks correspondences returned from KNN matching :  15  out of  150
fraction of true landmark correspondences returned from KNN matching :  0.1
vec6d.shape :  torch.Size([150, 6])
ldmk_s.shape :  torch.Size([150, 3])
ldmk_t.shape :  torch.Size([150, 3])
k0 :  -8
levels :  4
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([150, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 18.661 
full-AccS: 0.000 
full-AccR: 0.694 
full-outlier: 86.892 
vis-epe: 19.259 
vis-AccS: 0.000 
vis-AccR: 0.355 
vis-outlier: 90.882 
occ-epe: 6.591 
occ-AccS: 0.000 
occ-AccR: 7.527 
occ-outlier: 6.452 

Actual rotation :  [[-0.72100132  0.19757917 -0.66416833]
 [ 0.253515   -0.81682267 -0.51819964]
 [-0.6448932  -0.54199926  0.53884094]]
Actual translation :  [1.49731921 0.86758808 0.78433351]
Predicted rotation :  [[-0.36318526  0.43289153 -0.82504648]
 [ 0.36835173 -0.74665919 -0.55391103]
 [-0.8558118  -0.50507954  0.11171907]]
Predicted translation :  [-0.01251338  0.00691007 -0.02886304]
Relative Rotation Error :  0.4826639491589658
Relative Translation Error :  1.9187625455154984
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.06074254678860152
Strict IR :  0.0006134969325153375
Relaxed IR :  0.1721881390593047
model 042 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[124, 112]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([236, 2048])
block_i :  1
x.shape :  torch.Size([236, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 236])
coarse_feats.shape :  torch.Size([1, 528, 236])
coarse_feats.shape :  torch.Size([236, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 124])
tgt_mask.shape :  torch.Size([1, 112])
src_ind_coarse_split.shape :  torch.Size([124])
tgt_ind_coarse_split.shape :  torch.Size([112])
src_ind_coarse.shape :  torch.Size([124])
tgt_ind_coarse.shape :  torch.Size([112])
src_feats.shape :  torch.Size([1, 124, 528])
tgt_feats.shape :  torch.Size([1, 112, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([124, 528])
F1.shape : torch.Size([112, 528])
ldmk_t_indices :  tensor([105,  68,  16,  77,   4,  77,  16,  52,  68,  42,  63,  47,   4,  63,
         81,  16,  12,  68,  52,  81, 102,  77,  75,  81,  64,  45,  45,  81,
         75,  68,  52,  16,  52,  75,  81,  68,  68, 105,   0,  52,  98,  53,
         91,  52,  68, 102, 102,  63,  16,  52,  52, 102,  47,  52,  42,   0,
         52,  75,  77,  53,  20, 105,  91,  63,  31,  86, 101,  53, 101,  75,
         68,  31,  27,  75,  63,  47,  64,  68,  77, 105,  52,  68,  53, 102,
        102,  11,  75,  16,  63,  63,  52, 102,  81,  63,  52,  52,  29,  47,
         75,  45,  77,  63,  63,  75,  68,  81,  53,  52,  68,  15,  53,  52,
         81,  68,  63,  68, 102,  75,  81,  77,  63,  75, 105,  63],
       device='cuda:0')
ldmk_s.shape :  torch.Size([124, 3])
ldmk_t.shape :  torch.Size([124, 3])
vec_6d.shape :  torch.Size([124, 6])
ind.shape :  torch.Size([1, 124, 2])
bi :  0
si.shape :  torch.Size([124])
ti.shape :  torch.Size([124])
s_pos.shape :  torch.Size([124, 3])
t_pos.shape :  torch.Size([124, 3])
ind.shape :  torch.Size([1, 124, 2])
bi :  0
si.shape :  torch.Size([124])
ti.shape :  torch.Size([124])
s_pos.shape :  torch.Size([124, 3])
t_pos.shape :  torch.Size([124, 3])
number of true landmarks correspondences returned from KNN matching :  2  out of  124
fraction of true landmark correspondences returned from KNN matching :  0.016129032258064516
vec6d.shape :  torch.Size([124, 6])
ldmk_s.shape :  torch.Size([124, 3])
ldmk_t.shape :  torch.Size([124, 3])
k0 :  -8
levels :  4
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([124, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 13.431 
full-AccS: 0.000 
full-AccR: 0.403 
full-outlier: 86.794 
vis-epe: 14.064 
vis-AccS: 0.000 
vis-AccR: 0.628 
vis-outlier: 81.709 
occ-epe: 12.301 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 95.883 

Actual rotation :  [[ 0.77604838  0.62888338 -0.04748266]
 [ 0.31818631 -0.32541498  0.8904283 ]
 [ 0.54452399 -0.70612378 -0.45263985]]
Actual translation :  [-0.19578607  0.27815696  0.64648693]
Predicted rotation :  [[ 0.71495212 -0.55243283  0.42855738]
 [-0.3427571   0.25730925  0.90349849]
 [-0.60939393 -0.79284923 -0.00538647]]
Predicted translation :  [-0.03082074 -0.05681434  0.04652773]
Relative Rotation Error :  1.5561765548538475
Relative Translation Error :  0.706661418651356
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.11936230022219102
Strict IR :  0.0
Relaxed IR :  0.0
model 085 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[72, 76]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([148, 2048])
block_i :  1
x.shape :  torch.Size([148, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 148])
coarse_feats.shape :  torch.Size([1, 528, 148])
coarse_feats.shape :  torch.Size([148, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 72])
tgt_mask.shape :  torch.Size([1, 76])
src_ind_coarse_split.shape :  torch.Size([72])
tgt_ind_coarse_split.shape :  torch.Size([76])
src_ind_coarse.shape :  torch.Size([72])
tgt_ind_coarse.shape :  torch.Size([76])
src_feats.shape :  torch.Size([1, 72, 528])
tgt_feats.shape :  torch.Size([1, 76, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([72, 528])
F1.shape : torch.Size([76, 528])
ldmk_t_indices :  tensor([ 7, 21, 21,  6, 19, 25,  7, 48,  7, 41, 21, 64, 15, 41, 19, 21, 18, 21,
        48, 48, 32, 48, 48, 21, 15, 21, 32, 21,  7, 48,  7, 18, 21, 18, 73, 41,
        32, 48, 21, 21, 19, 21, 21, 25, 48,  6, 73, 41, 48, 43, 41,  6, 15, 41,
        32, 64, 16, 18, 21, 15, 41,  6, 21, 21, 11, 18, 15, 25, 15, 15, 41, 15],
       device='cuda:0')
ldmk_s.shape :  torch.Size([72, 3])
ldmk_t.shape :  torch.Size([72, 3])
vec_6d.shape :  torch.Size([72, 6])
ind.shape :  torch.Size([1, 72, 2])
bi :  0
si.shape :  torch.Size([72])
ti.shape :  torch.Size([72])
s_pos.shape :  torch.Size([72, 3])
t_pos.shape :  torch.Size([72, 3])
ind.shape :  torch.Size([1, 72, 2])
bi :  0
si.shape :  torch.Size([72])
ti.shape :  torch.Size([72])
s_pos.shape :  torch.Size([72, 3])
t_pos.shape :  torch.Size([72, 3])
number of true landmarks correspondences returned from KNN matching :  2  out of  72
fraction of true landmark correspondences returned from KNN matching :  0.027777777777777776
vec6d.shape :  torch.Size([72, 6])
ldmk_s.shape :  torch.Size([72, 3])
ldmk_t.shape :  torch.Size([72, 3])
k0 :  -8
levels :  4
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([72, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 19.914 
full-AccS: 0.000 
full-AccR: 0.134 
full-outlier: 93.895 
vis-epe: 22.453 
vis-AccS: 0.000 
vis-AccR: 0.187 
vis-outlier: 96.764 
occ-epe: 13.509 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 86.656 

Actual rotation :  [[ 0.62309055  0.76764504 -0.14993086]
 [ 0.39456846 -0.14298754  0.90767301]
 [ 0.67533244 -0.62472046 -0.39198271]]
Actual translation :  [-0.1258871  -0.82602395  0.43519561]
Predicted rotation :  [[ 0.18388385  0.98080412  0.06488477]
 [-0.23827414  0.10851922 -0.96511597]
 [-0.95363092  0.16200879  0.25365525]]
Predicted translation :  [ 0.01898742 -0.0131552  -0.00745148]
Relative Rotation Error :  2.9753928994036887
Relative Translation Error :  0.9368461346869954
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.14488655145267257
Strict IR :  0.0
Relaxed IR :  0.0
model 126 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[139, 135]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([274, 2048])
block_i :  1
x.shape :  torch.Size([274, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 274])
coarse_feats.shape :  torch.Size([1, 528, 274])
coarse_feats.shape :  torch.Size([274, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 139])
tgt_mask.shape :  torch.Size([1, 135])
src_ind_coarse_split.shape :  torch.Size([139])
tgt_ind_coarse_split.shape :  torch.Size([135])
src_ind_coarse.shape :  torch.Size([139])
tgt_ind_coarse.shape :  torch.Size([135])
src_feats.shape :  torch.Size([1, 139, 528])
tgt_feats.shape :  torch.Size([1, 135, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([139, 528])
F1.shape : torch.Size([135, 528])
ldmk_t_indices :  tensor([ 41, 108,  41, 119,  63, 127,  58,  58, 125,  48,  31,  41, 133,  11,
        118,   1,  25,   9,   7,  41, 113,  11,  45,  71, 113,  31,  11,  40,
         85, 133,  40,  17,  17,  16,  16, 114,  40,  63,  63,  63,  20, 133,
        125,  17, 119,  83,  83,  36,  40, 125,  55,  40,  40,  36,  50, 123,
        125,   1,  63,  34,  63, 132, 125,   7,  33,   7, 108, 125, 113, 133,
         78, 123, 112,  29,  78, 123, 125, 110,  63,  20,  33, 112,  63,  26,
         26,   1, 108, 132,  26,  34,  41,  85,  16,  63,  26,   1, 102,  63,
         78,  81, 132, 102,   1, 125, 127,  31, 125,  63,   0,  63,  40,  58,
         42,  31,  48,  26,  17,  36,  31,  42,  36,  48,  63, 113,  31,  31,
         31, 122,  48,  83, 113, 122, 114,  17,  42,  26,  20,  36,  28],
       device='cuda:0')
ldmk_s.shape :  torch.Size([139, 3])
ldmk_t.shape :  torch.Size([139, 3])
vec_6d.shape :  torch.Size([139, 6])
ind.shape :  torch.Size([1, 139, 2])
bi :  0
si.shape :  torch.Size([139])
ti.shape :  torch.Size([139])
s_pos.shape :  torch.Size([139, 3])
t_pos.shape :  torch.Size([139, 3])
ind.shape :  torch.Size([1, 139, 2])
bi :  0
si.shape :  torch.Size([139])
ti.shape :  torch.Size([139])
s_pos.shape :  torch.Size([139, 3])
t_pos.shape :  torch.Size([139, 3])
number of true landmarks correspondences returned from KNN matching :  12  out of  139
fraction of true landmark correspondences returned from KNN matching :  0.08633093525179857
vec6d.shape :  torch.Size([139, 6])
ldmk_s.shape :  torch.Size([139, 3])
ldmk_t.shape :  torch.Size([139, 3])
k0 :  -8
levels :  4
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([139, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 16.022 
full-AccS: 0.014 
full-AccR: 0.546 
full-outlier: 79.801 
vis-epe: 16.446 
vis-AccS: 0.015 
vis-AccR: 0.588 
vis-outlier: 82.191 
occ-epe: 10.479 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 48.521 

Actual rotation :  [[-0.22957138  0.09752936  0.968393  ]
 [ 0.82843609  0.54182999  0.1418235 ]
 [-0.51087242  0.83481033 -0.2051855 ]]
Actual translation :  [-0.25784987 -0.18299676  1.01717296]
Predicted rotation :  [[ 0.39270136  0.12608583  0.91098195]
 [ 0.91597843  0.03499275 -0.39969851]
 [-0.08227406  0.99140199 -0.10175013]]
Predicted translation :  [ 0.05494884 -0.00964262 -0.01120011]
Relative Rotation Error :  0.7841500857946311
Relative Translation Error :  1.0887818266561278
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.08700082684035265
Strict IR :  0.0
Relaxed IR :  0.0
model 167 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[64, 56]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([120, 2048])
block_i :  1
x.shape :  torch.Size([120, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 120])
coarse_feats.shape :  torch.Size([1, 528, 120])
coarse_feats.shape :  torch.Size([120, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 64])
tgt_mask.shape :  torch.Size([1, 56])
src_ind_coarse_split.shape :  torch.Size([64])
tgt_ind_coarse_split.shape :  torch.Size([56])
src_ind_coarse.shape :  torch.Size([64])
tgt_ind_coarse.shape :  torch.Size([56])
src_feats.shape :  torch.Size([1, 64, 528])
tgt_feats.shape :  torch.Size([1, 56, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([64, 528])
F1.shape : torch.Size([56, 528])
ldmk_t_indices :  tensor([42, 15, 15,  0, 16, 15,  0,  6, 44, 53,  0, 55, 16, 42,  1,  1, 42, 16,
        42, 49,  0, 16, 42, 16, 15, 15,  0, 42,  3,  0,  0,  0,  6,  0, 16, 42,
         0, 15,  3,  0, 55, 16, 43,  0, 15, 16, 16,  3, 43, 16,  0, 42, 43, 53,
         3, 43, 42,  0, 43,  1,  0, 16,  0,  6], device='cuda:0')
ldmk_s.shape :  torch.Size([64, 3])
ldmk_t.shape :  torch.Size([64, 3])
vec_6d.shape :  torch.Size([64, 6])
ind.shape :  torch.Size([1, 64, 2])
bi :  0
si.shape :  torch.Size([64])
ti.shape :  torch.Size([64])
s_pos.shape :  torch.Size([64, 3])
t_pos.shape :  torch.Size([64, 3])
ind.shape :  torch.Size([1, 64, 2])
bi :  0
si.shape :  torch.Size([64])
ti.shape :  torch.Size([64])
s_pos.shape :  torch.Size([64, 3])
t_pos.shape :  torch.Size([64, 3])
number of true landmarks correspondences returned from KNN matching :  5  out of  64
fraction of true landmark correspondences returned from KNN matching :  0.078125
vec6d.shape :  torch.Size([64, 6])
ldmk_s.shape :  torch.Size([64, 3])
ldmk_t.shape :  torch.Size([64, 3])
k0 :  -8
levels :  4
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([64, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 21.514 
full-AccS: 0.000 
full-AccR: 0.592 
full-outlier: 86.301 
vis-epe: 22.068 
vis-AccS: 0.000 
vis-AccR: 0.679 
vis-outlier: 85.311 
occ-epe: 17.765 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 92.995 

Actual rotation :  [[-0.93663582  0.31762455 -0.14774298]
 [-0.33643314 -0.69811809  0.63201573]
 [ 0.09760167  0.6416742   0.76074183]]
Actual translation :  [ 1.39406826  0.65549133 -0.56094614]
Predicted rotation :  [[ 0.75481126  0.65103336  0.08009687]
 [-0.13799546  0.27698394 -0.95091393]
 [-0.64126216  0.70670754  0.29891023]]
Predicted translation :  [ 0.03875724  0.03411674 -0.01205668]
Relative Rotation Error :  2.5336812149476997
Relative Translation Error :  1.5887901058087075
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.12746153365552468
Strict IR :  0.0014942099364960778
Relaxed IR :  0.028016436309301458
model 207 file1 020 file2 104
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  None
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  None
coarse_level :  -2
pts_num_coarse :  tensor([[67, 66]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  1
block_i :  0
x.shape :  torch.Size([133, 2048])
block_i :  1
x.shape :  torch.Size([133, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 133])
coarse_feats.shape :  torch.Size([1, 528, 133])
coarse_feats.shape :  torch.Size([133, 528])
coarse_level :  -2
src_mask.shape :  torch.Size([1, 67])
tgt_mask.shape :  torch.Size([1, 66])
src_ind_coarse_split.shape :  torch.Size([67])
tgt_ind_coarse_split.shape :  torch.Size([66])
src_ind_coarse.shape :  torch.Size([67])
tgt_ind_coarse.shape :  torch.Size([66])
src_feats.shape :  torch.Size([1, 67, 528])
tgt_feats.shape :  torch.Size([1, 66, 528])
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
confidence threshold used in the matching :  0.0001
preprocessing :  mutual
F0.shape : torch.Size([67, 528])
F1.shape : torch.Size([66, 528])
ldmk_t_indices :  tensor([43, 17, 10, 20, 17, 20, 15, 15, 17, 20, 26, 15, 63, 41, 55, 26, 35, 26,
        64, 49, 15, 63, 20, 36, 63, 36, 56, 43, 30, 46, 10, 30, 41, 41, 44, 30,
        53,  1, 26,  5, 30, 24, 26,  3,  6, 20,  3, 41, 15,  6,  6,  9, 20, 58,
        32, 63, 11, 49, 49, 36, 20, 15, 20, 13, 11, 64, 64], device='cuda:0')
ldmk_s.shape :  torch.Size([67, 3])
ldmk_t.shape :  torch.Size([67, 3])
vec_6d.shape :  torch.Size([67, 6])
ind.shape :  torch.Size([1, 67, 2])
bi :  0
si.shape :  torch.Size([67])
ti.shape :  torch.Size([67])
s_pos.shape :  torch.Size([67, 3])
t_pos.shape :  torch.Size([67, 3])
ind.shape :  torch.Size([1, 67, 2])
bi :  0
si.shape :  torch.Size([67])
ti.shape :  torch.Size([67])
s_pos.shape :  torch.Size([67, 3])
t_pos.shape :  torch.Size([67, 3])
number of true landmarks correspondences returned from KNN matching :  4  out of  67
fraction of true landmark correspondences returned from KNN matching :  0.05970149253731343
vec6d.shape :  torch.Size([67, 6])
ldmk_s.shape :  torch.Size([67, 3])
ldmk_t.shape :  torch.Size([67, 3])
k0 :  -8
levels :  4
posenc function :  None
samples :  2000
src_ldmk.shape in optimize_deformation_pyramid :  torch.Size([67, 3])
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
strict threshold :  0.01
relaxed threhold :  0.03
outlier threshold :  0.1
0/1: full-epe: 18.766 
full-AccS: 0.070 
full-AccR: 0.939 
full-outlier: 86.266 
vis-epe: 19.052 
vis-AccS: 0.072 
vis-AccR: 0.969 
vis-outlier: 88.052 
occ-epe: 9.813 
occ-AccS: 0.000 
occ-AccR: 0.000 
occ-outlier: 30.337 

Actual rotation :  [[ 0.73275637  0.1374364   0.66646781]
 [ 0.60033779 -0.59170884 -0.53802899]
 [ 0.32041012  0.79434998 -0.51608669]]
Actual translation :  [0.26170502 1.10936721 0.50044207]
Predicted rotation :  [[ 0.45371248  0.87693445  0.15852768]
 [ 0.72640509 -0.46698511  0.50424248]
 [ 0.51621768 -0.11362573 -0.84888658]]
Predicted translation :  [-0.00319867  0.03026122 -0.0206645 ]
Relative Rotation Error :  1.311402493697059
Relative Translation Error :  1.22727167485625
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
RMSE :  0.09115824156172479
Strict IR :  0.006021505376344086
Relaxed IR :  0.07010752688172044
