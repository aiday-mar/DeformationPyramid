model 002
feature_extractor :  kpfcn
feature extractor inside of get_dataloader :  kpfcn
coarse_level :  -3
feature extractor inside of collate_fn_4dmatch :  kpfcn
coarse_level :  -3
coarse_level :  -3
pts_num_coarse :  tensor([[453, 455]], dtype=torch.int32)


knn_matching :  True
index_at_which_to_return_coarse_feats :  2
block_i :  0
x.shape :  torch.Size([255, 2048])
block_i :  1
x.shape :  torch.Size([255, 1024])
block_i :  2
x.shape :  torch.Size([908, 1024])
coarse_feats.shape :  torch.Size([1, 1024, 908])
coarse_feats.shape :  torch.Size([1, 528, 908])
coarse_feats.shape :  torch.Size([908, 528])
data :  {'src_pcd_list': [tensor([[0.4769, 0.3043, 0.2341],
        [0.4753, 0.3030, 0.2367],
        [0.4741, 0.3013, 0.2394],
        ...,
        [0.6660, 0.1580, 0.1428],
        [0.6692, 0.1551, 0.1372],
        [0.5878, 0.1165, 0.1339]], device='cuda:0')], 'tgt_pcd_list': [tensor([[0.8783, 0.0681, 0.2151],
        [0.8811, 0.0669, 0.2160],
        [0.8840, 0.0657, 0.2168],
        ...,
        [0.8963, 0.1068, 0.1628],
        [0.9112, 0.1094, 0.1772],
        [0.9040, 0.1081, 0.1711]], device='cuda:0')], 'points': [tensor([[0.4769, 0.3043, 0.2341],
        [0.4753, 0.3030, 0.2367],
        [0.4741, 0.3013, 0.2394],
        ...,
        [0.8963, 0.1068, 0.1628],
        [0.9112, 0.1094, 0.1772],
        [0.9040, 0.1081, 0.1711]], device='cuda:0'), tensor([[0.6477, 0.1521, 0.1628],
        [0.5592, 0.1603, 0.1109],
        [0.5455, 0.1669, 0.0743],
        ...,
        [0.8754, 0.1067, 0.0315],
        [0.9491, 0.0496, 0.1245],
        [0.8516, 0.0552, 0.0508]], device='cuda:0'), tensor([[ 5.6239e-01,  1.6476e-01,  2.3592e-01],
        [ 5.3702e-01,  1.7639e-01,  2.3101e-01],
        [ 4.3532e-01,  1.9402e-01,  1.9248e-01],
        [ 5.0013e-01,  2.2073e-01,  1.3955e-01],
        [ 5.4210e-01,  2.1693e-01,  9.9829e-02],
        [ 6.2216e-01,  1.0506e-01,  1.2924e-01],
        [ 5.7912e-01,  1.7980e-01,  1.3350e-01],
        [ 5.1473e-01,  2.0193e-01,  7.7624e-02],
        [ 5.3888e-01,  2.2722e-01,  1.3466e-01],
        [ 4.5353e-01,  1.5964e-01,  1.9752e-01],
        [ 5.0061e-01,  2.5988e-01,  1.3967e-01],
        [ 5.7720e-01,  2.1894e-01,  1.2923e-01],
        [ 5.4025e-01,  2.5214e-01,  1.4897e-01],
        [ 5.7129e-01,  7.8620e-02,  1.3908e-01],
        [ 5.6774e-01,  7.5265e-02,  1.7947e-01],
        [ 4.3699e-01,  2.8407e-01,  2.1691e-01],
        [ 6.0340e-01,  1.2851e-01,  2.4281e-01],
        [ 5.1379e-01,  2.0115e-01,  2.3694e-01],
        [ 4.9531e-01,  2.5631e-01,  2.7686e-01],
        [ 6.0265e-01,  2.8186e-01,  1.3170e-01],
        [ 6.1734e-01,  1.0048e-01,  1.0048e-01],
        [ 5.7527e-01,  1.7935e-01,  9.9551e-02],
        [ 5.0566e-01,  2.5597e-01,  2.8365e-01],
        [ 4.2730e-01,  2.6230e-01,  2.2036e-01],
        [ 6.0591e-01,  1.4196e-01,  2.3730e-01],
        [ 4.4492e-01,  2.1931e-01,  1.6760e-01],
        [ 6.1168e-01,  9.5929e-02,  2.5158e-01],
        [ 6.0812e-01,  6.0666e-02,  2.3133e-01],
        [ 4.2070e-01,  2.1908e-01,  2.1903e-01],
        [ 4.2644e-01,  2.1968e-01,  1.8500e-01],
        [ 4.9969e-01,  2.1624e-01,  2.6437e-01],
        [ 4.9646e-01,  1.8002e-01,  9.4987e-02],
        [ 4.6140e-01,  2.6005e-01,  1.4080e-01],
        [ 5.1530e-01,  1.4372e-01,  2.0601e-01],
        [ 5.0585e-01,  1.4551e-01,  1.7994e-01],
        [ 5.0044e-01,  1.7970e-01,  2.1905e-01],
        [ 5.2435e-01,  1.2456e-01,  1.7895e-01],
        [ 5.3794e-01,  2.0425e-01,  7.6754e-02],
        [ 4.6829e-01,  2.8964e-01,  2.5026e-01],
        [ 4.8477e-01,  3.1198e-01,  2.1400e-01],
        [ 5.4984e-01,  1.0938e-01,  1.5664e-01],
        [ 4.8561e-01,  1.7627e-01,  1.7934e-01],
        [ 4.4114e-01,  2.7786e-01,  2.3841e-01],
        [ 4.6047e-01,  2.1992e-01,  1.5112e-01],
        [ 4.3640e-01,  2.8412e-01,  1.9379e-01],
        [ 5.0682e-01,  1.5052e-01,  1.4388e-01],
        [ 5.7643e-01,  1.3650e-01,  1.3513e-01],
        [ 4.6448e-01,  1.8913e-01,  1.5652e-01],
        [ 4.3581e-01,  2.6107e-01,  1.8280e-01],
        [ 6.4074e-01,  1.5958e-01,  1.1725e-01],
        [ 5.5733e-01,  1.7750e-01,  1.3120e-01],
        [ 6.1345e-01,  2.1837e-01,  1.1225e-01],
        [ 5.7172e-01,  9.1790e-02,  2.2871e-01],
        [ 4.8816e-01,  3.2431e-01,  1.7605e-01],
        [ 5.4159e-01,  1.4036e-01,  9.9521e-02],
        [ 4.5486e-01,  3.0502e-01,  1.8069e-01],
        [ 4.5674e-01,  2.6273e-01,  2.6276e-01],
        [ 5.3817e-01,  1.7966e-01,  7.1602e-02],
        [ 5.1703e-01,  1.5729e-01,  7.7594e-02],
        [ 4.3349e-01,  2.2090e-01,  2.4868e-01],
        [ 4.6721e-01,  3.3100e-01,  1.4040e-01],
        [ 5.7536e-01,  1.0127e-01,  1.3576e-01],
        [ 6.4766e-01,  1.5212e-01,  1.6285e-01],
        [ 5.4076e-01,  1.3985e-01,  1.4093e-01],
        [ 4.5933e-01,  2.9994e-01,  2.2099e-01],
        [ 5.5740e-01,  1.7983e-01,  9.7756e-02],
        [ 5.0598e-01,  1.5313e-01,  1.0314e-01],
        [ 4.6843e-01,  3.2249e-01,  1.7135e-01],
        [ 6.5951e-01,  1.1820e-01,  1.3669e-01],
        [ 4.6070e-01,  1.7901e-01,  1.7906e-01],
        [ 6.5865e-01,  1.4177e-01,  1.3849e-01],
        [ 4.5453e-01,  1.5956e-01,  2.0172e-01],
        [ 5.2528e-01,  2.2149e-01,  2.7639e-01],
        [ 6.0603e-01,  2.5851e-01,  1.1191e-01],
        [ 5.7398e-01,  1.4434e-01,  2.3820e-01],
        [ 4.5915e-01,  1.7984e-01,  2.1872e-01],
        [ 5.0467e-01,  1.8062e-01,  7.5627e-02],
        [ 4.3645e-01,  2.5208e-01,  2.5146e-01],
        [ 5.8501e-01,  9.9051e-02,  1.0511e-01],
        [ 5.3359e-01,  2.9930e-01,  1.6153e-01],
        [ 5.6163e-01,  8.2854e-02,  1.7793e-01],
        [ 5.7978e-01,  7.7017e-02,  2.2064e-01],
        [ 5.4036e-01,  2.4358e-01,  2.8180e-01],
        [ 6.0708e-01,  1.6470e-01,  1.0143e-01],
        [ 5.7566e-01,  2.6501e-01,  1.3973e-01],
        [ 5.8541e-01,  2.5413e-01,  1.1434e-01],
        [ 5.3637e-01,  1.4014e-01,  2.2376e-01],
        [ 4.8816e-01,  1.7946e-01,  1.3934e-01],
        [ 4.4409e-01,  2.6659e-01,  1.7286e-01],
        [ 5.0148e-01,  1.8569e-01,  2.4701e-01],
        [ 5.3190e-01,  3.0021e-01,  1.4791e-01],
        [ 5.4612e-01,  1.0699e-01,  2.1842e-01],
        [ 5.8005e-01,  2.2183e-01,  1.0639e-01],
        [ 6.8267e-01,  1.4906e-01,  1.3277e-01],
        [ 5.8081e-01,  7.7890e-02,  1.0384e-01],
        [ 5.4428e-01,  2.5942e-01,  1.7358e-01],
        [ 4.6195e-01,  1.9584e-01,  2.4688e-01],
        [ 5.0485e-01,  3.0064e-01,  1.3518e-01],
        [ 5.3788e-01,  1.5421e-01,  7.7300e-02],
        [ 4.5747e-01,  2.1704e-01,  2.6218e-01],
        [ 4.9425e-01,  3.2660e-01,  1.4503e-01],
        [ 6.4926e-01,  1.6975e-01,  1.3022e-01],
        [ 6.1695e-01,  6.6388e-02,  2.5830e-01],
        [ 5.7233e-01,  2.6911e-01,  1.7330e-01],
        [ 6.1917e-01,  1.7696e-01,  1.3902e-01],
        [ 6.1404e-01,  1.4537e-01,  1.0802e-01],
        [ 5.3113e-01,  2.2452e-01,  2.9232e-01],
        [ 5.1335e-01,  2.2216e-01,  2.8858e-01],
        [ 5.8461e-01,  1.3903e-01,  9.9532e-02],
        [ 4.9575e-01,  3.1687e-01,  1.8816e-01],
        [ 5.8140e-01,  1.3676e-01,  2.4200e-01],
        [ 6.0395e-01,  2.7466e-01,  1.2352e-01],
        [ 5.3634e-01,  1.7808e-01,  2.4833e-01],
        [ 5.8110e-01,  2.8721e-01,  1.3898e-01],
        [ 5.4287e-01,  1.0219e-01,  1.8062e-01],
        [ 4.8029e-01,  3.0121e-01,  2.4260e-01],
        [ 4.3370e-01,  1.8370e-01,  2.1844e-01],
        [ 5.0391e-01,  2.0659e-01,  1.0172e-01],
        [ 4.5750e-01,  2.9994e-01,  1.3679e-01],
        [ 6.1877e-01,  1.3831e-01,  1.4258e-01],
        [ 6.1628e-01,  2.1276e-01,  1.2231e-01],
        [ 5.8330e-01,  1.0362e-01,  2.4409e-01],
        [ 4.3847e-01,  2.2026e-01,  1.5748e-01],
        [ 8.5481e-01,  3.5450e-02,  5.4701e-02],
        [ 8.2288e-01,  3.3952e-02,  1.0498e-01],
        [ 7.9816e-01,  6.6393e-02,  1.1208e-01],
        [ 9.2129e-01,  2.9557e-02, -1.2024e-03],
        [ 9.3693e-01, -5.1210e-04,  1.3534e-01],
        [ 8.7776e-01,  3.6409e-02, -2.2323e-02],
        [ 8.9942e-01,  6.4929e-02,  2.0782e-01],
        [ 8.2603e-01,  6.1496e-02,  1.7246e-01],
        [ 1.0267e+00,  1.2549e-01, -1.1135e-02],
        [ 8.8332e-01,  1.1454e-01,  2.0323e-02],
        [ 8.8137e-01,  1.1819e-01,  4.6723e-02],
        [ 8.6647e-01,  1.4041e-01, -1.6861e-02],
        [ 8.8648e-01,  1.5536e-01, -1.5974e-03],
        [ 9.8338e-01,  9.3182e-02,  1.0398e-01],
        [ 9.7935e-01,  1.0318e-01,  1.2615e-01],
        [ 1.0018e+00,  1.1508e-01,  1.2142e-01],
        [ 8.9436e-01,  3.0881e-02, -1.3477e-02],
        [ 9.1865e-01,  4.1052e-02,  1.1892e-01],
        [ 9.0041e-01,  1.3694e-01,  1.6933e-02],
        [ 9.2082e-01,  7.8497e-02,  1.9453e-01],
        [ 9.1292e-01,  1.6167e-01,  1.6113e-03],
        [ 9.4340e-01, -2.1208e-03,  7.6267e-02],
        [ 9.3526e-01,  1.0004e-01,  1.2238e-01],
        [ 9.4435e-01,  9.6555e-02,  1.0944e-01],
        [ 8.9718e-01,  6.1200e-02,  1.7810e-01],
        [ 9.8146e-01,  9.6916e-02,  5.6891e-02],
        [ 8.7993e-01,  1.0739e-02,  2.0024e-01],
        [ 9.5784e-01,  1.2606e-01,  1.2125e-01],
        [ 9.7678e-01, -3.3711e-03,  9.0260e-02],
        [ 9.2317e-01,  3.2227e-02,  1.0541e-03],
        [ 7.8333e-01,  6.2631e-02,  1.4429e-01],
        [ 1.0019e+00,  4.6140e-02,  7.3524e-02],
        [ 8.5724e-01,  1.0727e-01,  1.8110e-01],
        [ 8.0929e-01,  5.7940e-02,  1.4389e-01],
        [ 8.3318e-01,  2.3597e-02,  1.6760e-01],
        [ 1.0129e+00,  1.0478e-01,  4.8483e-03],
        [ 9.0104e-01,  1.1701e-01,  1.1424e-01],
        [ 9.0099e-01,  1.0119e-01,  1.4046e-01],
        [ 9.6427e-01,  1.6108e-01, -1.3591e-02],
        [ 9.5625e-01,  1.5802e-01, -2.6692e-03],
        [ 1.0255e+00,  9.8553e-02, -1.4597e-02],
        [ 8.7419e-01,  1.2084e-01,  9.8008e-02],
        [ 7.8295e-01,  6.2222e-02,  1.6468e-01],
        [ 9.3024e-01,  1.4286e-02,  7.1231e-02],
        [ 8.7357e-01,  1.3538e-01, -4.5024e-02],
        [ 9.7895e-01,  1.5363e-01, -5.5738e-03],
        [ 9.1508e-01,  2.3025e-02,  6.5884e-02],
        [ 9.3669e-01,  1.4525e-01,  5.6505e-02],
        [ 1.0487e+00,  1.1663e-01, -4.0397e-02],
        [ 9.0597e-01,  1.3331e-01,  6.0968e-02],
        [ 8.2324e-01,  2.5225e-02,  1.3997e-01],
        [ 1.0016e+00,  1.3359e-01,  1.2127e-01],
        [ 9.2216e-01,  9.7503e-02,  2.0373e-01],
        [ 8.9279e-01,  5.8667e-02, -1.6296e-02],
        [ 8.7639e-01,  1.2077e-01,  7.5612e-02],
        [ 8.5773e-01,  1.0224e-01,  5.7748e-02],
        [ 9.8095e-01,  1.5566e-01,  1.0030e-01],
        [ 9.0759e-01,  1.0332e-01,  1.7600e-01],
        [ 8.7761e-01,  6.3292e-02, -5.5890e-02],
        [ 9.0193e-01,  2.2587e-02,  1.8285e-01],
        [ 1.0074e+00,  1.3459e-01,  5.2074e-03],
        [ 9.4384e-01,  2.4536e-02,  9.4438e-02],
        [ 8.5776e-01,  1.1675e-01,  1.0057e-01],
        [ 9.0187e-01,  2.0860e-02,  1.4178e-01],
        [ 9.7818e-01,  1.4575e-01,  5.6700e-02],
        [ 9.3721e-01,  1.6237e-01,  2.3747e-03],
        [ 8.6338e-01,  6.8746e-02,  2.0388e-01],
        [ 1.0012e+00,  2.5519e-02,  8.2400e-02],
        [ 9.0202e-01,  1.8094e-01, -1.6212e-02],
        [ 8.2781e-01,  6.7678e-02,  6.4447e-02],
        [ 1.0065e+00,  1.2081e-01,  6.8619e-02],
        [ 9.3605e-01,  3.3634e-02,  1.3460e-01],
        [ 1.0015e+00,  4.5688e-02,  8.2899e-02],
        [ 8.7203e-01,  1.1735e-01,  2.0134e-01],
        [ 8.7844e-01,  1.2085e-01,  2.0477e-01],
        [ 1.0040e+00,  1.0020e-01,  1.0376e-01],
        [ 9.4112e-01,  1.4035e-01,  2.4168e-02],
        [ 8.5510e-01,  5.4793e-02,  1.8953e-01],
        [ 1.0023e+00,  2.4233e-02,  7.6369e-02],
        [ 9.4126e-01,  1.3774e-01,  9.8735e-02],
        [ 8.5561e-01,  2.2692e-02,  1.8450e-01],
        [ 8.6368e-01,  1.7536e-01, -1.2700e-02],
        [ 9.8350e-01,  1.6034e-01,  9.4682e-02],
        [ 8.9267e-01,  1.2257e-01,  1.8711e-01],
        [ 8.7065e-01,  9.5968e-02, -5.6029e-02],
        [ 1.0083e+00,  1.4008e-01,  1.0187e-01],
        [ 9.2040e-01,  7.4121e-03,  1.7008e-01],
        [ 9.2224e-01,  9.7326e-02,  1.9252e-01],
        [ 8.8011e-01,  6.8273e-02, -5.5104e-02],
        [ 8.2981e-01,  8.9785e-02,  6.9728e-02],
        [ 8.7722e-01,  1.2162e-01,  1.8412e-01],
        [ 1.0052e+00,  1.1359e-01,  5.6309e-02],
        [ 9.5200e-01, -2.8634e-03,  8.7621e-02],
        [ 8.2211e-01,  9.7004e-02,  1.0198e-01],
        [ 9.9103e-01,  7.3131e-02, -2.0928e-03],
        [ 8.1438e-01,  6.0174e-02,  9.5375e-02],
        [ 7.7528e-01,  8.9985e-02,  1.3621e-01],
        [ 9.7870e-01,  1.3743e-01,  1.9015e-02],
        [ 9.0691e-01,  2.6638e-02,  9.6031e-02],
        [ 1.0437e+00,  1.1580e-01, -3.5293e-02],
        [ 9.0036e-01,  1.2343e-01,  9.7081e-02],
        [ 8.6633e-01,  1.7375e-01,  2.2511e-03],
        [ 9.3211e-01,  1.7316e-01, -1.8441e-02],
        [ 8.4581e-01,  6.0679e-02,  5.6242e-02],
        [ 8.6749e-01,  1.4844e-01,  9.2512e-04],
        [ 9.8029e-01,  1.3670e-01,  1.2503e-01],
        [ 8.9771e-01,  1.2554e-02,  2.0240e-01],
        [ 9.1140e-01,  1.0920e-01,  2.1335e-01],
        [ 8.7706e-01,  6.6971e-02, -2.6525e-02],
        [ 9.8024e-01,  1.9309e-02,  9.8976e-02],
        [ 7.5913e-01,  7.4234e-02,  1.4090e-01],
        [ 8.9812e-01,  3.3084e-02,  1.6183e-02],
        [ 8.2126e-01,  9.7817e-02,  1.3959e-01],
        [ 9.8512e-01,  7.6946e-02,  2.0540e-02],
        [ 8.8041e-01,  8.1202e-02, -4.8953e-03],
        [ 9.8283e-01,  1.0254e-01,  2.1554e-02],
        [ 9.1017e-01,  5.5931e-02,  1.4501e-01],
        [ 7.8344e-01,  8.0952e-02,  1.6153e-01],
        [ 9.5656e-01,  6.2122e-02,  7.7823e-02],
        [ 7.5972e-01,  8.2667e-02,  1.4672e-01],
        [ 8.9104e-01,  5.2515e-02,  1.0521e-02],
        [ 9.7886e-01,  5.3603e-02,  9.1365e-02],
        [ 9.3394e-01,  6.1071e-02,  1.3028e-01],
        [ 8.3151e-01,  8.5515e-02,  1.7600e-01],
        [ 9.8321e-01,  6.1925e-02,  6.5297e-02],
        [ 8.5967e-01,  1.1467e-01,  1.3996e-01],
        [ 1.0036e+00,  7.5325e-02,  2.3257e-02],
        [ 9.4106e-01,  5.9437e-02,  1.0035e-01],
        [ 8.6791e-01,  6.3972e-02,  2.6647e-02],
        [ 8.7154e-01,  9.5493e-02,  2.3407e-02],
        [ 8.9748e-01,  1.2310e-01,  2.0774e-01],
        [ 8.7007e-01,  1.0043e-01, -1.9928e-02]], device='cuda:0'), tensor([[ 0.5723,  0.2691,  0.1733],
        [ 0.4943,  0.3266,  0.1450],
        [ 0.4684,  0.3225,  0.1713],
        [ 0.6477,  0.1521,  0.1628],
        [ 0.6493,  0.1698,  0.1302],
        [ 0.4510,  0.2113,  0.2526],
        [ 0.4882,  0.3243,  0.1760],
        [ 0.6604,  0.1422,  0.1313],
        [ 0.4545,  0.2098,  0.1550],
        [ 0.6169,  0.0664,  0.2583],
        [ 0.5290,  0.1386,  0.1288],
        [ 0.5146,  0.2969,  0.1843],
        [ 0.4538,  0.2682,  0.2548],
        [ 0.5285,  0.1272,  0.1980],
        [ 0.4595,  0.2800,  0.1388],
        [ 0.5179,  0.2080,  0.2695],
        [ 0.5960,  0.1966,  0.1180],
        [ 0.5992,  0.1206,  0.1195],
        [ 0.4401,  0.1992,  0.1972],
        [ 0.5239,  0.1916,  0.0754],
        [ 0.5783,  0.1152,  0.2205],
        [ 0.5624,  0.1648,  0.2359],
        [ 0.5194,  0.2782,  0.1429],
        [ 0.5092,  0.1834,  0.2166],
        [ 0.5230,  0.1985,  0.1174],
        [ 0.5949,  0.1162,  0.2451],
        [ 0.4540,  0.1596,  0.1996],
        [ 0.5760,  0.0783,  0.1215],
        [ 0.4672,  0.3310,  0.1404],
        [ 0.5054,  0.2643,  0.2712],
        [ 0.5275,  0.1558,  0.0774],
        [ 0.5852,  0.0710,  0.2105],
        [ 0.4420,  0.2801,  0.2034],
        [ 0.5925,  0.2702,  0.1267],
        [ 0.8663,  0.1738,  0.0023],
        [ 0.9835,  0.1603,  0.0947],
        [ 0.9171,  0.1770, -0.0173],
        [ 0.8606,  0.1113,  0.0455],
        [ 0.9089,  0.1088,  0.1967],
        [ 1.0462,  0.1162, -0.0378],
        [ 0.8470,  0.1094,  0.1160],
        [ 0.9643,  0.1611, -0.0136],
        [ 0.8633,  0.1105,  0.1895],
        [ 0.7830,  0.0622,  0.1647],
        [ 0.9952,  0.0569,  0.0518],
        [ 0.9190,  0.0362,  0.0404],
        [ 0.7834,  0.0810,  0.1615],
        [ 0.9941,  0.1195,  0.0361],
        [ 0.9259,  0.1146,  0.1148],
        [ 0.9768, -0.0034,  0.0903],
        [ 0.8775,  0.0556, -0.0349],
        [ 0.9445, -0.0017,  0.1115],
        [ 0.8971,  0.0468, -0.0215],
        [ 0.9910,  0.0731, -0.0021],
        [ 0.7802,  0.0678,  0.1324],
        [ 0.9904,  0.0360,  0.0889],
        [ 0.8702,  0.1180, -0.0345],
        [ 0.8491,  0.0569,  0.0505],
        [ 0.8174,  0.0443,  0.1211],
        [ 0.9077,  0.1315, -0.0031],
        [ 0.9062,  0.0412,  0.1893],
        [ 0.8522,  0.0403,  0.1864],
        [ 0.9081,  0.1314,  0.0376],
        [ 0.7675,  0.0863,  0.1415],
        [ 1.0104,  0.1259, -0.0104],
        [ 0.9241,  0.0404,  0.1202],
        [ 0.8637,  0.1754, -0.0127],
        [ 0.9925,  0.1222,  0.1130],
        [ 0.9251,  0.1620,  0.0020],
        [ 0.9434, -0.0021,  0.0763]], device='cuda:0')], 'neighbors': [tensor([[    0,    43,  1999,  ..., 18512, 18512, 18512],
        [    1,    43,    46,  ..., 18512, 18512, 18512],
        [    2,    60,     3,  ..., 18512, 18512, 18512],
        ...,
        [18509, 16092, 18500,  ..., 18512, 18512, 18512],
        [18510, 16102, 18502,  ..., 18512, 18512, 18512],
        [18511, 18508, 16610,  ..., 18512, 18512, 18512]], device='cuda:0'), tensor([[  0, 412, 380,  ..., 908, 908, 908],
        [  1,   3,   4,  ..., 151, 306,  75],
        [  2, 379, 391,  ..., 908, 908, 908],
        ...,
        [905, 759, 723,  ..., 584, 830, 908],
        [906, 614, 611,  ..., 559, 552, 571],
        [907, 584, 867,  ..., 908, 908, 908]], device='cuda:0'), tensor([[  0,  74,   1,  ..., 255, 255, 255],
        [  1, 112,   0,  ..., 255, 255, 255],
        [  2, 116,  29,  ..., 255, 255, 255],
        ...,
        [252, 132, 251,  ..., 170, 216, 169],
        [253, 197, 230,  ..., 255, 255, 255],
        [254, 237, 231,  ..., 255, 255, 255]], device='cuda:0'), tensor([[ 0, 33, 22,  ..., 26, 25, 27],
        [ 1, 28,  6,  ..., 70, 70, 70],
        [ 2,  6, 28,  ..., 70, 70, 70],
        ...,
        [67, 35, 48,  ..., 56, 58, 50],
        [68, 36, 59,  ..., 70, 70, 70],
        [69, 51, 49,  ..., 39, 43, 46]], device='cuda:0')], 'pools': [tensor([[ 9368,  9364,  9370,  ..., 18512, 18512, 18512],
        [ 9345,  9346,  9352,  ..., 18512, 18512, 18512],
        [ 9290,  9302,  9287,  ..., 18512, 18512, 18512],
        ...,
        [14504, 14523, 14453,  ..., 18512, 18512, 18512],
        [17070, 17553, 17079,  ..., 18512, 18512, 18512],
        [15337, 15351, 15308,  ..., 18512, 18512, 18512]], device='cuda:0'), tensor([[452, 444,  96,  ..., 908, 908, 908],
        [442, 446, 440,  ..., 908, 908, 908],
        [400, 330, 409,  ..., 207, 142, 443],
        ...,
        [723, 905, 823,  ..., 908, 908, 908],
        [749, 901, 508,  ..., 908, 908, 908],
        [612, 637, 760,  ..., 908, 908, 908]], device='cuda:0'), tensor([[103,  95,  84,  ..., 255, 255, 255],
        [100,  60,  97,  ..., 255, 255, 255],
        [ 67,  53,  55,  ..., 255, 255, 255],
        ...,
        [138, 174, 228,  ..., 255, 255, 255],
        [143, 188, 225,  ..., 255, 255, 255],
        [144, 215, 166,  ..., 255, 255, 255]], device='cuda:0'), tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)], 'upsamples': [tensor([[200, 101, 107,  ..., 908, 908, 908],
        [101, 107, 200,  ..., 908, 908, 908],
        [101, 107, 200,  ..., 908, 908, 908],
        ...,
        [615, 654, 509,  ..., 908, 908, 908],
        [509, 650, 670,  ..., 908, 908, 908],
        [509, 615, 819,  ..., 908, 908, 908]], device='cuda:0'), tensor([[ 62,  70, 101,  ..., 255, 255, 255],
        [ 65,  50,  21,  ...,  49,  20,  36],
        [ 57,  98,  65,  ..., 255, 255, 255],
        ...,
        [252, 132, 133,  ..., 207, 128, 216],
        [245, 194, 250,  ..., 142, 159, 138],
        [226, 123, 192,  ..., 173, 255, 255]], device='cuda:0'), tensor([[21, 20, 25,  ..., 70, 70, 70],
        [21, 23, 15,  ..., 28, 70, 70],
        [18, 26,  8,  ..., 70, 70, 70],
        ...,
        [37, 57, 62,  ..., 38, 60, 39],
        [38, 42, 60,  ..., 70, 70, 70],
        [56, 50, 59,  ..., 70, 70, 70]], device='cuda:0'), tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)], 'features': tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0'), 'stack_lengths': [tensor([9380, 9132], device='cuda:0', dtype=torch.int32), tensor([453, 455], device='cuda:0', dtype=torch.int32), tensor([123, 132], device='cuda:0', dtype=torch.int32), tensor([34, 36], device='cuda:0', dtype=torch.int32)], 'coarse_matches': [tensor([[  3,   4,   5,   6,  13,  23,  26,  27,  51,  53,  56,  58,  72,  77,
          80,  84,  87,  88,  89,  92,  95, 117, 137, 139, 149, 160, 163, 174,
         175, 184, 187, 188, 197, 198, 201, 210, 222, 239, 242, 249, 267, 269,
         287, 289, 303, 305, 307, 308, 310, 312, 313, 316, 331, 344, 346, 350,
         357, 363, 364, 372, 394, 403, 419, 428],
        [550, 570, 587, 547, 637, 834, 828, 548, 755, 592, 663, 539, 885, 473,
         768, 503, 779, 883, 833, 898, 797, 692, 459, 710, 565, 714, 884, 462,
         590, 676, 743, 686, 469, 575, 783, 763, 461, 706, 851, 881, 622, 701,
         594, 737, 862, 465, 636, 679, 642, 588, 558, 576, 853, 646, 886, 603,
         780, 889, 695, 625, 760, 647, 470, 466]], device='cuda:0')], 'coarse_flow': [tensor([[ 0.1348, -0.0581, -0.0844],
        [-0.0041,  0.0190, -0.0672],
        [-0.0463,  0.0491, -0.1067],
        ...,
        [ 0.0678, -0.0178, -0.1237],
        [ 0.0000,  0.0000,  0.0000],
        [ 0.0975, -0.0536,  0.0894]], device='cuda:0')], 'src_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True]],
       device='cuda:0'), 'tgt_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True]],
       device='cuda:0'), 'src_ind_coarse_split': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
        448, 449, 450, 451, 452], device='cuda:0'), 'tgt_ind_coarse_split': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
        448, 449, 450, 451, 452, 453, 454], device='cuda:0'), 'src_ind_coarse': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
        448, 449, 450, 451, 452], device='cuda:0'), 'tgt_ind_coarse': tensor([453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466,
        467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,
        481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,
        495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508,
        509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522,
        523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536,
        537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,
        551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,
        565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578,
        579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592,
        593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606,
        607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620,
        621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634,
        635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648,
        649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,
        663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676,
        677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690,
        691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704,
        705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718,
        719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,
        733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746,
        747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760,
        761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774,
        775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788,
        789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802,
        803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816,
        817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830,
        831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,
        845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858,
        859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872,
        873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886,
        887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900,
        901, 902, 903, 904, 905, 906, 907], device='cuda:0'), 'batched_rot': tensor([[[-0.0151,  0.6491, -0.7606],
         [ 0.4767,  0.6734,  0.5651],
         [ 0.8790, -0.3540, -0.3196]]], device='cuda:0'), 'batched_trn': tensor([[[ 0.9373],
         [-0.4066],
         [-0.2994]]], device='cuda:0'), 'sflow_list': [tensor([[ 0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000],
        ...,
        [ 0.1352, -0.0547, -0.1224],
        [ 0.1349, -0.0568, -0.1364],
        [ 0.0741, -0.0265, -0.0858]], device='cuda:0')], 'correspondences_list': [tensor([[ 221, 4844],
        [ 224, 4934],
        [ 225, 4901],
        ...,
        [9379, 2428],
        [9379, 2346],
        [9379, 2355]], device='cuda:0')], 'depth_paths_list': {0: None}, 'cam_intrin': None, 'src_pcd_colors_list': [tensor([[0.5098, 0.2902, 0.1647],
        [0.5020, 0.2824, 0.1569],
        [0.5098, 0.3020, 0.1804],
        ...,
        [0.4000, 0.2863, 0.2314],
        [0.5333, 0.5020, 0.4863],
        [0.6353, 0.6353, 0.6431]], device='cuda:0', dtype=torch.float64)]}
coarse_level :  -3
src_mask.shape :  torch.Size([1, 453])
tgt_mask.shape :  torch.Size([1, 455])
src_ind_coarse_split.shape :  torch.Size([453])
tgt_ind_coarse_split.shape :  torch.Size([455])
src_ind_coarse.shape :  torch.Size([453])
tgt_ind_coarse.shape :  torch.Size([455])
src_feats.shape :  torch.Size([1, 453, 528])
tgt_feats.shape :  torch.Size([1, 455, 528])
confidence threshold used in the matching :  1e-06
preprocessing :  none
confidence threshold used in the matching :  1e-06
preprocessing :  none
F0.shape : torch.Size([453, 528])
F1.shape : torch.Size([455, 528])
ldmk_t_indices :  tensor([ 55, 109, 104, 132, 118, 109, 109, 412,  70, 412, 132, 109, 148, 148,
        331, 428, 165, 331, 331, 331, 331, 331, 132, 148,   2, 109, 109, 109,
          2, 428, 132, 132, 428, 100, 148, 109,   2,  81, 215, 404, 404, 404,
        404, 428, 428, 148, 122, 428, 148, 122, 148, 428, 109, 109, 148, 148,
        112, 148, 109, 112,  81, 109, 109, 148, 109, 148, 112, 148, 112, 109,
        428, 148, 428, 132, 165, 100, 148, 217, 148, 233, 148, 167,  57, 239,
        217,  57, 296,   0, 428, 398, 202, 227, 227,  70, 233, 148, 167, 100,
        100,  57,  57, 167, 233, 148, 167, 227, 217, 167, 148,  93, 109, 104,
         78, 233,  80,  78,  78,   0, 404,   0,  23,  23,  70, 190, 159,  78,
        104, 331, 196, 428, 190, 331, 196,   0, 428, 190, 190, 217, 202, 148,
        124, 167, 159,   0,  57,  80, 331, 104,  70, 202, 215, 104, 331, 233,
        388, 104, 317,   0, 190, 331, 227, 190, 167, 148, 412, 196, 202, 112,
        167, 148, 412, 190, 196, 412, 122, 331, 190,  93,  14, 190, 412,  23,
          0, 167,  14, 190,  23, 412, 148, 148, 190, 412, 190,  23, 398, 190,
        202, 217, 148, 412, 190,   0, 398, 202, 190, 196, 412, 148, 148,  70,
        233, 398, 331, 412,   0, 196, 404, 112,  57, 148, 196, 412, 122, 412,
        227, 190, 167, 124, 412, 196, 428, 190, 167, 428, 398, 398, 196, 124,
        202, 217,  23, 398, 428, 148, 412, 190, 296, 123, 332, 428, 317, 202,
        124, 428, 100, 123, 428,  80, 167, 428, 133, 233, 388, 412, 100, 317,
        296,   0, 190,  70, 233, 202, 428, 233, 100, 412, 196,   0, 167, 196,
        227, 190,   0, 104, 331, 192, 296, 202, 123, 192, 388, 233, 331, 264,
        202, 123, 428, 239,  57, 331, 332, 123, 331, 192, 331, 104, 118, 123,
        227, 296, 192, 192, 192, 192,  81, 118, 118,  81, 118, 331, 215, 331,
        109, 331, 215, 233,  80, 331, 215,  93, 165, 118,  81,   2, 167, 388,
        159, 331, 159, 388, 159,  80, 109, 428,  81,   2, 428, 100, 167,  80,
        192, 388, 159, 159, 109, 264, 331, 159, 109, 159, 331, 104, 109, 217,
        215, 109, 109, 159, 109, 112, 159,  57,   0, 217, 404, 217, 192, 217,
        100, 104, 331, 192, 104, 331, 264, 100, 331, 133, 165, 264, 148, 104,
        331, 109, 148, 122, 109, 148, 331, 428, 165, 331, 264,  80, 109, 331,
        331, 215, 428,  80, 331, 264,  55, 109, 109, 100, 100, 331, 104, 264,
        165, 404, 104, 109, 109, 196, 109, 388, 233,  70, 159, 388, 167, 332,
         57, 148, 233, 165, 123, 148,  93, 148,  93, 148,  93, 148,  93, 148,
        148, 148, 100, 148,  57], device='cuda:0')
ldmk_s.shape :  torch.Size([453, 3])
ldmk_t.shape :  torch.Size([453, 3])
vec_6d.shape :  torch.Size([453, 6])
ind.shape :  torch.Size([1, 453, 2])
bi :  0
si.shape :  torch.Size([453])
ti.shape :  torch.Size([453])
s_pos.shape :  torch.Size([453, 3])
t_pos.shape :  torch.Size([453, 3])
ind.shape :  torch.Size([1, 453, 2])
bi :  0
si.shape :  torch.Size([453])
ti.shape :  torch.Size([453])
s_pos.shape :  torch.Size([453, 3])
t_pos.shape :  torch.Size([453, 3])
number of true landmarks correspondences returned from KNN matching :  14  out of  453
fraction of true landmark correspondences returned from KNN matching :  0.03090507726269316
vec6d.shape :  torch.Size([453, 6])
ldmk_s.shape :  torch.Size([453, 3])
ldmk_t.shape :  torch.Size([453, 3])
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(AlignAndNonRigidMerge) {
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L167:#points1: 453
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L168:#points2: 453
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L169:#matches: 453
Before Run of ransac
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(SquentialRANSAC) {
num_inliers : 69
num_inliers : 35
num_inliers : 41
num_inliers : 21
num_inliers : 40
num_inliers : 84
num_inliers : 192
num_inliers : 124
num_inliers : 24
num_inliers : 26
num_inliers : 68
num_inliers : 155
num_inliers : 98
num_inliers : 92
num_inliers : 90
num_inliers : 65
num_inliers : 68
num_inliers : 40
num_inliers : 19
num_inliers : 58
num_inliers : 56
num_inliers : 97
num_inliers : 27
num_inliers : 15
num_inliers : 14
num_inliers : 50
num_inliers : 65
num_inliers : 140
num_inliers : 168
num_inliers : 22
num_inliers : 77
num_inliers : 61
num_inliers : 103
num_inliers : 30
num_inliers : 19
num_inliers : 86
num_inliers : 119
num_inliers : 111
num_inliers : 53
num_inliers : 12
num_inliers : 31
num_inliers : 69
num_inliers : 24
num_inliers : 68
num_inliers : 105
num_inliers : 90
num_inliers : 44
num_inliers : 106
num_inliers : 16
num_inliers : 56
num_inliers : 37
num_inliers : 52
num_inliers : 14
num_inliers : 80
num_inliers : 9
num_inliers : 28
num_inliers : 64
num_inliers : 57
num_inliers : 78
num_inliers : 104
num_inliers : 24
num_inliers : 108
num_inliers : 20
num_inliers : 122
num_inliers : 70
num_inliers : 86
num_inliers : 41
num_inliers : 65
num_inliers : 182
num_inliers : 85
num_inliers : 27
num_inliers : 47
num_inliers : 92
num_inliers : 69
num_inliers : 38
num_inliers : 24
num_inliers : 26
num_inliers : 25
num_inliers : 142
num_inliers : 31
num_inliers : 29
num_inliers : 37
num_inliers : 95
num_inliers : 41
num_inliers : 38
num_inliers : 14
num_inliers : 87
num_inliers : 33
num_inliers : 136
num_inliers : 60
num_inliers : 69
num_inliers : 55
num_inliers : 36
num_inliers : 59
num_inliers : 8
num_inliers : 52
num_inliers : 41
num_inliers : 27
num_inliers : 66
num_inliers : 36
num_inliers : 41
num_inliers inside of Run : 192
num_inliers : 42
num_inliers : 17
num_inliers : 35
num_inliers : 37
num_inliers : 34
num_inliers : 15
num_inliers : 49
num_inliers : 59
num_inliers : 116
num_inliers : 27
num_inliers : 100
num_inliers : 9
num_inliers : 12
num_inliers : 53
num_inliers : 52
num_inliers : 77
num_inliers : 35
num_inliers : 102
num_inliers : 42
num_inliers : 35
num_inliers : 17
num_inliers : 37
num_inliers : 43
num_inliers : 56
num_inliers : 82
num_inliers : 62
num_inliers : 69
num_inliers : 38
num_inliers : 48
num_inliers : 14
num_inliers : 53
num_inliers : 17
num_inliers : 34
num_inliers : 104
num_inliers : 31
num_inliers : 26
num_inliers : 48
num_inliers : 92
num_inliers : 16
num_inliers : 103
num_inliers : 4
num_inliers : 46
num_inliers : 23
num_inliers : 26
num_inliers : 56
num_inliers : 28
num_inliers : 47
num_inliers : 17
num_inliers : 30
num_inliers : 18
num_inliers : 102
num_inliers : 10
num_inliers : 31
num_inliers : 8
num_inliers : 18
num_inliers : 20
num_inliers : 21
num_inliers : 13
num_inliers : 4
num_inliers : 30
num_inliers : 37
num_inliers : 80
num_inliers : 30
num_inliers : 16
num_inliers : 4
num_inliers : 56
num_inliers : 55
num_inliers : 13
num_inliers : 7
num_inliers : 18
num_inliers : 19
num_inliers : 76
num_inliers : 23
num_inliers : 65
num_inliers : 52
num_inliers : 74
num_inliers : 42
num_inliers : 22
num_inliers : 51
num_inliers : 26
num_inliers : 15
num_inliers : 12
num_inliers : 90
num_inliers : 39
num_inliers : 33
num_inliers : 11
num_inliers : 5
num_inliers : 34
num_inliers : 24
num_inliers : 57
num_inliers : 11
num_inliers : 90
num_inliers : 42
num_inliers : 77
num_inliers : 28
num_inliers : 19
num_inliers : 108
num_inliers : 5
num_inliers : 41
num_inliers : 33
num_inliers : 29
num_inliers inside of Run : 116
num_inliers : 24
num_inliers : 25
num_inliers : 32
num_inliers : 22
num_inliers : 22
num_inliers : 23
num_inliers : 26
num_inliers : 39
num_inliers : 30
num_inliers : 13
num_inliers : 4
num_inliers : 40
num_inliers : 28
num_inliers : 19
num_inliers : 20
num_inliers : 28
num_inliers : 12
num_inliers : 10
num_inliers : 25
num_inliers : 21
num_inliers : 37
num_inliers : 11
num_inliers : 9
num_inliers : 27
num_inliers : 4
num_inliers : 35
num_inliers : 15
num_inliers : 24
num_inliers : 14
num_inliers : 25
num_inliers : 17
num_inliers : 23
num_inliers : 16
num_inliers : 16
num_inliers : 25
num_inliers : 24
num_inliers : 26
num_inliers : 18
num_inliers : 25
num_inliers : 10
num_inliers : 30
num_inliers : 27
num_inliers : 33
num_inliers : 24
num_inliers : 22
num_inliers : 5
num_inliers : 11
num_inliers : 27
num_inliers : 23
num_inliers : 12
num_inliers : 24
num_inliers : 22
num_inliers : 23
num_inliers : 35
num_inliers : 15
num_inliers : 19
num_inliers : 44
num_inliers : 2
num_inliers : 34
num_inliers : 20
num_inliers : 30
num_inliers : 26
num_inliers : 16
num_inliers : 31
num_inliers : 35
num_inliers : 23
num_inliers : 25
num_inliers : 19
num_inliers : 12
num_inliers : 31
num_inliers : 28
num_inliers : 19
num_inliers : 5
num_inliers : 38
num_inliers : 27
num_inliers : 11
num_inliers : 20
num_inliers : 24
num_inliers : 23
num_inliers : 37
num_inliers : 4
num_inliers : 9
num_inliers : 29
num_inliers : 11
num_inliers : 14
num_inliers : 30
num_inliers : 13
num_inliers : 21
num_inliers : 20
num_inliers : 20
num_inliers : 32
num_inliers : 3
num_inliers : 11
num_inliers : 23
num_inliers : 8
num_inliers : 21
num_inliers : 9
num_inliers : 27
num_inliers : 11
num_inliers : 11
num_inliers : 27
num_inliers : 0
num_inliers : 26
num_inliers : 4
num_inliers : 33
num_inliers : 17
num_inliers : 9
num_inliers : 32
num_inliers : 6
num_inliers : 12
num_inliers : 28
num_inliers : 20
num_inliers : 9
num_inliers : 12
num_inliers : 29
num_inliers : 10
num_inliers : 4
num_inliers : 9
num_inliers : 18
num_inliers : 5
num_inliers : 25
num_inliers : 18
num_inliers : 1
num_inliers : 12
num_inliers : 5
num_inliers : 26
num_inliers : 9
num_inliers : 27
num_inliers : 32
num_inliers : 24
num_inliers : 17
num_inliers : 14
num_inliers : 35
num_inliers : 17
num_inliers : 6
num_inliers : 7
num_inliers : 4
num_inliers : 36
num_inliers : 15
num_inliers : 12
num_inliers : 14
num_inliers : 10
num_inliers : 9
num_inliers : 27
num_inliers : 20
num_inliers : 46
num_inliers inside of Run : 46
num_inliers : 17
num_inliers : 19
num_inliers : 8
num_inliers : 27
num_inliers : 25
num_inliers : 15
num_inliers : 27
num_inliers : 26
num_inliers : 8
num_inliers : 20
num_inliers : 7
num_inliers : 31
num_inliers : 19
num_inliers : 15
num_inliers : 3
num_inliers : 28
num_inliers : 29
num_inliers : 12
num_inliers : 21
num_inliers : 12
num_inliers : 27
num_inliers : 27
num_inliers : 23
num_inliers : 10
num_inliers : 15
num_inliers : 4
num_inliers : 27
num_inliers : 15
num_inliers : 2
num_inliers : 16
num_inliers : 13
num_inliers : 17
num_inliers : 6
num_inliers : 17
num_inliers : 18
num_inliers : 24
num_inliers : 13
num_inliers : 20
num_inliers : 3
num_inliers : 2
num_inliers : 6
num_inliers : 5
num_inliers : 2
num_inliers : 27
num_inliers : 10
num_inliers : 8
num_inliers : 26
num_inliers : 7
num_inliers : 17
num_inliers : 8
num_inliers : 28
num_inliers : 23
num_inliers : 27
num_inliers : 25
num_inliers : 0
num_inliers : 11
num_inliers : 1
num_inliers : 13
num_inliers : 7
num_inliers : 27
num_inliers : 13
num_inliers : 4
num_inliers : 10
num_inliers : 12
num_inliers : 23
num_inliers : 21
num_inliers : 18
num_inliers : 21
num_inliers : 3
num_inliers : 20
num_inliers : 18
num_inliers : 11
num_inliers : 28
num_inliers : 21
num_inliers : 24
num_inliers : 2
num_inliers : 0
num_inliers : 9
num_inliers : 17
num_inliers : 9
num_inliers : 13
num_inliers : 15
num_inliers : 25
num_inliers : 8
num_inliers : 7
num_inliers : 13
num_inliers : 26
num_inliers : 24
num_inliers : 22
num_inliers : 22
num_inliers : 7
num_inliers : 20
num_inliers : 6
num_inliers : 19
num_inliers : 24
num_inliers : 16
num_inliers : 21
num_inliers : 2
num_inliers : 5
num_inliers : 12
num_inliers : 28
num_inliers : 7
num_inliers : 3
num_inliers : 19
num_inliers : 2
num_inliers : 11
num_inliers : 15
num_inliers : 19
num_inliers : 0
num_inliers : 28
num_inliers : 20
num_inliers : 3
num_inliers : 12
num_inliers : 9
num_inliers : 0
num_inliers : 22
num_inliers : 12
num_inliers : 14
num_inliers : 18
num_inliers : 4
num_inliers : 17
num_inliers : 12
num_inliers : 21
num_inliers : 13
num_inliers : 17
num_inliers : 22
num_inliers : 17
num_inliers : 2
num_inliers : 22
num_inliers : 31
num_inliers : 4
num_inliers : 26
num_inliers : 10
num_inliers : 0
num_inliers : 14
num_inliers : 23
num_inliers : 30
num_inliers : 6
num_inliers : 23
num_inliers : 25
num_inliers : 22
num_inliers : 14
num_inliers : 26
num_inliers : 20
num_inliers : 20
num_inliers : 16
num_inliers : 4
num_inliers : 15
num_inliers : 9
num_inliers inside of Run : 31
num_inliers : 11
num_inliers : 8
num_inliers : 14
num_inliers : 1
num_inliers : 9
num_inliers : 17
num_inliers : 5
num_inliers : 10
num_inliers : 0
num_inliers : 19
num_inliers : 4
num_inliers : 17
num_inliers : 20
num_inliers : 17
num_inliers : 18
num_inliers : 16
num_inliers : 18
num_inliers : 3
num_inliers : 9
num_inliers : 3
num_inliers : 9
num_inliers : 17
num_inliers : 12
num_inliers : 13
num_inliers : 19
num_inliers : 4
num_inliers : 13
num_inliers : 8
num_inliers : 15
num_inliers : 23
num_inliers : 9
num_inliers : 1
num_inliers : 5
num_inliers : 9
num_inliers : 2
num_inliers : 8
num_inliers : 11
num_inliers : 11
num_inliers : 1
num_inliers : 8
num_inliers : 13
num_inliers : 7
num_inliers : 12
num_inliers : 10
num_inliers : 13
num_inliers : 16
num_inliers : 8
num_inliers : 14
num_inliers : 13
num_inliers : 9
num_inliers : 5
num_inliers : 15
num_inliers : 0
num_inliers : 0
num_inliers : 6
num_inliers : 17
num_inliers : 0
num_inliers : 25
num_inliers : 7
num_inliers : 16
num_inliers : 22
num_inliers : 11
num_inliers : 2
num_inliers : 7
num_inliers : 1
num_inliers : 14
num_inliers : 25
num_inliers : 5
num_inliers : 14
num_inliers : 19
num_inliers : 17
num_inliers : 8
num_inliers : 15
num_inliers : 16
num_inliers : 12
num_inliers : 21
num_inliers : 17
num_inliers : 13
num_inliers : 14
num_inliers : 19
num_inliers : 6
num_inliers : 9
num_inliers : 10
num_inliers : 9
num_inliers : 0
num_inliers : 7
num_inliers : 14
num_inliers : 6
num_inliers : 15
num_inliers : 15
num_inliers : 22
num_inliers : 15
num_inliers : 16
num_inliers : 1
num_inliers : 10
num_inliers : 15
num_inliers : 10
num_inliers : 18
num_inliers : 0
num_inliers : 11
num_inliers : 6
num_inliers inside of Run : 25
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L74:} // ScopedTimer (SquentialRANSAC) [0.021444 s]
  0.49517  0.213479 -0.120122  0.585624
-0.198222  0.508375 0.0863605  0.083823
 0.143912 -0.034306  0.532267 -0.152702
        0         0         0         1
  0.224372  0.0762663  -0.114129   0.765774
  0.135032 -0.0833387   0.209776   0.016592
 0.0246642  -0.237535  -0.110243   0.262806
         0          0          0          1
 0.678136  0.172612 -0.257312  0.551886
-0.105447 -0.453634 -0.582211  0.279933
-0.291351  0.565945 -0.388193  0.193195
        0         0         0         1
  0.158222   0.389915  0.0682774   0.712978
 -0.387003   0.167825  -0.061585    0.22886
-0.0832084 -0.0391264   0.416263 0.00824322
         0          0          0          1
 -0.127603   0.243636 -0.0125899   0.830298
  0.229938   0.115361 -0.0980795 -0.0497972
-0.0815179 -0.0559724  -0.256946   0.275295
         0          0          0          1
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(DenseGaussNewton::optimize()) {
VERBOSE: /home/aiday.kyzy/code/sfm/src/./vision/geometry/dense_gauss_newton.h:L118:# parameters: 7
VERBOSE: /home/aiday.kyzy/code/sfm/src/./vision/geometry/dense_gauss_newton.h:L119:# residuals: 9380
INFO: /home/aiday.kyzy/code/sfm/src/./vision/geometry/dense_gauss_newton.h:L238:Gauss-Newton gradient threshold reached.
INFO: /home/aiday.kyzy/code/sfm/src/./vision/geometry/dense_gauss_newton.h:L240:Gauss-Newton gradient max norm 0.000000e+00 <= 1.000000e-06
INFO: /home/aiday.kyzy/code/sfm/src/./vision/geometry/dense_gauss_newton.h:L241:Gauss-Newton convergence #iters: 19
INFO: /home/aiday.kyzy/code/sfm/src/./vision/geometry/dense_gauss_newton.h:L242:Gauss-Newton converged.
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L74:} // ScopedTimer (DenseGaussNewton::optimize()) [0.069516 s]
Affine transform:   0.00109267   0.00161882  -0.00106522     -2.45565
  0.00191475  -0.00109017  0.000307346    0.0725558
-0.000298352  -0.00106778  -0.00192874     -3.21465
           0            0            0            1
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L232:#models: 5
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L91:#model 0 | #inliers 192
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L91:#model 1 | #inliers 116
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L91:#model 2 | #inliers 46
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L91:#model 3 | #inliers 31
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L91:#model 4 | #inliers 25
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L235:#inilers: 410
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L257:Mesh1: #vertices: 9132
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/point_cloud_non_rigid_merge.cc:L258:Mesh2: #vertices: 9380
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(Registration2::Register) {
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/registration/non_rigid_registration.cc:L784:SampleDeformationNodes
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(PointCloudSampling::PoissonSphereSampling) {
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L74:} // ScopedTimer (PointCloudSampling::PoissonSphereSampling) [0.008702 s]
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/registration/non_rigid_registration.cc:L790:Create balltree...
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/registration/non_rigid_registration.cc:L797:Build kdtree...
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/registration/non_rigid_registration.cc:L804:Create matches...
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/registration/non_rigid_registration.cc:L826:#matches / #inliers: 453/453
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/registration/non_rigid_registration.cc:L827:Mesh1: #points | #normals: 410 | 410
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/registration/non_rigid_registration.cc:L828:Mesh2: #points | #normals: 410 | 410
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(SetupRegistrationProblem) {
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L74:} // ScopedTimer (SetupRegistrationProblem) [0.000217 s]
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(SolveCeresProblem) {
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L74:} // ScopedTimer (SolveCeresProblem) [0.000942 s]
VERBOSE: /home/aiday.kyzy/code/sfm/src/vision/point_cloud/registration/non_rigid_registration.cc:L881:Summary: 
Solver Summary (v 2.1.0-eigen-(3.3.4)-lapack-suitesparse-(5.1.2)-cxsparse-(3.1.9)-eigensparse-no_openmp-cuda-(11030))

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  6                        6
Residual blocks                           410                      410
Residuals                                 410                      410

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver          SPARSE_NORMAL_CHOLESKY   SPARSE_NORMAL_CHOLESKY
Threads                                    16                       16
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                         -1.000000e+00

Minimizer iterations                        0
Successful steps                            0
Unsuccessful steps                          0

Time (in seconds):
Preprocessor                         0.000468

  Residual only evaluation           0.000000 (0)
  Jacobian & residual evaluation     0.000396 (1)
  Linear solver                      0.000000 (0)
Minimizer                            0.000439

Postprocessor                        0.000008
Total                                0.000926

Termination:                          FAILURE (Residual and Jacobian evaluation failed.)

INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(Update nodes) {
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L74:} // ScopedTimer (Update nodes) [0.000005 s]
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L74:} // ScopedTimer (Registration2::Register) [0.020913 s]
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(PointCloudSampling::PoissonSphereSampling) {
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L74:} // ScopedTimer (PointCloudSampling::PoissonSphereSampling) [0.011670 s]
INFO: /home/aiday.kyzy/code/sfm/src/base/scoped_timer.cc:L87:ScopedTimer(PointCloudSampling::PoissonSphereSampling) {
strict inlier ratio threshold :  0.01
relaxed inlier ratio threshold :  0.03
[1;33m[Open3D WARNING] Read PLY failed: unable to open file: /home/aiday.kyzy/dataset/Synthetic/PartialNonDeformedData/TestingData//model002/output_partial_non_deformed_deformed_current_deformation_pre_none_kpfcn_td_full_deformed_e_10_knn_True_conf_1e-06_cl_-3_icf_2/current_deformation.ply[0;m
