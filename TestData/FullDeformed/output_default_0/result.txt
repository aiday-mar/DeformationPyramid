Before getting the dataloader
Inside of collate_fn_4dmatch
src_pcd.shape :  (8696, 3)
tgt_pcd.shape :  (8682, 3)
src_feats.shape :  (8696, 1)
tgt_feats.shape :  (8682, 1)
correspondences.shape :  (11941, 2)
rot.shape :  (3, 3)
trn.shape :  (3, 1)
s2t_flow.shape :  (11941, 3)


block_i :  0
pool or strided in block


block_i :  1
pool or strided in block


block_i :  2
layer_blocks exists
batched_points.shape :  torch.Size([17378, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.025
conv_i.shape :  torch.Size([17378, 126])
pool or strided in the block
pool_p.shape :  torch.Size([2109, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([17378, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.025
pool_i.shape :  torch.Size([2109, 123])
up_i.shape :  torch.Size([17378, 58])
pool_p.shape :  torch.Size([2109, 3])
pool_b.shape :  torch.Size([2])


block_i :  3
pool or strided in block


block_i :  4
pool or strided in block


block_i :  5
layer_blocks exists
batched_points.shape :  torch.Size([2109, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.05
conv_i.shape :  torch.Size([2109, 54])
pool or strided in the block
pool_p.shape :  torch.Size([543, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([2109, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.05
pool_i.shape :  torch.Size([543, 49])
up_i.shape :  torch.Size([2109, 53])
pool_p.shape :  torch.Size([543, 3])
pool_b.shape :  torch.Size([2])


block_i :  6
pool or strided in block


block_i :  7
pool or strided in block


block_i :  8
layer_blocks exists
batched_points.shape :  torch.Size([543, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.1
conv_i.shape :  torch.Size([543, 53])
pool or strided in the block
pool_p.shape :  torch.Size([137, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([543, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.1
pool_i.shape :  torch.Size([137, 49])
up_i.shape :  torch.Size([543, 61])
pool_p.shape :  torch.Size([137, 3])
pool_b.shape :  torch.Size([2])


block_i :  9
pool or strided in block


block_i :  10
pool or strided in block
layer_blocks exists
batched_points.shape :  torch.Size([137, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.2
conv_i.shape :  torch.Size([137, 58])
pool or strided not in the block
pool_i.shape :  torch.Size([0, 1])
pool_p.shape :  torch.Size([0, 3])
pool_b.shape :  torch.Size([0])
up_i.shape :  torch.Size([0, 1])
pool_p.shape :  torch.Size([0, 3])
pool_b.shape :  torch.Size([0])


block_i :  11
global or upsample in block
coarse_level :  -3
pts_num_coarse.shape :  torch.Size([1, 2])
src_pts_max.shape :  torch.Size([])
tgt_pts_max.shape :  torch.Size([])
len(input_points) :  4
coarse_pcd.shape :  torch.Size([2109, 3])
n_s_pts :  tensor(1061, dtype=torch.int32)
n_t_pts :  tensor(1048, dtype=torch.int32)
accumu :  0
accumu + n_s_pts :  tensor(1061, dtype=torch.int32)
c_src_pcd_np.shape :  (1061, 3)
accumu + n_s_pts :  tensor(1061, dtype=torch.int32)
accumu + n_s_pts + n_t_pts :  tensor(2109, dtype=torch.int32)
c_tgt_pcd_np.shape :  (1048, 3)
f_src_pcd.shape :  (8696, 3)
Inside of blend_scene_flow
query_loc.shape :  (1061, 3)
reference_loc.shape :  (8696, 3)
reference_flow.shape :  (11941, 3)
dists.shape :  (1061, 3)
idx.shape :  (1061, 3)
blended_flow.shape :  (1061, 3)
c_flow.shape :  (1061, 3)
c_src_pcd_deformed.shape :  (1061, 3)
s_pc_wrapped.shape :  (1061, 3)


Inside of mutual_nn_correspondence
src_pcd_deformed.shape :  (1061, 3)
tgt_pcd.shape :  (1048, 3)
s2t_dists.shape :  (1061, 1)
ref_tgt_idx.shape :  (1061, 1)
s2t_dists.shape :  (1061,)
ref_tgt_idx.shape :  (1061,)
cycle_src_idx.shape :  (1061,)
mutual_nn.shape :  (1061,)
correspondences.shape :  (2, 178)


coarse_match_gt.shape :  torch.Size([2, 178])


Returned from collate_fn_4dmatch
len(src_pcd_list) :  1
src_pcd_list[0].shape :  torch.Size([8696, 3])
len(tgt_pcd_list) :  1
tgt_pcd_list[0].shape :  torch.Size([8682, 3])
len(input_points) :  4
input_points[0].shape :  torch.Size([17378, 3])
len(input_neighbors) :  4
input_neighbors[0].shape :  torch.Size([17378, 126])
len(input_pools) :  4
input_pools[0].shape :  torch.Size([2109, 123])
len(input_upsamples) :  4
input_upsamples[0].shape :  torch.Size([17378, 58])
batched_features.shape :  torch.Size([17378, 1])
len(input_batches_len) :  4
input_batches_len[0].shape :  torch.Size([2])
len(coarse_matches) :  1
coarse_matches[0].shape :  torch.Size([2, 178])
len(coarse_flow) :  1
coarse_flow[0].shape :  torch.Size([1061, 3])
src_mask.shape :  torch.Size([1, 1061])
tgt_mask.shape :  torch.Size([1, 1048])
src_ind_coarse_split.shape :  torch.Size([1061])
tgt_ind_coarse_split.shape :  torch.Size([1048])
src_ind_coarse.shape :  torch.Size([1061])
tgt_ind_coarse.shape :  torch.Size([1048])
batched_rot.shape :  torch.Size([1, 3, 3])
batched_trn.shape :  torch.Size([1, 3, 1])
len(sflow_list) :  1
sflow_list[0].shape :  torch.Size([11941, 3])
len(correspondences_list) :  1
correspondences_list[0].shape :  torch.Size([11941, 2])




Before inference on the Landmark Model
Inside of Landmark_Model inference


Calling the matcher on the inputs
Inside the forward method of the Pipeline
Before KPFCN backbone
Inside of KPFCN forward

 
Before encoder blocks
batch.keys() : dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list'])
x.shape :  torch.Size([17378, 1])
block_i :  0
x.shape :  torch.Size([17378, 128])
block_i :  1
x.shape :  torch.Size([17378, 256])
block_i :  2
Adding skip
x.shape :  torch.Size([2109, 256])
block_i :  3
x.shape :  torch.Size([2109, 512])
block_i :  4
x.shape :  torch.Size([2109, 512])
block_i :  5
Adding skip
x.shape :  torch.Size([543, 512])
block_i :  6
x.shape :  torch.Size([543, 1024])
block_i :  7
x.shape :  torch.Size([543, 1024])
block_i :  8
Adding skip
x.shape :  torch.Size([137, 1024])
block_i :  9
x.shape :  torch.Size([137, 2048])
block_i :  10
x.shape :  torch.Size([137, 2048])


Before decoder blocks
block_i :  0
x.shape :  torch.Size([543, 2048])
block_i :  1
block_i in decoder_concats
x.shape :  torch.Size([543, 1024])
block_i :  2
x.shape :  torch.Size([2109, 1024])
coarse_feats.shape :  torch.Size([2109, 528])


Before splitting the features
Inside of split_feats
geo_feats.shape :  torch.Size([2109, 528])
src_mask.shape :  torch.Size([1, 1061])
tgt_mask.shape :  torch.Size([1, 1048])
src_ind_coarse_split.shape :  torch.Size([1061])
tgt_ind_coarse_split.shape :  torch.Size([1048])
src_ind_coarse.shape :  torch.Size([1061])
tgt_ind_coarse.shape :  torch.Size([1048])
src_feats.shape :  torch.Size([1061, 528])
tgt_feats.shape :  torch.Size([1048, 528])
src_feats.shape :  torch.Size([1061, 528])
tgt_feats.shape :  torch.Size([1048, 528])
src_pcd.shape :  torch.Size([1061, 3])
tgt_pcd.shape :  torch.Size([1048, 3])


Before the Repositioning Transformer
src_feat.shape :  torch.Size([1, 1061, 528])
tgt_feat.shape :  torch.Size([1, 1048, 528])
s_pcd.shape :  torch.Size([1, 1061, 3])
t_pcd.shape :  torch.Size([1, 1048, 3])
src_mask.shape :  torch.Size([1, 1061])
tgt_mask.shape :  torch.Size([1, 1048])
self.d_model : 528
src_feat.size(2) :  528
xyz.shape :  torch.Size([1, 1061, 3])
self.vol_origin.shape :  torch.Size([1, 1, 3])
After sent to other device
src_pe.shape :  torch.Size([1, 1061, 528, 2])
xyz.shape :  torch.Size([1, 1048, 3])
tgt_pe.shape :  torch.Size([1, 1048, 528, 2])


self
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
src_feat.shape :  torch.Size([1, 1061, 528])
tgt_feat.shape :  torch.Size([1, 1048, 528])


cross
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
src_feat.shape :  torch.Size([1, 1061, 528])
tgt_feat.shape :  torch.Size([1, 1048, 528])


positioning


Inside of forward function of Matching
src_feats.shape :  torch.Size([1, 1061, 528])
tgt_feats.shape :  torch.Size([1, 1048, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
Using dual softmax for matching
sim_matrix_1.shape :  torch.Size([1, 1061, 1048])
conf_matrix.shape :  torch.Size([1, 1061, 1048])
coarse_match.shape :  torch.Size([2506, 3])


Inside of the forward function of the SoftProcrustesLayer
conf_matrix.shape :  torch.Size([1, 1061, 1048])
src_pcd.shape :  torch.Size([1, 1061, 3])
tgt_pcd.shape :  torch.Size([1, 1048, 3])
src_mask.shape :  torch.Size([1, 1061])
tgt_mask.shape :  torch.Size([1, 1048])
sample_n_points.shape :  torch.Size([])
idx.shape :  torch.Size([1, 1061])
src_pcd_sampled.shape :  torch.Size([1, 1061, 3])
tgt_pcd_sampled.shape :  torch.Size([1, 1061, 3])
w_mask.shape :  torch.Size([1, 1061])
R.shape :  torch.Size([1, 3, 3])
t.shape :  torch.Size([1, 3, 1])
R_forwd.shape :  torch.Size([1, 3, 3])
t_forwd.shape :  torch.Size([1, 3, 1])
solution_mask.shape :  torch.Size([1])
xyz.shape :  torch.Size([1, 1061, 3])
xyz.shape :  torch.Size([1, 1048, 3])


self
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
src_feat.shape :  torch.Size([1, 1061, 528])
tgt_feat.shape :  torch.Size([1, 1048, 528])


cross
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
src_feat.shape :  torch.Size([1, 1061, 528])
tgt_feat.shape :  torch.Size([1, 1048, 528])


End of forward of RepositioningTransformer
src_feat.shape :  torch.Size([1, 1061, 528])
tgt_feat.shape :  torch.Size([1, 1048, 528])
src_pe.shape :  torch.Size([1, 1061, 528, 2])
tgt_pe.shape :  torch.Size([1, 1048, 528, 2])


Before the matching


Inside of forward function of Matching
src_feats.shape :  torch.Size([1, 1061, 528])
tgt_feats.shape :  torch.Size([1, 1048, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1061, 528])
x2.shape :  torch.Size([1, 1061, 528])
cos.shape :  torch.Size([1, 1061, 528])
sin.shape :  torch.Size([1, 1061, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 1048, 528])
x2.shape :  torch.Size([1, 1048, 528])
cos.shape :  torch.Size([1, 1048, 528])
sin.shape :  torch.Size([1, 1048, 528])
Using dual softmax for matching
sim_matrix_1.shape :  torch.Size([1, 1061, 1048])
conf_matrix.shape :  torch.Size([1, 1061, 1048])
coarse_match.shape :  torch.Size([3118, 3])


Before the Soft Procrustes Layer


Inside of the forward function of the SoftProcrustesLayer
conf_matrix.shape :  torch.Size([1, 1061, 1048])
src_pcd.shape :  torch.Size([1, 1061, 3])
tgt_pcd.shape :  torch.Size([1, 1048, 3])
src_mask.shape :  torch.Size([1, 1061])
tgt_mask.shape :  torch.Size([1, 1048])
sample_n_points.shape :  torch.Size([])
idx.shape :  torch.Size([1, 1061])
src_pcd_sampled.shape :  torch.Size([1, 1061, 3])
tgt_pcd_sampled.shape :  torch.Size([1, 1061, 3])
w_mask.shape :  torch.Size([1, 1061])
R.shape :  torch.Size([1, 3, 3])
t.shape :  torch.Size([1, 3, 1])
R_forwd.shape :  torch.Size([1, 3, 3])
t_forwd.shape :  torch.Size([1, 3, 1])
solution_mask.shape :  torch.Size([1])
data.keys() :  dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list', 's_pcd', 't_pcd', 'position_layers', 'src_feats_nopos', 'tgt_feats_nopos', 'src_feats', 'tgt_feats', 'conf_matrix_pred', 'coarse_match_pred', 'R_s2t_pred', 't_s2t_pred'])


Calling the outlier rejection method on the data
data.keys() :  dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list', 's_pcd', 't_pcd', 'position_layers', 'src_feats_nopos', 'tgt_feats_nopos', 'src_feats', 'tgt_feats', 'conf_matrix_pred', 'coarse_match_pred', 'R_s2t_pred', 't_s2t_pred'])
Inside of _3D_to_6D
ind.shape :  torch.Size([3118, 3])
batch_vec6d.shape :  torch.Size([1, 3118, 6])
batch_mask.shape :  torch.Size([1, 3118])
batch_index.shape :  torch.Size([1, 3118, 2])
src_keypts.shape :  torch.Size([1, 3118, 3])
tgt_keypts.shape :  torch.Size([1, 3118, 3])
src_dist.shape :  torch.Size([1, 3118, 3118])
tgt_dist.shape :  torch.Size([1, 3118, 3118])
corr_compatibility.shape :  torch.Size([1, 3118, 3118])


Inside of forward method of VolPE
s_pe.shape :  torch.Size([1, 3118, 72, 2])
t_pe.shape :  torch.Size([1, 3118, 72, 2])
pe_6d.shape :  torch.Size([1, 3118, 144, 2])
feat.shape :  torch.Size([1, 3118, 144])
feat.shape after _6D_geometry_layers :  torch.Size([1, 3118, 144])
confidence.shape :  torch.Size([1, 3118])


coarse_flow :  torch.Size([1061, 3])
len(inlier_mask) :  1
inlier_mask[0].shape :  torch.Size([3118])
len(inlier_rate) :  1
match_filtered.shape :  torch.Size([2868])
inlier_rate_2.shape :  torch.Size([])
ldmk_s.shape :  torch.Size([2868, 3])
ldmk_t.shape :  torch.Size([2868, 3])


s2t_flow.shape :  torch.Size([11941, 3])
correspondence.shape :  torch.Size([11941, 2])
overlap.shape :  torch.Size([8696])


Before calling the register method on the model
Inside of the register method
Inside of optimize_deformation_pyramid
base :  /home/aiday.kyzy/code/DeformationPyramid/TestData/
src_mean.shape :  torch.Size([1, 3])
tgt_mean.shape :  torch.Size([1, 3])
src.shape :  torch.Size([8696])
tgt.shape :  torch.Size([8682])
s_sample.shape :  torch.Size([2000, 3])
t_sample.shape :  torch.Size([2000, 3])
src_ldmk.shape :  torch.Size([2868, 3])
tgt_ldmk.shape :  torch.Size([2868, 3])


BEFORE TRAINING
level :  0
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  108
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  1
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  2
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  3
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  4
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  5
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  6
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  37
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  7
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  27
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  8
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  75
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  9
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([2868, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([2868, 3])
s_sample.shape :  torch.Size([2000, 3])


AFTER TRAINING


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  0
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  1
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  2
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  3
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  4
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  5
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  6
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  7
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  8
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([8696, 3])
x_position.shape :  torch.Size([8696, 1])
y_position.shape :  torch.Size([8696, 1])
z_position.shape :  torch.Size([8696, 1])
pe.shape :  torch.Size([8696, 6])
fea.shape :  torch.Size([8696, 6])
fea.shape after input layer :  torch.Size([8696, 128])
fea.shape after mlp layer :  torch.Size([8696, 128])
t.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
x_.shape :  torch.Size([8696, 3])
Nonrigidity set to None


i :  9
x.shape :  torch.Size([8696, 3])
R.shape :  torch.Size([8696, 3, 3])
t.shape :  torch.Size([8696, 3])
warped_pcd.shape :  torch.Size([8696, 3])


After call to register
warped_pcd.shape :  torch.Size([8696, 3])


flow.shape :  torch.Size([8696, 3])
message : 0/1: full-epe: 21.350 
full-AccS: 10.108 
full-AccR: 13.558 
full-outlier: 23.758 
vis-epe: 25.008 
vis-AccS: 0.663 
vis-AccR: 2.569 
vis-outlier: 29.160 
occ-epe: 5.262 
occ-AccS: 51.645 
occ-AccR: 61.887 
occ-outlier: 0.000 

