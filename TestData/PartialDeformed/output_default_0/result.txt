Before getting the dataloader
Inside of collate_fn_4dmatch
src_pcd.shape :  (16241, 3)
tgt_pcd.shape :  (15854, 3)
src_feats.shape :  (16241, 1)
tgt_feats.shape :  (15854, 1)
correspondences.shape :  (32395, 2)
rot.shape :  (3, 3)
trn.shape :  (3, 1)
s2t_flow.shape :  (32395, 3)


block_i :  0
pool or strided in block


block_i :  1
pool or strided in block


block_i :  2
layer_blocks exists
batched_points.shape :  torch.Size([32095, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.025
conv_i.shape :  torch.Size([32095, 207])
pool or strided in the block
pool_p.shape :  torch.Size([1711, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([32095, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.025
pool_i.shape :  torch.Size([1711, 196])
up_i.shape :  torch.Size([32095, 48])
pool_p.shape :  torch.Size([1711, 3])
pool_b.shape :  torch.Size([2])


block_i :  3
pool or strided in block


block_i :  4
pool or strided in block


block_i :  5
layer_blocks exists
batched_points.shape :  torch.Size([1711, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.05
conv_i.shape :  torch.Size([1711, 46])
pool or strided in the block
pool_p.shape :  torch.Size([483, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([1711, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.05
pool_i.shape :  torch.Size([483, 46])
up_i.shape :  torch.Size([1711, 60])
pool_p.shape :  torch.Size([483, 3])
pool_b.shape :  torch.Size([2])


block_i :  6
pool or strided in block


block_i :  7
pool or strided in block


block_i :  8
layer_blocks exists
batched_points.shape :  torch.Size([483, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.1
conv_i.shape :  torch.Size([483, 57])
pool or strided in the block
pool_p.shape :  torch.Size([125, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([483, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.1
pool_i.shape :  torch.Size([125, 55])
up_i.shape :  torch.Size([483, 55])
pool_p.shape :  torch.Size([125, 3])
pool_b.shape :  torch.Size([2])


block_i :  9
pool or strided in block


block_i :  10
pool or strided in block
layer_blocks exists
batched_points.shape :  torch.Size([125, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.2
conv_i.shape :  torch.Size([125, 56])
pool or strided not in the block
pool_i.shape :  torch.Size([0, 1])
pool_p.shape :  torch.Size([0, 3])
pool_b.shape :  torch.Size([0])
up_i.shape :  torch.Size([0, 1])
pool_p.shape :  torch.Size([0, 3])
pool_b.shape :  torch.Size([0])


block_i :  11
global or upsample in block
coarse_level :  -3
pts_num_coarse.shape :  torch.Size([1, 2])
src_pts_max.shape :  torch.Size([])
tgt_pts_max.shape :  torch.Size([])
len(input_points) :  4
coarse_pcd.shape :  torch.Size([1711, 3])
n_s_pts :  tensor(867, dtype=torch.int32)
n_t_pts :  tensor(844, dtype=torch.int32)
accumu :  0
accumu + n_s_pts :  tensor(867, dtype=torch.int32)
c_src_pcd_np.shape :  (867, 3)
accumu + n_s_pts :  tensor(867, dtype=torch.int32)
accumu + n_s_pts + n_t_pts :  tensor(1711, dtype=torch.int32)
c_tgt_pcd_np.shape :  (844, 3)
f_src_pcd.shape :  (16241, 3)
Inside of blend_scene_flow
query_loc.shape :  (867, 3)
reference_loc.shape :  (16241, 3)
reference_flow.shape :  (32395, 3)
dists.shape :  (867, 3)
idx.shape :  (867, 3)
blended_flow.shape :  (867, 3)
c_flow.shape :  (867, 3)
c_src_pcd_deformed.shape :  (867, 3)
s_pc_wrapped.shape :  (867, 3)


Inside of mutual_nn_correspondence
src_pcd_deformed.shape :  (867, 3)
tgt_pcd.shape :  (844, 3)
s2t_dists.shape :  (867, 1)
ref_tgt_idx.shape :  (867, 1)
s2t_dists.shape :  (867,)
ref_tgt_idx.shape :  (867,)
cycle_src_idx.shape :  (867,)
mutual_nn.shape :  (867,)
correspondences.shape :  (2, 136)


coarse_match_gt.shape :  torch.Size([2, 136])


Returned from collate_fn_4dmatch
len(src_pcd_list) :  1
src_pcd_list[0].shape :  torch.Size([16241, 3])
len(tgt_pcd_list) :  1
tgt_pcd_list[0].shape :  torch.Size([15854, 3])
len(input_points) :  4
input_points[0].shape :  torch.Size([32095, 3])
len(input_neighbors) :  4
input_neighbors[0].shape :  torch.Size([32095, 207])
len(input_pools) :  4
input_pools[0].shape :  torch.Size([1711, 196])
len(input_upsamples) :  4
input_upsamples[0].shape :  torch.Size([32095, 48])
batched_features.shape :  torch.Size([32095, 1])
len(input_batches_len) :  4
input_batches_len[0].shape :  torch.Size([2])
len(coarse_matches) :  1
coarse_matches[0].shape :  torch.Size([2, 136])
len(coarse_flow) :  1
coarse_flow[0].shape :  torch.Size([867, 3])
src_mask.shape :  torch.Size([1, 867])
tgt_mask.shape :  torch.Size([1, 844])
src_ind_coarse_split.shape :  torch.Size([867])
tgt_ind_coarse_split.shape :  torch.Size([844])
src_ind_coarse.shape :  torch.Size([867])
tgt_ind_coarse.shape :  torch.Size([844])
batched_rot.shape :  torch.Size([1, 3, 3])
batched_trn.shape :  torch.Size([1, 3, 1])
len(sflow_list) :  1
sflow_list[0].shape :  torch.Size([32395, 3])
len(correspondences_list) :  1
correspondences_list[0].shape :  torch.Size([32395, 2])




Before inference on the Landmark Model
Inside of Landmark_Model inference


Calling the matcher on the inputs
Inside the forward method of the Pipeline
Before KPFCN backbone
Inside of KPFCN forward

 
Before encoder blocks
batch.keys() : dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list'])
x.shape :  torch.Size([32095, 1])
block_i :  0
x.shape :  torch.Size([32095, 128])
block_i :  1
x.shape :  torch.Size([32095, 256])
block_i :  2
Adding skip
x.shape :  torch.Size([1711, 256])
block_i :  3
x.shape :  torch.Size([1711, 512])
block_i :  4
x.shape :  torch.Size([1711, 512])
block_i :  5
Adding skip
x.shape :  torch.Size([483, 512])
block_i :  6
x.shape :  torch.Size([483, 1024])
block_i :  7
x.shape :  torch.Size([483, 1024])
block_i :  8
Adding skip
x.shape :  torch.Size([125, 1024])
block_i :  9
x.shape :  torch.Size([125, 2048])
block_i :  10
x.shape :  torch.Size([125, 2048])


Before decoder blocks
block_i :  0
x.shape :  torch.Size([483, 2048])
block_i :  1
block_i in decoder_concats
x.shape :  torch.Size([483, 1024])
block_i :  2
x.shape :  torch.Size([1711, 1024])
coarse_feats.shape :  torch.Size([1711, 528])


Before splitting the features
Inside of split_feats
geo_feats.shape :  torch.Size([1711, 528])
src_mask.shape :  torch.Size([1, 867])
tgt_mask.shape :  torch.Size([1, 844])
src_ind_coarse_split.shape :  torch.Size([867])
tgt_ind_coarse_split.shape :  torch.Size([844])
src_ind_coarse.shape :  torch.Size([867])
tgt_ind_coarse.shape :  torch.Size([844])
src_feats.shape :  torch.Size([867, 528])
tgt_feats.shape :  torch.Size([844, 528])
src_feats.shape :  torch.Size([867, 528])
tgt_feats.shape :  torch.Size([844, 528])
src_pcd.shape :  torch.Size([867, 3])
tgt_pcd.shape :  torch.Size([844, 3])


Before the Repositioning Transformer
src_feat.shape :  torch.Size([1, 867, 528])
tgt_feat.shape :  torch.Size([1, 844, 528])
s_pcd.shape :  torch.Size([1, 867, 3])
t_pcd.shape :  torch.Size([1, 844, 3])
src_mask.shape :  torch.Size([1, 867])
tgt_mask.shape :  torch.Size([1, 844])
self.d_model : 528
src_feat.size(2) :  528
xyz.shape :  torch.Size([1, 867, 3])
self.vol_origin.shape :  torch.Size([1, 1, 3])
After sent to other device
src_pe.shape :  torch.Size([1, 867, 528, 2])
xyz.shape :  torch.Size([1, 844, 3])
tgt_pe.shape :  torch.Size([1, 844, 528, 2])


self
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
src_feat.shape :  torch.Size([1, 867, 528])
tgt_feat.shape :  torch.Size([1, 844, 528])


cross
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
src_feat.shape :  torch.Size([1, 867, 528])
tgt_feat.shape :  torch.Size([1, 844, 528])


positioning


Inside of forward function of Matching
src_feats.shape :  torch.Size([1, 867, 528])
tgt_feats.shape :  torch.Size([1, 844, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
Using dual softmax for matching
sim_matrix_1.shape :  torch.Size([1, 867, 844])
conf_matrix.shape :  torch.Size([1, 867, 844])
coarse_match.shape :  torch.Size([1424, 3])


Inside of the forward function of the SoftProcrustesLayer
conf_matrix.shape :  torch.Size([1, 867, 844])
src_pcd.shape :  torch.Size([1, 867, 3])
tgt_pcd.shape :  torch.Size([1, 844, 3])
src_mask.shape :  torch.Size([1, 867])
tgt_mask.shape :  torch.Size([1, 844])
sample_n_points.shape :  torch.Size([])
idx.shape :  torch.Size([1, 867])
src_pcd_sampled.shape :  torch.Size([1, 867, 3])
tgt_pcd_sampled.shape :  torch.Size([1, 867, 3])
w_mask.shape :  torch.Size([1, 867])
R.shape :  torch.Size([1, 3, 3])
t.shape :  torch.Size([1, 3, 1])
R_forwd.shape :  torch.Size([1, 3, 3])
t_forwd.shape :  torch.Size([1, 3, 1])
solution_mask.shape :  torch.Size([1])
xyz.shape :  torch.Size([1, 867, 3])
xyz.shape :  torch.Size([1, 844, 3])


self
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
src_feat.shape :  torch.Size([1, 867, 528])
tgt_feat.shape :  torch.Size([1, 844, 528])


cross
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
src_feat.shape :  torch.Size([1, 867, 528])
tgt_feat.shape :  torch.Size([1, 844, 528])


End of forward of RepositioningTransformer
src_feat.shape :  torch.Size([1, 867, 528])
tgt_feat.shape :  torch.Size([1, 844, 528])
src_pe.shape :  torch.Size([1, 867, 528, 2])
tgt_pe.shape :  torch.Size([1, 844, 528, 2])


Before the matching


Inside of forward function of Matching
src_feats.shape :  torch.Size([1, 867, 528])
tgt_feats.shape :  torch.Size([1, 844, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 867, 528])
x2.shape :  torch.Size([1, 867, 528])
cos.shape :  torch.Size([1, 867, 528])
sin.shape :  torch.Size([1, 867, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 844, 528])
x2.shape :  torch.Size([1, 844, 528])
cos.shape :  torch.Size([1, 844, 528])
sin.shape :  torch.Size([1, 844, 528])
Using dual softmax for matching
sim_matrix_1.shape :  torch.Size([1, 867, 844])
conf_matrix.shape :  torch.Size([1, 867, 844])
coarse_match.shape :  torch.Size([1354, 3])


Before the Soft Procrustes Layer


Inside of the forward function of the SoftProcrustesLayer
conf_matrix.shape :  torch.Size([1, 867, 844])
src_pcd.shape :  torch.Size([1, 867, 3])
tgt_pcd.shape :  torch.Size([1, 844, 3])
src_mask.shape :  torch.Size([1, 867])
tgt_mask.shape :  torch.Size([1, 844])
sample_n_points.shape :  torch.Size([])
idx.shape :  torch.Size([1, 867])
src_pcd_sampled.shape :  torch.Size([1, 867, 3])
tgt_pcd_sampled.shape :  torch.Size([1, 867, 3])
w_mask.shape :  torch.Size([1, 867])
R.shape :  torch.Size([1, 3, 3])
t.shape :  torch.Size([1, 3, 1])
R_forwd.shape :  torch.Size([1, 3, 3])
t_forwd.shape :  torch.Size([1, 3, 1])
solution_mask.shape :  torch.Size([1])
data.keys() :  dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list', 's_pcd', 't_pcd', 'position_layers', 'src_feats_nopos', 'tgt_feats_nopos', 'src_feats', 'tgt_feats', 'conf_matrix_pred', 'coarse_match_pred', 'R_s2t_pred', 't_s2t_pred'])


Calling the outlier rejection method on the data
data.keys() :  dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list', 's_pcd', 't_pcd', 'position_layers', 'src_feats_nopos', 'tgt_feats_nopos', 'src_feats', 'tgt_feats', 'conf_matrix_pred', 'coarse_match_pred', 'R_s2t_pred', 't_s2t_pred'])
Inside of _3D_to_6D
ind.shape :  torch.Size([1354, 3])
batch_vec6d.shape :  torch.Size([1, 1354, 6])
batch_mask.shape :  torch.Size([1, 1354])
batch_index.shape :  torch.Size([1, 1354, 2])
src_keypts.shape :  torch.Size([1, 1354, 3])
tgt_keypts.shape :  torch.Size([1, 1354, 3])
src_dist.shape :  torch.Size([1, 1354, 1354])
tgt_dist.shape :  torch.Size([1, 1354, 1354])
corr_compatibility.shape :  torch.Size([1, 1354, 1354])


Inside of forward method of VolPE
s_pe.shape :  torch.Size([1, 1354, 72, 2])
t_pe.shape :  torch.Size([1, 1354, 72, 2])
pe_6d.shape :  torch.Size([1, 1354, 144, 2])
feat.shape :  torch.Size([1, 1354, 144])
feat.shape after _6D_geometry_layers :  torch.Size([1, 1354, 144])
confidence.shape :  torch.Size([1, 1354])


coarse_flow :  torch.Size([867, 3])
len(inlier_mask) :  1
inlier_mask[0].shape :  torch.Size([1354])
len(inlier_rate) :  1
match_filtered.shape :  torch.Size([871])
inlier_rate_2.shape :  torch.Size([])
ldmk_s.shape :  torch.Size([871, 3])
ldmk_t.shape :  torch.Size([871, 3])


s2t_flow.shape :  torch.Size([32395, 3])
correspondence.shape :  torch.Size([32395, 2])
overlap.shape :  torch.Size([16241])


Before calling the register method on the model
Inside of the register method
Inside of optimize_deformation_pyramid
base :  /home/aiday.kyzy/code/DeformationPyramid/TestData/
src_mean.shape :  torch.Size([1, 3])
tgt_mean.shape :  torch.Size([1, 3])
src.shape :  torch.Size([16241])
tgt.shape :  torch.Size([15854])
s_sample.shape :  torch.Size([2000, 3])
t_sample.shape :  torch.Size([2000, 3])
src_ldmk.shape :  torch.Size([871, 3])
tgt_ldmk.shape :  torch.Size([871, 3])


BEFORE TRAINING
level :  0
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  90
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  1
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  2
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  3
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  4
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  5
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  6
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  63
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  7
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  16
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  8
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  112
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  9
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([871, 3])
Before break at iter :  109
warped_ldmk.shape :  torch.Size([871, 3])
s_sample.shape :  torch.Size([2000, 3])


AFTER TRAINING


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  0
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  1
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  2
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  3
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  4
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  5
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  6
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  7
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  8
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16241, 3])
x_position.shape :  torch.Size([16241, 1])
y_position.shape :  torch.Size([16241, 1])
z_position.shape :  torch.Size([16241, 1])
pe.shape :  torch.Size([16241, 6])
fea.shape :  torch.Size([16241, 6])
fea.shape after input layer :  torch.Size([16241, 128])
fea.shape after mlp layer :  torch.Size([16241, 128])
t.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
x_.shape :  torch.Size([16241, 3])
Nonrigidity set to None


i :  9
x.shape :  torch.Size([16241, 3])
R.shape :  torch.Size([16241, 3, 3])
t.shape :  torch.Size([16241, 3])
warped_pcd.shape :  torch.Size([16241, 3])


After call to register
warped_pcd.shape :  torch.Size([16241, 3])


flow.shape :  torch.Size([16241, 3])
message : 0/1: full-epe: 19.170 
full-AccS: 0.419 
full-AccR: 7.210 
full-outlier: 51.358 
vis-epe: 27.529 
vis-AccS: 0.166 
vis-AccR: 0.599 
vis-outlier: 88.582 
occ-epe: 8.748 
occ-AccS: 0.733 
occ-AccR: 15.452 
occ-outlier: 4.952 

