Before getting the dataloader
Inside of collate_fn_4dmatch
src_pcd.shape :  (16205, 3)
tgt_pcd.shape :  (16228, 3)
src_feats.shape :  (16205, 1)
tgt_feats.shape :  (16228, 1)
correspondences.shape :  (32765, 2)
rot.shape :  (3, 3)
trn.shape :  (3, 1)
s2t_flow.shape :  (32765, 3)


block_i :  0
pool or strided in block


block_i :  1
pool or strided in block


block_i :  2
layer_blocks exists
batched_points.shape :  torch.Size([32433, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.025
conv_i.shape :  torch.Size([32433, 211])
pool or strided in the block
pool_p.shape :  torch.Size([1726, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([32433, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.025
pool_i.shape :  torch.Size([1726, 206])
up_i.shape :  torch.Size([32433, 48])
pool_p.shape :  torch.Size([1726, 3])
pool_b.shape :  torch.Size([2])


block_i :  3
pool or strided in block


block_i :  4
pool or strided in block


block_i :  5
layer_blocks exists
batched_points.shape :  torch.Size([1726, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.05
conv_i.shape :  torch.Size([1726, 45])
pool or strided in the block
pool_p.shape :  torch.Size([478, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([1726, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.05
pool_i.shape :  torch.Size([478, 43])
up_i.shape :  torch.Size([1726, 56])
pool_p.shape :  torch.Size([478, 3])
pool_b.shape :  torch.Size([2])


block_i :  6
pool or strided in block


block_i :  7
pool or strided in block


block_i :  8
layer_blocks exists
batched_points.shape :  torch.Size([478, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.1
conv_i.shape :  torch.Size([478, 55])
pool or strided in the block
pool_p.shape :  torch.Size([122, 3])
pool_b.shape :  torch.Size([2])
batched_points.shape :  torch.Size([478, 3])
batched_lengths.shape :  torch.Size([2])
r :  0.1
pool_i.shape :  torch.Size([122, 52])
up_i.shape :  torch.Size([478, 60])
pool_p.shape :  torch.Size([122, 3])
pool_b.shape :  torch.Size([2])


block_i :  9
pool or strided in block


block_i :  10
pool or strided in block
layer_blocks exists
batched_points.shape :  torch.Size([122, 3])
batched_lengths.shape :  torch.Size([2])
neighborhood_limits[layer] :  905
r :  0.2
conv_i.shape :  torch.Size([122, 55])
pool or strided not in the block
pool_i.shape :  torch.Size([0, 1])
pool_p.shape :  torch.Size([0, 3])
pool_b.shape :  torch.Size([0])
up_i.shape :  torch.Size([0, 1])
pool_p.shape :  torch.Size([0, 3])
pool_b.shape :  torch.Size([0])


block_i :  11
global or upsample in block
coarse_level :  -3
pts_num_coarse.shape :  torch.Size([1, 2])
src_pts_max.shape :  torch.Size([])
tgt_pts_max.shape :  torch.Size([])
len(input_points) :  4
coarse_pcd.shape :  torch.Size([1726, 3])
n_s_pts :  tensor(876, dtype=torch.int32)
n_t_pts :  tensor(850, dtype=torch.int32)
accumu :  0
accumu + n_s_pts :  tensor(876, dtype=torch.int32)
c_src_pcd_np.shape :  (876, 3)
accumu + n_s_pts :  tensor(876, dtype=torch.int32)
accumu + n_s_pts + n_t_pts :  tensor(1726, dtype=torch.int32)
c_tgt_pcd_np.shape :  (850, 3)
f_src_pcd.shape :  (16205, 3)
Inside of blend_scene_flow
query_loc.shape :  (876, 3)
reference_loc.shape :  (16205, 3)
reference_flow.shape :  (32765, 3)
dists.shape :  (876, 3)
idx.shape :  (876, 3)
blended_flow.shape :  (876, 3)
c_flow.shape :  (876, 3)
c_src_pcd_deformed.shape :  (876, 3)
s_pc_wrapped.shape :  (876, 3)


Inside of mutual_nn_correspondence
src_pcd_deformed.shape :  (876, 3)
tgt_pcd.shape :  (850, 3)
s2t_dists.shape :  (876, 1)
ref_tgt_idx.shape :  (876, 1)
s2t_dists.shape :  (876,)
ref_tgt_idx.shape :  (876,)
cycle_src_idx.shape :  (876,)
mutual_nn.shape :  (876,)
correspondences.shape :  (2, 83)


coarse_match_gt.shape :  torch.Size([2, 83])


Returned from collate_fn_4dmatch
len(src_pcd_list) :  1
src_pcd_list[0].shape :  torch.Size([16205, 3])
len(tgt_pcd_list) :  1
tgt_pcd_list[0].shape :  torch.Size([16228, 3])
len(input_points) :  4
input_points[0].shape :  torch.Size([32433, 3])
len(input_neighbors) :  4
input_neighbors[0].shape :  torch.Size([32433, 211])
len(input_pools) :  4
input_pools[0].shape :  torch.Size([1726, 206])
len(input_upsamples) :  4
input_upsamples[0].shape :  torch.Size([32433, 48])
batched_features.shape :  torch.Size([32433, 1])
len(input_batches_len) :  4
input_batches_len[0].shape :  torch.Size([2])
len(coarse_matches) :  1
coarse_matches[0].shape :  torch.Size([2, 83])
len(coarse_flow) :  1
coarse_flow[0].shape :  torch.Size([876, 3])
src_mask.shape :  torch.Size([1, 876])
tgt_mask.shape :  torch.Size([1, 850])
src_ind_coarse_split.shape :  torch.Size([876])
tgt_ind_coarse_split.shape :  torch.Size([850])
src_ind_coarse.shape :  torch.Size([876])
tgt_ind_coarse.shape :  torch.Size([850])
batched_rot.shape :  torch.Size([1, 3, 3])
batched_trn.shape :  torch.Size([1, 3, 1])
len(sflow_list) :  1
sflow_list[0].shape :  torch.Size([32765, 3])
len(correspondences_list) :  1
correspondences_list[0].shape :  torch.Size([32765, 2])




Before inference on the Landmark Model
Inside of Landmark_Model inference


Calling the matcher on the inputs
Inside the forward method of the Pipeline
Before KPFCN backbone
Inside of KPFCN forward

 
Before encoder blocks
batch.keys() : dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list'])
x.shape :  torch.Size([32433, 1])
block_i :  0
x.shape :  torch.Size([32433, 128])
block_i :  1
x.shape :  torch.Size([32433, 256])
block_i :  2
Adding skip
x.shape :  torch.Size([1726, 256])
block_i :  3
x.shape :  torch.Size([1726, 512])
block_i :  4
x.shape :  torch.Size([1726, 512])
block_i :  5
Adding skip
x.shape :  torch.Size([478, 512])
block_i :  6
x.shape :  torch.Size([478, 1024])
block_i :  7
x.shape :  torch.Size([478, 1024])
block_i :  8
Adding skip
x.shape :  torch.Size([122, 1024])
block_i :  9
x.shape :  torch.Size([122, 2048])
block_i :  10
x.shape :  torch.Size([122, 2048])


Before decoder blocks
block_i :  0
x.shape :  torch.Size([478, 2048])
block_i :  1
block_i in decoder_concats
x.shape :  torch.Size([478, 1024])
block_i :  2
x.shape :  torch.Size([1726, 1024])
coarse_feats.shape :  torch.Size([1726, 528])


Before splitting the features
Inside of split_feats
geo_feats.shape :  torch.Size([1726, 528])
src_mask.shape :  torch.Size([1, 876])
tgt_mask.shape :  torch.Size([1, 850])
src_ind_coarse_split.shape :  torch.Size([876])
tgt_ind_coarse_split.shape :  torch.Size([850])
src_ind_coarse.shape :  torch.Size([876])
tgt_ind_coarse.shape :  torch.Size([850])
src_feats.shape :  torch.Size([876, 528])
tgt_feats.shape :  torch.Size([850, 528])
src_feats.shape :  torch.Size([876, 528])
tgt_feats.shape :  torch.Size([850, 528])
src_pcd.shape :  torch.Size([876, 3])
tgt_pcd.shape :  torch.Size([850, 3])


Before the Repositioning Transformer
src_feat.shape :  torch.Size([1, 876, 528])
tgt_feat.shape :  torch.Size([1, 850, 528])
s_pcd.shape :  torch.Size([1, 876, 3])
t_pcd.shape :  torch.Size([1, 850, 3])
src_mask.shape :  torch.Size([1, 876])
tgt_mask.shape :  torch.Size([1, 850])
self.d_model : 528
src_feat.size(2) :  528
xyz.shape :  torch.Size([1, 876, 3])
self.vol_origin.shape :  torch.Size([1, 1, 3])
After sent to other device
src_pe.shape :  torch.Size([1, 876, 528, 2])
xyz.shape :  torch.Size([1, 850, 3])
tgt_pe.shape :  torch.Size([1, 850, 528, 2])


self
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
src_feat.shape :  torch.Size([1, 876, 528])
tgt_feat.shape :  torch.Size([1, 850, 528])


cross
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
src_feat.shape :  torch.Size([1, 876, 528])
tgt_feat.shape :  torch.Size([1, 850, 528])


positioning


Inside of forward function of Matching
src_feats.shape :  torch.Size([1, 876, 528])
tgt_feats.shape :  torch.Size([1, 850, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
Using dual softmax for matching
sim_matrix_1.shape :  torch.Size([1, 876, 850])
conf_matrix.shape :  torch.Size([1, 876, 850])
coarse_match.shape :  torch.Size([1416, 3])


Inside of the forward function of the SoftProcrustesLayer
conf_matrix.shape :  torch.Size([1, 876, 850])
src_pcd.shape :  torch.Size([1, 876, 3])
tgt_pcd.shape :  torch.Size([1, 850, 3])
src_mask.shape :  torch.Size([1, 876])
tgt_mask.shape :  torch.Size([1, 850])
sample_n_points.shape :  torch.Size([])
idx.shape :  torch.Size([1, 876])
src_pcd_sampled.shape :  torch.Size([1, 876, 3])
tgt_pcd_sampled.shape :  torch.Size([1, 876, 3])
w_mask.shape :  torch.Size([1, 876])
R.shape :  torch.Size([1, 3, 3])
t.shape :  torch.Size([1, 3, 1])
R_forwd.shape :  torch.Size([1, 3, 3])
t_forwd.shape :  torch.Size([1, 3, 1])
solution_mask.shape :  torch.Size([1])
xyz.shape :  torch.Size([1, 876, 3])
xyz.shape :  torch.Size([1, 850, 3])


self
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
src_feat.shape :  torch.Size([1, 876, 528])
tgt_feat.shape :  torch.Size([1, 850, 528])


cross
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
src_feat.shape :  torch.Size([1, 876, 528])
tgt_feat.shape :  torch.Size([1, 850, 528])


End of forward of RepositioningTransformer
src_feat.shape :  torch.Size([1, 876, 528])
tgt_feat.shape :  torch.Size([1, 850, 528])
src_pe.shape :  torch.Size([1, 876, 528, 2])
tgt_pe.shape :  torch.Size([1, 850, 528, 2])


Before the matching


Inside of forward function of Matching
src_feats.shape :  torch.Size([1, 876, 528])
tgt_feats.shape :  torch.Size([1, 850, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 876, 528])
x2.shape :  torch.Size([1, 876, 528])
cos.shape :  torch.Size([1, 876, 528])
sin.shape :  torch.Size([1, 876, 528])
Inside of embed_rotary
x.shape :  torch.Size([1, 850, 528])
x2.shape :  torch.Size([1, 850, 528])
cos.shape :  torch.Size([1, 850, 528])
sin.shape :  torch.Size([1, 850, 528])
Using dual softmax for matching
sim_matrix_1.shape :  torch.Size([1, 876, 850])
conf_matrix.shape :  torch.Size([1, 876, 850])
coarse_match.shape :  torch.Size([1626, 3])


Before the Soft Procrustes Layer


Inside of the forward function of the SoftProcrustesLayer
conf_matrix.shape :  torch.Size([1, 876, 850])
src_pcd.shape :  torch.Size([1, 876, 3])
tgt_pcd.shape :  torch.Size([1, 850, 3])
src_mask.shape :  torch.Size([1, 876])
tgt_mask.shape :  torch.Size([1, 850])
sample_n_points.shape :  torch.Size([])
idx.shape :  torch.Size([1, 876])
src_pcd_sampled.shape :  torch.Size([1, 876, 3])
tgt_pcd_sampled.shape :  torch.Size([1, 876, 3])
w_mask.shape :  torch.Size([1, 876])
R.shape :  torch.Size([1, 3, 3])
t.shape :  torch.Size([1, 3, 1])
R_forwd.shape :  torch.Size([1, 3, 3])
t_forwd.shape :  torch.Size([1, 3, 1])
solution_mask.shape :  torch.Size([1])
data.keys() :  dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list', 's_pcd', 't_pcd', 'position_layers', 'src_feats_nopos', 'tgt_feats_nopos', 'src_feats', 'tgt_feats', 'conf_matrix_pred', 'coarse_match_pred', 'R_s2t_pred', 't_s2t_pred'])


Calling the outlier rejection method on the data
data.keys() :  dict_keys(['src_pcd_list', 'tgt_pcd_list', 'points', 'neighbors', 'pools', 'upsamples', 'features', 'stack_lengths', 'coarse_matches', 'coarse_flow', 'src_mask', 'tgt_mask', 'src_ind_coarse_split', 'tgt_ind_coarse_split', 'src_ind_coarse', 'tgt_ind_coarse', 'batched_rot', 'batched_trn', 'sflow_list', 'correspondences_list', 'depth_paths_list', 'cam_intrin', 'src_pcd_colors_list', 's_pcd', 't_pcd', 'position_layers', 'src_feats_nopos', 'tgt_feats_nopos', 'src_feats', 'tgt_feats', 'conf_matrix_pred', 'coarse_match_pred', 'R_s2t_pred', 't_s2t_pred'])
Inside of _3D_to_6D
ind.shape :  torch.Size([1626, 3])
batch_vec6d.shape :  torch.Size([1, 1626, 6])
batch_mask.shape :  torch.Size([1, 1626])
batch_index.shape :  torch.Size([1, 1626, 2])
src_keypts.shape :  torch.Size([1, 1626, 3])
tgt_keypts.shape :  torch.Size([1, 1626, 3])
src_dist.shape :  torch.Size([1, 1626, 1626])
tgt_dist.shape :  torch.Size([1, 1626, 1626])
corr_compatibility.shape :  torch.Size([1, 1626, 1626])


Inside of forward method of VolPE
s_pe.shape :  torch.Size([1, 1626, 72, 2])
t_pe.shape :  torch.Size([1, 1626, 72, 2])
pe_6d.shape :  torch.Size([1, 1626, 144, 2])
feat.shape :  torch.Size([1, 1626, 144])
feat.shape after _6D_geometry_layers :  torch.Size([1, 1626, 144])
confidence.shape :  torch.Size([1, 1626])


coarse_flow :  torch.Size([876, 3])
len(inlier_mask) :  1
inlier_mask[0].shape :  torch.Size([1626])
len(inlier_rate) :  1
match_filtered.shape :  torch.Size([977])
inlier_rate_2.shape :  torch.Size([])
ldmk_s.shape :  torch.Size([977, 3])
ldmk_t.shape :  torch.Size([977, 3])


s2t_flow.shape :  torch.Size([32765, 3])
correspondence.shape :  torch.Size([32765, 2])
overlap.shape :  torch.Size([16205])


Before calling the register method on the model
Inside of the register method
Inside of optimize_deformation_pyramid
base :  /home/aiday.kyzy/code/DeformationPyramid/TestData/
src_mean.shape :  torch.Size([1, 3])
tgt_mean.shape :  torch.Size([1, 3])
src.shape :  torch.Size([16205])
tgt.shape :  torch.Size([16228])
s_sample.shape :  torch.Size([2000, 3])
t_sample.shape :  torch.Size([2000, 3])
src_ldmk.shape :  torch.Size([977, 3])
tgt_ldmk.shape :  torch.Size([977, 3])


BEFORE TRAINING
level :  0
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  114
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  1
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  2
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  3
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  4
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  5
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  15
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  6
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  16
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  7
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  40
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  8
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  72
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])
level :  9
iter :  0
Landmarks is not None
Entered into the case config.w_cd = 0
warped_ldmk.shape :  torch.Size([977, 3])
Before break at iter :  55
warped_ldmk.shape :  torch.Size([977, 3])
s_sample.shape :  torch.Size([2000, 3])


AFTER TRAINING


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  0
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  1
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  2
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  3
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  4
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  5
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  6
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  7
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  8
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])


Inside of the forward function of the NDPLayer
x.shape :  torch.Size([16205, 3])
x_position.shape :  torch.Size([16205, 1])
y_position.shape :  torch.Size([16205, 1])
z_position.shape :  torch.Size([16205, 1])
pe.shape :  torch.Size([16205, 6])
fea.shape :  torch.Size([16205, 6])
fea.shape after input layer :  torch.Size([16205, 128])
fea.shape after mlp layer :  torch.Size([16205, 128])
t.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
x_.shape :  torch.Size([16205, 3])
Nonrigidity set to None


i :  9
x.shape :  torch.Size([16205, 3])
R.shape :  torch.Size([16205, 3, 3])
t.shape :  torch.Size([16205, 3])
warped_pcd.shape :  torch.Size([16205, 3])


After call to register
warped_pcd.shape :  torch.Size([16205, 3])


flow.shape :  torch.Size([16205, 3])
message : 0/1: full-epe: 24.141 
full-AccS: 15.427 
full-AccR: 37.902 
full-outlier: 35.810 
vis-epe: 38.578 
vis-AccS: 0.458 
vis-AccR: 1.682 
vis-outlier: 61.793 
occ-epe: 4.244 
occ-AccS: 36.058 
occ-AccR: 87.819 
occ-outlier: 0.000 

